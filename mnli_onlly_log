09/05 09:01:21 PM: Git branch: master
09/05 09:01:21 PM: Git SHA: 883e7176a66d891d9d0238a6a08338d8f200af17
09/05 09:01:21 PM: Parsed args: 
{
  "batch_size": 24,
  "classifier": "log_reg",
  "do_target_task_training": 0,
  "dropout": 0.1,
  "dropout_embs": 0.1,
  "input_module": "bert-base-cased",
  "local_log_path": "diagnostic_run_2/my-experiment/mnli_diagnostic/log.log",
  "lr": "1e-5",
  "lr_patience": 4,
  "max_epochs": 3,
  "max_vals": 10000,
  "min_lr": 0.0,
  "optimizer": "bert_adam",
  "patience": 20,
  "pretrain_tasks": "mnli",
  "pytorch_transformers_output_mode": "top",
  "random_seed": 42,
  "remote_log_name": "my-experiment__mnli_diagnostic",
  "run_dir": "diagnostic_run_2/my-experiment/mnli_diagnostic",
  "run_name": "mnli_diagnostic",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "mnli,glue-diagnostic",
  "transfer_paradigm": "finetune",
  "write_preds": "val,test"
}
09/05 09:01:21 PM: Saved config to diagnostic_run_2/my-experiment/mnli_diagnostic/params.conf
09/05 09:01:21 PM: Using random seed 42
09/05 09:01:22 PM: Using GPU 0
09/05 09:01:22 PM: Loading tasks...
09/05 09:01:22 PM: Writing pre-preprocessed tasks to diagnostic_run_2/my-experiment/
09/05 09:01:22 PM: 	Loaded existing task glue-diagnostic
09/05 09:01:22 PM: 	Task 'glue-diagnostic': |train|=1104 |val|=1104 |test|=1104
09/05 09:01:25 PM: 	Loaded existing task mnli
09/05 09:01:25 PM: 	Task 'mnli': |train|=392702 |val|=19647 |test|=19643
09/05 09:01:25 PM: 	Finished loading tasks: glue-diagnostic mnli.
09/05 09:01:25 PM: Loading token dictionary from diagnostic_run_2/my-experiment/vocab.
09/05 09:01:25 PM: 	Loaded vocab from diagnostic_run_2/my-experiment/vocab
09/05 09:01:25 PM: 	Vocab namespace bert_cased: size 28998
09/05 09:01:25 PM: 	Vocab namespace tokens: size 25700
09/05 09:01:25 PM: 	Vocab namespace chars: size 139
09/05 09:01:25 PM: 	Finished building vocab.
09/05 09:01:25 PM: 	Task 'glue-diagnostic', split 'train': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__train_data
09/05 09:01:25 PM: 	Task 'glue-diagnostic', split 'val': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__val_data
09/05 09:01:25 PM: 	Task 'glue-diagnostic', split 'test': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__test_data
09/05 09:01:25 PM: 	Task 'mnli', split 'train': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__train_data
09/05 09:01:25 PM: 	Task 'mnli', split 'val': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__val_data
09/05 09:01:25 PM: 	Task 'mnli', split 'test': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__test_data
09/05 09:01:25 PM: 	Finished indexing tasks
09/05 09:01:25 PM: 	Creating trimmed target-only version of glue-diagnostic train.
09/05 09:01:25 PM: 	Creating trimmed pretraining-only version of mnli train.
09/05 09:01:25 PM: 	Creating trimmed target-only version of mnli train.
09/05 09:01:25 PM: 	  Training on mnli
09/05 09:01:25 PM: 	  Evaluating on mnli, glue-diagnostic
09/05 09:01:25 PM: 	Finished loading tasks in 3.673s
09/05 09:01:25 PM: 	 Tasks: ['glue-diagnostic', 'mnli']
09/05 09:01:25 PM: Building model...
09/05 09:01:25 PM: Using BERT model (bert-base-cased).
09/05 09:01:25 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at diagnostic_run_2/my-experiment/pytorch_transformers_cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6
09/05 09:01:25 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

09/05 09:01:25 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at diagnostic_run_2/my-experiment/pytorch_transformers_cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
09/05 09:01:26 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/beegfs/yp913/jiant_cleanup/jiant/__main__.py", line 510, in main
    model = build_model(args, vocab, word_embs, tasks)
  File "/beegfs/yp913/jiant_cleanup/jiant/models.py", line 237, in build_model
    embedder = BertEmbedderModule(args)
  File "/beegfs/yp913/jiant_cleanup/jiant/pytorch_transformers_interface/modules.py", line 253, in __init__
    args.input_module, cache_dir=self.cache_dir, output_hidden_states=True
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_utils.py", line 474, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 657, in __init__
    self.encoder = BertEncoder(config)
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 428, in __init__
    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 428, in <listcomp>
    self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 410, in __init__
    self.attention = BertAttention(config)
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 351, in __init__
    self.self = BertSelfAttention(config)
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/pytorch_transformers/modeling_bert.py", line 288, in __init__
    self.key = nn.Linear(config.hidden_size, self.all_head_size)
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 81, in __init__
    self.reset_parameters()
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 84, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/beegfs/yp913/anaconda3/envs/jiant/lib/python3.6/site-packages/torch/nn/init.py", line 328, in kaiming_uniform_
    return tensor.uniform_(-bound, bound)
KeyboardInterrupt
09/05 09:01:41 PM: Git branch: master
09/05 09:01:41 PM: Git SHA: 883e7176a66d891d9d0238a6a08338d8f200af17
09/05 09:01:42 PM: Parsed args: 
{
  "batch_size": 24,
  "classifier": "log_reg",
  "do_target_task_training": 0,
  "dropout": 0.1,
  "dropout_embs": 0.1,
  "input_module": "bert-base-cased",
  "local_log_path": "diagnostic_run_2/my-experiment/mnli_diagnostic/log.log",
  "lr": "1e-5",
  "lr_patience": 4,
  "max_epochs": 3,
  "max_vals": 10000,
  "min_lr": 0.0,
  "optimizer": "bert_adam",
  "patience": 20,
  "pretrain_tasks": "mnli",
  "pytorch_transformers_output_mode": "top",
  "random_seed": 42,
  "remote_log_name": "my-experiment__mnli_diagnostic",
  "run_dir": "diagnostic_run_2/my-experiment/mnli_diagnostic",
  "run_name": "mnli_diagnostic",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "mnli,glue-diagnostic",
  "transfer_paradigm": "finetune",
  "write_preds": "val,test"
}
09/05 09:01:42 PM: Saved config to diagnostic_run_2/my-experiment/mnli_diagnostic/params.conf
09/05 09:01:42 PM: Using random seed 42
09/05 09:01:42 PM: Using GPU 0
09/05 09:01:42 PM: Loading tasks...
09/05 09:01:42 PM: Writing pre-preprocessed tasks to diagnostic_run_2/my-experiment/
09/05 09:01:42 PM: 	Loaded existing task glue-diagnostic
09/05 09:01:42 PM: 	Task 'glue-diagnostic': |train|=1104 |val|=1104 |test|=1104
09/05 09:01:45 PM: 	Loaded existing task mnli
09/05 09:01:45 PM: 	Task 'mnli': |train|=392702 |val|=19647 |test|=19643
09/05 09:01:45 PM: 	Finished loading tasks: glue-diagnostic mnli.
09/05 09:01:45 PM: Loading token dictionary from diagnostic_run_2/my-experiment/vocab.
09/05 09:01:45 PM: 	Loaded vocab from diagnostic_run_2/my-experiment/vocab
09/05 09:01:45 PM: 	Vocab namespace bert_cased: size 28998
09/05 09:01:45 PM: 	Vocab namespace tokens: size 25700
09/05 09:01:45 PM: 	Vocab namespace chars: size 139
09/05 09:01:45 PM: 	Finished building vocab.
09/05 09:01:45 PM: 	Task 'glue-diagnostic', split 'train': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__train_data
09/05 09:01:45 PM: 	Task 'glue-diagnostic', split 'val': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__val_data
09/05 09:01:45 PM: 	Task 'glue-diagnostic', split 'test': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/glue-diagnostic__test_data
09/05 09:01:45 PM: 	Task 'mnli', split 'train': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__train_data
09/05 09:01:45 PM: 	Task 'mnli', split 'val': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__val_data
09/05 09:01:45 PM: 	Task 'mnli', split 'test': Found preprocessed copy in diagnostic_run_2/my-experiment/preproc/mnli__test_data
09/05 09:01:45 PM: 	Finished indexing tasks
09/05 09:01:45 PM: 	Creating trimmed target-only version of glue-diagnostic train.
09/05 09:01:45 PM: 	Creating trimmed pretraining-only version of mnli train.
09/05 09:01:45 PM: 	Creating trimmed target-only version of mnli train.
09/05 09:01:45 PM: 	  Training on mnli
09/05 09:01:45 PM: 	  Evaluating on mnli, glue-diagnostic
09/05 09:01:45 PM: 	Finished loading tasks in 3.662s
09/05 09:01:45 PM: 	 Tasks: ['glue-diagnostic', 'mnli']
09/05 09:01:45 PM: Building model...
09/05 09:01:45 PM: Using BERT model (bert-base-cased).
09/05 09:01:45 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at diagnostic_run_2/my-experiment/pytorch_transformers_cache/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6
09/05 09:01:45 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

09/05 09:01:45 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at diagnostic_run_2/my-experiment/pytorch_transformers_cache/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
09/05 09:01:48 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at diagnostic_run_2/my-experiment/pytorch_transformers_cache/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
09/05 09:01:48 PM: Initializing parameters
09/05 09:01:48 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/05 09:01:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/05 09:01:48 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/05 09:01:48 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/05 09:01:48 PM:    _text_field_embedder.model.pooler.dense.bias
09/05 09:01:48 PM:    _text_field_embedder.model.pooler.dense.weight
09/05 09:01:48 PM: 	Task 'glue-diagnostic' params: {
  "cls_type": "log_reg",
  "d_hid": 512,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 1,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "softmax",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "mnli"
}
09/05 09:01:48 PM: 	Task 'mnli' params: {
  "cls_type": "log_reg",
  "d_hid": 512,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 1,
  "d_hid_attn": 512,
  "dropout": 0.2,
  "cls_loss_fn": "softmax",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "mnli"
}
09/05 09:01:48 PM: Name of the task is different than the classifier it should use
09/05 09:01:48 PM: batch_first = True
09/05 09:01:48 PM: stateful = False
09/05 09:01:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/05 09:01:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/05 09:01:48 PM: input_size = 1536
09/05 09:01:48 PM: hidden_size = 512
09/05 09:01:48 PM: num_layers = 1
09/05 09:01:48 PM: bidirectional = True
09/05 09:01:48 PM: batch_first = True
09/05 09:01:48 PM: Initializing parameters
09/05 09:01:48 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/05 09:01:48 PM:    _modeling_layer._module.bias_hh_l0
09/05 09:01:48 PM:    _modeling_layer._module.bias_hh_l0_reverse
09/05 09:01:48 PM:    _modeling_layer._module.bias_ih_l0
09/05 09:01:48 PM:    _modeling_layer._module.bias_ih_l0_reverse
09/05 09:01:48 PM:    _modeling_layer._module.weight_hh_l0
09/05 09:01:48 PM:    _modeling_layer._module.weight_hh_l0_reverse
09/05 09:01:48 PM:    _modeling_layer._module.weight_ih_l0
09/05 09:01:48 PM:    _modeling_layer._module.weight_ih_l0_reverse
09/05 09:01:52 PM: Model specification:
09/05 09:01:52 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(28996, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.1)
  )
  (mnli_mdl): SingleClassifier(
    (pooler): Pooler()
    (classifier): Classifier(
      (classifier): Linear(in_features=768, out_features=3, bias=True)
    )
  )
)
09/05 09:01:52 PM: Model parameters:
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Trainable parameter, count 22268928 with torch.Size([28996, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Trainable parameter, count 393216 with torch.Size([512, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Trainable parameter, count 1536 with torch.Size([2, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Trainable parameter, count 2359296 with torch.Size([3072, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Trainable parameter, count 3072 with torch.Size([3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Trainable parameter, count 2359296 with torch.Size([768, 3072])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Trainable parameter, count 589824 with torch.Size([768, 768])
09/05 09:01:52 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Trainable parameter, count 768 with torch.Size([768])
09/05 09:01:52 PM: 	mnli_mdl.classifier.classifier.weight: Trainable parameter, count 2304 with torch.Size([3, 768])
09/05 09:01:52 PM: 	mnli_mdl.classifier.classifier.bias: Trainable parameter, count 3 with torch.Size([3])
09/05 09:01:52 PM: Total number of parameters: 108312579 (1.08313e+08)
09/05 09:01:52 PM: Number of trainable parameters: 108312579 (1.08313e+08)
09/05 09:01:52 PM: Finished building model in 6.668s
09/05 09:01:52 PM: Will run the following steps for this experiment:
Training model on tasks: mnli 
Evaluating model on tasks: mnli,glue-diagnostic 

09/05 09:01:52 PM: Training...
09/05 09:01:52 PM: patience = 20
09/05 09:01:52 PM: val_interval = 1000
09/05 09:01:52 PM: max_vals = 10000
09/05 09:01:52 PM: cuda_device = 0
09/05 09:01:52 PM: grad_norm = 5.0
09/05 09:01:52 PM: grad_clipping = None
09/05 09:01:52 PM: lr_decay = 0.99
09/05 09:01:52 PM: min_lr = 1e-07
09/05 09:01:52 PM: keep_all_checkpoints = 0
09/05 09:01:52 PM: val_data_limit = 5000
09/05 09:01:52 PM: max_epochs = 3
09/05 09:01:52 PM: dec_val_scale = 250
09/05 09:01:52 PM: training_data_fraction = 1
09/05 09:01:52 PM: type = bert_adam
09/05 09:01:52 PM: parameter_groups = None
09/05 09:01:52 PM: Number of trainable parameters: 108312579
09/05 09:01:52 PM: infer_type_and_cast = True
09/05 09:01:52 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/05 09:01:52 PM: CURRENTLY DEFINED PARAMETERS: 
09/05 09:01:52 PM: lr = 1e-5
09/05 09:01:52 PM: t_total = 50000
09/05 09:01:52 PM: warmup = 0.1
09/05 09:01:52 PM: type = reduce_on_plateau
09/05 09:01:52 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/05 09:01:52 PM: CURRENTLY DEFINED PARAMETERS: 
09/05 09:01:52 PM: mode = max
09/05 09:01:52 PM: factor = 0.5
09/05 09:01:52 PM: patience = 4
09/05 09:01:52 PM: threshold = 0.0001
09/05 09:01:52 PM: threshold_mode = abs
09/05 09:01:52 PM: verbose = True
09/05 09:01:52 PM: type = bert_adam
09/05 09:01:52 PM: parameter_groups = None
09/05 09:01:52 PM: Number of trainable parameters: 108312579
09/05 09:01:52 PM: infer_type_and_cast = True
09/05 09:01:52 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/05 09:01:52 PM: CURRENTLY DEFINED PARAMETERS: 
09/05 09:01:52 PM: lr = 1e-5
09/05 09:01:52 PM: t_total = 50000
09/05 09:01:52 PM: warmup = 0.1
09/05 09:01:52 PM: type = reduce_on_plateau
09/05 09:01:52 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/05 09:01:52 PM: CURRENTLY DEFINED PARAMETERS: 
09/05 09:01:52 PM: mode = max
09/05 09:01:52 PM: factor = 0.5
09/05 09:01:52 PM: patience = 4
09/05 09:01:52 PM: threshold = 0.0001
09/05 09:01:52 PM: threshold_mode = abs
09/05 09:01:52 PM: verbose = True
09/05 09:01:52 PM: load_model=1 but there is not checkpoint.                         Starting training without restoring from a checkpoint.
09/05 09:01:52 PM: Training examples per task, before any subsampling: {'mnli': 392702}
09/05 09:01:52 PM: Beginning training with stopping criteria based on metric: mnli_accuracy
09/05 09:02:02 PM: Update 15: task mnli, batch 15 (15): accuracy: 0.3239, mnli_loss: 1.1130
09/05 09:02:12 PM: Update 34: task mnli, batch 34 (34): accuracy: 0.3243, mnli_loss: 1.1077
09/05 09:02:22 PM: Update 54: task mnli, batch 54 (54): accuracy: 0.3214, mnli_loss: 1.1118
09/05 09:02:33 PM: Update 74: task mnli, batch 74 (74): accuracy: 0.3218, mnli_loss: 1.1119
09/05 09:02:43 PM: Update 94: task mnli, batch 94 (94): accuracy: 0.3176, mnli_loss: 1.1138
09/05 09:02:53 PM: Update 115: task mnli, batch 115 (115): accuracy: 0.3256, mnli_loss: 1.1109
09/05 09:03:03 PM: Update 135: task mnli, batch 135 (135): accuracy: 0.3246, mnli_loss: 1.1119
09/05 09:03:14 PM: Update 155: task mnli, batch 155 (155): accuracy: 0.3209, mnli_loss: 1.1128
09/05 09:03:24 PM: Update 173: task mnli, batch 173 (173): accuracy: 0.3214, mnli_loss: 1.1119
09/05 09:03:34 PM: Update 192: task mnli, batch 192 (192): accuracy: 0.3237, mnli_loss: 1.1115
09/05 09:03:45 PM: Update 212: task mnli, batch 212 (212): accuracy: 0.3252, mnli_loss: 1.1102
09/05 09:03:55 PM: Update 232: task mnli, batch 232 (232): accuracy: 0.3281, mnli_loss: 1.1093
09/05 09:04:05 PM: Update 250: task mnli, batch 250 (250): accuracy: 0.3288, mnli_loss: 1.1094
09/05 09:04:15 PM: Update 270: task mnli, batch 270 (270): accuracy: 0.3320, mnli_loss: 1.1078
09/05 09:04:26 PM: Update 290: task mnli, batch 290 (290): accuracy: 0.3343, mnli_loss: 1.1065
09/05 09:04:36 PM: Update 310: task mnli, batch 310 (310): accuracy: 0.3365, mnli_loss: 1.1055
09/05 09:04:47 PM: Update 329: task mnli, batch 329 (329): accuracy: 0.3363, mnli_loss: 1.1051
09/05 09:04:57 PM: Update 349: task mnli, batch 349 (349): accuracy: 0.3369, mnli_loss: 1.1048
09/05 09:05:07 PM: Update 369: task mnli, batch 369 (369): accuracy: 0.3393, mnli_loss: 1.1040
09/05 09:05:17 PM: Update 389: task mnli, batch 389 (389): accuracy: 0.3403, mnli_loss: 1.1034
09/05 09:05:27 PM: Update 408: task mnli, batch 408 (408): accuracy: 0.3417, mnli_loss: 1.1026
09/05 09:05:38 PM: Update 424: task mnli, batch 424 (424): accuracy: 0.3437, mnli_loss: 1.1016
09/05 09:05:48 PM: Update 445: task mnli, batch 445 (445): accuracy: 0.3434, mnli_loss: 1.1015
09/05 09:05:59 PM: Update 467: task mnli, batch 467 (467): accuracy: 0.3453, mnli_loss: 1.1009
09/05 09:06:09 PM: Update 486: task mnli, batch 486 (486): accuracy: 0.3480, mnli_loss: 1.0999
09/05 09:06:19 PM: Update 506: task mnli, batch 506 (506): accuracy: 0.3514, mnli_loss: 1.0988
09/05 09:06:29 PM: Update 526: task mnli, batch 526 (526): accuracy: 0.3541, mnli_loss: 1.0975
09/05 09:06:40 PM: Update 546: task mnli, batch 546 (546): accuracy: 0.3581, mnli_loss: 1.0963
09/05 09:06:50 PM: Update 565: task mnli, batch 565 (565): accuracy: 0.3610, mnli_loss: 1.0948
09/05 09:07:00 PM: Update 583: task mnli, batch 583 (583): accuracy: 0.3638, mnli_loss: 1.0937
09/05 09:07:10 PM: Update 603: task mnli, batch 603 (603): accuracy: 0.3663, mnli_loss: 1.0926
09/05 09:07:21 PM: Update 623: task mnli, batch 623 (623): accuracy: 0.3704, mnli_loss: 1.0907
09/05 09:07:31 PM: Update 642: task mnli, batch 642 (642): accuracy: 0.3736, mnli_loss: 1.0890
09/05 09:07:41 PM: Update 661: task mnli, batch 661 (661): accuracy: 0.3763, mnli_loss: 1.0880
09/05 09:07:52 PM: Update 680: task mnli, batch 680 (680): accuracy: 0.3790, mnli_loss: 1.0860
09/05 09:08:02 PM: Update 698: task mnli, batch 698 (698): accuracy: 0.3823, mnli_loss: 1.0841
09/05 09:08:12 PM: Update 717: task mnli, batch 717 (717): accuracy: 0.3854, mnli_loss: 1.0818
09/05 09:08:22 PM: Update 736: task mnli, batch 736 (736): accuracy: 0.3885, mnli_loss: 1.0800
09/05 09:08:33 PM: Update 756: task mnli, batch 756 (756): accuracy: 0.3924, mnli_loss: 1.0776
09/05 09:08:43 PM: Update 776: task mnli, batch 776 (776): accuracy: 0.3960, mnli_loss: 1.0752
09/05 09:08:53 PM: Update 794: task mnli, batch 794 (794): accuracy: 0.4001, mnli_loss: 1.0717
09/05 09:09:04 PM: Update 814: task mnli, batch 814 (814): accuracy: 0.4050, mnli_loss: 1.0683
09/05 09:09:14 PM: Update 833: task mnli, batch 833 (833): accuracy: 0.4083, mnli_loss: 1.0656
09/05 09:09:24 PM: Update 849: task mnli, batch 849 (849): accuracy: 0.4114, mnli_loss: 1.0630
09/05 09:09:34 PM: Update 868: task mnli, batch 868 (868): accuracy: 0.4148, mnli_loss: 1.0594
09/05 09:09:44 PM: Update 886: task mnli, batch 886 (886): accuracy: 0.4177, mnli_loss: 1.0566
09/05 09:09:55 PM: Update 907: task mnli, batch 907 (907): accuracy: 0.4214, mnli_loss: 1.0540
09/05 09:10:05 PM: Update 926: task mnli, batch 926 (926): accuracy: 0.4250, mnli_loss: 1.0508
09/05 09:10:15 PM: Update 945: task mnli, batch 945 (945): accuracy: 0.4274, mnli_loss: 1.0487
09/05 09:10:25 PM: Update 965: task mnli, batch 965 (965): accuracy: 0.4316, mnli_loss: 1.0452
09/05 09:10:35 PM: Update 983: task mnli, batch 983 (983): accuracy: 0.4347, mnli_loss: 1.0422
09/05 09:10:44 PM: ***** Step 1000 / Validation 1 *****
09/05 09:10:44 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:10:44 PM: Validating...
09/05 09:10:45 PM: Evaluate: task mnli, batch 7 (209): accuracy: 0.5714, mnli_loss: 0.9447
09/05 09:10:55 PM: Evaluate: task mnli, batch 57 (209): accuracy: 0.6133, mnli_loss: 0.8792
09/05 09:11:05 PM: Evaluate: task mnli, batch 107 (209): accuracy: 0.6036, mnli_loss: 0.8873
09/05 09:11:16 PM: Evaluate: task mnli, batch 157 (209): accuracy: 0.6032, mnli_loss: 0.8845
09/05 09:11:26 PM: Evaluate: task mnli, batch 207 (209): accuracy: 0.5994, mnli_loss: 0.8889
09/05 09:11:26 PM: Best result seen so far for mnli.
09/05 09:11:26 PM: Best result seen so far for micro.
09/05 09:11:26 PM: Best result seen so far for macro.
09/05 09:11:26 PM: Updating LR scheduler:
09/05 09:11:26 PM: 	Best result seen so far for macro_avg: 0.600
09/05 09:11:26 PM: 	# validation passes without improvement: 0
09/05 09:11:26 PM: mnli_loss: training: 1.040738 validation: 0.889068
09/05 09:11:26 PM: macro_avg: validation: 0.599800
09/05 09:11:26 PM: micro_avg: validation: 0.599800
09/05 09:11:26 PM: mnli_accuracy: training: 0.437104 validation: 0.599800
09/05 09:11:26 PM: Global learning rate: 1e-05
09/05 09:11:26 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 09:11:36 PM: Update 1018: task mnli, batch 18 (1018): accuracy: 0.5671, mnli_loss: 0.8963
09/05 09:11:46 PM: Update 1038: task mnli, batch 38 (1038): accuracy: 0.5855, mnli_loss: 0.8751
09/05 09:11:57 PM: Update 1057: task mnli, batch 57 (1057): accuracy: 0.6009, mnli_loss: 0.8653
09/05 09:12:07 PM: Update 1076: task mnli, batch 76 (1076): accuracy: 0.5976, mnli_loss: 0.8756
09/05 09:12:17 PM: Update 1094: task mnli, batch 94 (1094): accuracy: 0.5935, mnli_loss: 0.8832
09/05 09:12:27 PM: Update 1112: task mnli, batch 112 (1112): accuracy: 0.5904, mnli_loss: 0.8831
09/05 09:12:37 PM: Update 1131: task mnli, batch 131 (1131): accuracy: 0.5916, mnli_loss: 0.8806
09/05 09:12:47 PM: Update 1149: task mnli, batch 149 (1149): accuracy: 0.5926, mnli_loss: 0.8775
09/05 09:12:58 PM: Update 1169: task mnli, batch 169 (1169): accuracy: 0.6006, mnli_loss: 0.8671
09/05 09:13:08 PM: Update 1189: task mnli, batch 189 (1189): accuracy: 0.6025, mnli_loss: 0.8619
09/05 09:13:18 PM: Update 1209: task mnli, batch 209 (1209): accuracy: 0.6051, mnli_loss: 0.8590
09/05 09:13:29 PM: Update 1227: task mnli, batch 227 (1227): accuracy: 0.6050, mnli_loss: 0.8577
09/05 09:13:39 PM: Update 1246: task mnli, batch 246 (1246): accuracy: 0.6060, mnli_loss: 0.8579
09/05 09:13:49 PM: Update 1261: task mnli, batch 261 (1261): accuracy: 0.6066, mnli_loss: 0.8557
09/05 09:13:59 PM: Update 1280: task mnli, batch 280 (1280): accuracy: 0.6065, mnli_loss: 0.8576
09/05 09:14:09 PM: Update 1298: task mnli, batch 298 (1298): accuracy: 0.6095, mnli_loss: 0.8547
09/05 09:14:19 PM: Update 1316: task mnli, batch 316 (1316): accuracy: 0.6101, mnli_loss: 0.8528
09/05 09:14:29 PM: Update 1335: task mnli, batch 335 (1335): accuracy: 0.6106, mnli_loss: 0.8493
09/05 09:14:40 PM: Update 1354: task mnli, batch 354 (1354): accuracy: 0.6103, mnli_loss: 0.8503
09/05 09:14:50 PM: Update 1373: task mnli, batch 373 (1373): accuracy: 0.6116, mnli_loss: 0.8493
09/05 09:15:00 PM: Update 1392: task mnli, batch 392 (1392): accuracy: 0.6123, mnli_loss: 0.8473
09/05 09:15:11 PM: Update 1412: task mnli, batch 412 (1412): accuracy: 0.6145, mnli_loss: 0.8451
09/05 09:15:21 PM: Update 1431: task mnli, batch 431 (1431): accuracy: 0.6154, mnli_loss: 0.8435
09/05 09:15:31 PM: Update 1450: task mnli, batch 450 (1450): accuracy: 0.6160, mnli_loss: 0.8424
09/05 09:15:41 PM: Update 1467: task mnli, batch 467 (1467): accuracy: 0.6186, mnli_loss: 0.8388
09/05 09:15:51 PM: Update 1487: task mnli, batch 487 (1487): accuracy: 0.6206, mnli_loss: 0.8363
09/05 09:16:02 PM: Update 1509: task mnli, batch 509 (1509): accuracy: 0.6204, mnli_loss: 0.8365
09/05 09:16:12 PM: Update 1530: task mnli, batch 530 (1530): accuracy: 0.6213, mnli_loss: 0.8365
09/05 09:16:23 PM: Update 1550: task mnli, batch 550 (1550): accuracy: 0.6230, mnli_loss: 0.8335
09/05 09:16:33 PM: Update 1570: task mnli, batch 570 (1570): accuracy: 0.6230, mnli_loss: 0.8328
09/05 09:16:43 PM: Update 1589: task mnli, batch 589 (1589): accuracy: 0.6230, mnli_loss: 0.8331
09/05 09:16:53 PM: Update 1607: task mnli, batch 607 (1607): accuracy: 0.6248, mnli_loss: 0.8311
09/05 09:17:04 PM: Update 1625: task mnli, batch 625 (1625): accuracy: 0.6267, mnli_loss: 0.8283
09/05 09:17:14 PM: Update 1645: task mnli, batch 645 (1645): accuracy: 0.6269, mnli_loss: 0.8280
09/05 09:17:24 PM: Update 1664: task mnli, batch 664 (1664): accuracy: 0.6276, mnli_loss: 0.8275
09/05 09:17:34 PM: Update 1679: task mnli, batch 679 (1679): accuracy: 0.6284, mnli_loss: 0.8267
09/05 09:17:45 PM: Update 1698: task mnli, batch 698 (1698): accuracy: 0.6285, mnli_loss: 0.8261
09/05 09:17:55 PM: Update 1718: task mnli, batch 718 (1718): accuracy: 0.6299, mnli_loss: 0.8247
09/05 09:18:05 PM: Update 1738: task mnli, batch 738 (1738): accuracy: 0.6303, mnli_loss: 0.8241
09/05 09:18:15 PM: Update 1758: task mnli, batch 758 (1758): accuracy: 0.6319, mnli_loss: 0.8228
09/05 09:18:25 PM: Update 1776: task mnli, batch 776 (1776): accuracy: 0.6325, mnli_loss: 0.8214
09/05 09:18:36 PM: Update 1794: task mnli, batch 794 (1794): accuracy: 0.6331, mnli_loss: 0.8195
09/05 09:18:46 PM: Update 1814: task mnli, batch 814 (1814): accuracy: 0.6342, mnli_loss: 0.8183
09/05 09:18:56 PM: Update 1833: task mnli, batch 833 (1833): accuracy: 0.6340, mnli_loss: 0.8183
09/05 09:19:06 PM: Update 1852: task mnli, batch 852 (1852): accuracy: 0.6349, mnli_loss: 0.8165
09/05 09:19:16 PM: Update 1871: task mnli, batch 871 (1871): accuracy: 0.6360, mnli_loss: 0.8142
09/05 09:19:27 PM: Update 1891: task mnli, batch 891 (1891): accuracy: 0.6366, mnli_loss: 0.8133
09/05 09:19:37 PM: Update 1910: task mnli, batch 910 (1910): accuracy: 0.6367, mnli_loss: 0.8131
09/05 09:19:47 PM: Update 1929: task mnli, batch 929 (1929): accuracy: 0.6369, mnli_loss: 0.8131
09/05 09:19:57 PM: Update 1950: task mnli, batch 950 (1950): accuracy: 0.6365, mnli_loss: 0.8130
09/05 09:20:08 PM: Update 1969: task mnli, batch 969 (1969): accuracy: 0.6375, mnli_loss: 0.8114
09/05 09:20:18 PM: Update 1986: task mnli, batch 986 (1986): accuracy: 0.6375, mnli_loss: 0.8117
09/05 09:20:25 PM: ***** Step 2000 / Validation 2 *****
09/05 09:20:25 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:20:25 PM: Validating...
09/05 09:20:28 PM: Evaluate: task mnli, batch 15 (209): accuracy: 0.6889, mnli_loss: 0.7163
09/05 09:20:38 PM: Evaluate: task mnli, batch 66 (209): accuracy: 0.6824, mnli_loss: 0.7224
09/05 09:20:48 PM: Evaluate: task mnli, batch 116 (209): accuracy: 0.6724, mnli_loss: 0.7349
09/05 09:20:58 PM: Evaluate: task mnli, batch 166 (209): accuracy: 0.6827, mnli_loss: 0.7240
09/05 09:21:07 PM: Best result seen so far for mnli.
09/05 09:21:07 PM: Best result seen so far for micro.
09/05 09:21:07 PM: Best result seen so far for macro.
09/05 09:21:07 PM: Updating LR scheduler:
09/05 09:21:07 PM: 	Best result seen so far for macro_avg: 0.681
09/05 09:21:07 PM: 	# validation passes without improvement: 0
09/05 09:21:07 PM: mnli_loss: training: 0.811086 validation: 0.730914
09/05 09:21:07 PM: macro_avg: validation: 0.681400
09/05 09:21:07 PM: micro_avg: validation: 0.681400
09/05 09:21:07 PM: mnli_accuracy: training: 0.637717 validation: 0.681400
09/05 09:21:07 PM: Global learning rate: 1e-05
09/05 09:21:07 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 09:21:09 PM: Update 2002: task mnli, batch 2 (2002): accuracy: 0.6042, mnli_loss: 0.8450
09/05 09:21:19 PM: Update 2020: task mnli, batch 20 (2020): accuracy: 0.6396, mnli_loss: 0.7678
09/05 09:21:29 PM: Update 2039: task mnli, batch 39 (2039): accuracy: 0.6560, mnli_loss: 0.7645
09/05 09:21:40 PM: Update 2060: task mnli, batch 60 (2060): accuracy: 0.6604, mnli_loss: 0.7598
09/05 09:21:50 PM: Update 2078: task mnli, batch 78 (2078): accuracy: 0.6656, mnli_loss: 0.7530
09/05 09:22:01 PM: Update 2093: task mnli, batch 93 (2093): accuracy: 0.6691, mnli_loss: 0.7526
09/05 09:22:11 PM: Update 2112: task mnli, batch 112 (2112): accuracy: 0.6728, mnli_loss: 0.7503
09/05 09:22:21 PM: Update 2132: task mnli, batch 132 (2132): accuracy: 0.6718, mnli_loss: 0.7494
09/05 09:22:32 PM: Update 2152: task mnli, batch 152 (2152): accuracy: 0.6698, mnli_loss: 0.7527
09/05 09:22:42 PM: Update 2170: task mnli, batch 170 (2170): accuracy: 0.6690, mnli_loss: 0.7565
09/05 09:22:52 PM: Update 2190: task mnli, batch 190 (2190): accuracy: 0.6727, mnli_loss: 0.7491
09/05 09:23:02 PM: Update 2210: task mnli, batch 210 (2210): accuracy: 0.6731, mnli_loss: 0.7480
09/05 09:23:13 PM: Update 2231: task mnli, batch 231 (2231): accuracy: 0.6759, mnli_loss: 0.7438
09/05 09:23:23 PM: Update 2249: task mnli, batch 249 (2249): accuracy: 0.6771, mnli_loss: 0.7428
09/05 09:23:33 PM: Update 2267: task mnli, batch 267 (2267): accuracy: 0.6758, mnli_loss: 0.7461
09/05 09:23:44 PM: Update 2286: task mnli, batch 286 (2286): accuracy: 0.6771, mnli_loss: 0.7447
09/05 09:23:54 PM: Update 2306: task mnli, batch 306 (2306): accuracy: 0.6801, mnli_loss: 0.7414
09/05 09:24:04 PM: Update 2325: task mnli, batch 325 (2325): accuracy: 0.6842, mnli_loss: 0.7362
09/05 09:24:14 PM: Update 2344: task mnli, batch 344 (2344): accuracy: 0.6836, mnli_loss: 0.7363
09/05 09:24:25 PM: Update 2363: task mnli, batch 363 (2363): accuracy: 0.6828, mnli_loss: 0.7394
09/05 09:24:35 PM: Update 2382: task mnli, batch 382 (2382): accuracy: 0.6852, mnli_loss: 0.7340
09/05 09:24:45 PM: Update 2402: task mnli, batch 402 (2402): accuracy: 0.6876, mnli_loss: 0.7298
09/05 09:24:55 PM: Update 2421: task mnli, batch 421 (2421): accuracy: 0.6865, mnli_loss: 0.7317
09/05 09:25:06 PM: Update 2440: task mnli, batch 440 (2440): accuracy: 0.6854, mnli_loss: 0.7328
09/05 09:25:16 PM: Update 2459: task mnli, batch 459 (2459): accuracy: 0.6866, mnli_loss: 0.7325
09/05 09:25:26 PM: Update 2478: task mnli, batch 478 (2478): accuracy: 0.6855, mnli_loss: 0.7336
09/05 09:25:36 PM: Update 2499: task mnli, batch 499 (2499): accuracy: 0.6857, mnli_loss: 0.7320
09/05 09:25:46 PM: Update 2514: task mnli, batch 514 (2514): accuracy: 0.6845, mnli_loss: 0.7340
09/05 09:25:57 PM: Update 2534: task mnli, batch 534 (2534): accuracy: 0.6859, mnli_loss: 0.7314
09/05 09:26:07 PM: Update 2553: task mnli, batch 553 (2553): accuracy: 0.6853, mnli_loss: 0.7305
09/05 09:26:17 PM: Update 2573: task mnli, batch 573 (2573): accuracy: 0.6852, mnli_loss: 0.7304
09/05 09:26:28 PM: Update 2592: task mnli, batch 592 (2592): accuracy: 0.6858, mnli_loss: 0.7303
09/05 09:26:38 PM: Update 2610: task mnli, batch 610 (2610): accuracy: 0.6852, mnli_loss: 0.7317
09/05 09:26:48 PM: Update 2629: task mnli, batch 629 (2629): accuracy: 0.6871, mnli_loss: 0.7282
09/05 09:26:58 PM: Update 2649: task mnli, batch 649 (2649): accuracy: 0.6885, mnli_loss: 0.7257
09/05 09:27:09 PM: Update 2669: task mnli, batch 669 (2669): accuracy: 0.6892, mnli_loss: 0.7245
09/05 09:27:19 PM: Update 2689: task mnli, batch 689 (2689): accuracy: 0.6894, mnli_loss: 0.7240
09/05 09:27:30 PM: Update 2706: task mnli, batch 706 (2706): accuracy: 0.6896, mnli_loss: 0.7235
09/05 09:27:40 PM: Update 2724: task mnli, batch 724 (2724): accuracy: 0.6904, mnli_loss: 0.7234
09/05 09:27:50 PM: Update 2743: task mnli, batch 743 (2743): accuracy: 0.6894, mnli_loss: 0.7239
09/05 09:28:00 PM: Update 2762: task mnli, batch 762 (2762): accuracy: 0.6903, mnli_loss: 0.7228
09/05 09:28:11 PM: Update 2781: task mnli, batch 781 (2781): accuracy: 0.6905, mnli_loss: 0.7227
09/05 09:28:21 PM: Update 2801: task mnli, batch 801 (2801): accuracy: 0.6900, mnli_loss: 0.7237
09/05 09:28:32 PM: Update 2820: task mnli, batch 820 (2820): accuracy: 0.6906, mnli_loss: 0.7228
09/05 09:28:42 PM: Update 2841: task mnli, batch 841 (2841): accuracy: 0.6913, mnli_loss: 0.7230
09/05 09:28:52 PM: Update 2860: task mnli, batch 860 (2860): accuracy: 0.6920, mnli_loss: 0.7217
09/05 09:29:02 PM: Update 2880: task mnli, batch 880 (2880): accuracy: 0.6917, mnli_loss: 0.7223
09/05 09:29:13 PM: Update 2899: task mnli, batch 899 (2899): accuracy: 0.6921, mnli_loss: 0.7215
09/05 09:29:23 PM: Update 2918: task mnli, batch 918 (2918): accuracy: 0.6915, mnli_loss: 0.7230
09/05 09:29:33 PM: Update 2934: task mnli, batch 934 (2934): accuracy: 0.6917, mnli_loss: 0.7229
09/05 09:29:43 PM: Update 2951: task mnli, batch 951 (2951): accuracy: 0.6913, mnli_loss: 0.7231
09/05 09:29:54 PM: Update 2969: task mnli, batch 969 (2969): accuracy: 0.6911, mnli_loss: 0.7230
09/05 09:30:04 PM: Update 2987: task mnli, batch 987 (2987): accuracy: 0.6915, mnli_loss: 0.7226
09/05 09:30:11 PM: ***** Step 3000 / Validation 3 *****
09/05 09:30:11 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:30:11 PM: Validating...
09/05 09:30:14 PM: Evaluate: task mnli, batch 17 (209): accuracy: 0.7157, mnli_loss: 0.6721
09/05 09:30:24 PM: Evaluate: task mnli, batch 67 (209): accuracy: 0.7195, mnli_loss: 0.6649
09/05 09:30:34 PM: Evaluate: task mnli, batch 117 (209): accuracy: 0.7108, mnli_loss: 0.6802
09/05 09:30:45 PM: Evaluate: task mnli, batch 167 (209): accuracy: 0.7173, mnli_loss: 0.6698
09/05 09:30:53 PM: Best result seen so far for mnli.
09/05 09:30:53 PM: Best result seen so far for micro.
09/05 09:30:53 PM: Best result seen so far for macro.
09/05 09:30:53 PM: Updating LR scheduler:
09/05 09:30:53 PM: 	Best result seen so far for macro_avg: 0.714
09/05 09:30:53 PM: 	# validation passes without improvement: 0
09/05 09:30:53 PM: mnli_loss: training: 0.721676 validation: 0.674097
09/05 09:30:53 PM: macro_avg: validation: 0.714200
09/05 09:30:53 PM: micro_avg: validation: 0.714200
09/05 09:30:53 PM: mnli_accuracy: training: 0.691942 validation: 0.714200
09/05 09:30:53 PM: Global learning rate: 1e-05
09/05 09:30:53 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 09:30:55 PM: Update 3002: task mnli, batch 2 (3002): accuracy: 0.7708, mnli_loss: 0.6752
09/05 09:31:05 PM: Update 3023: task mnli, batch 23 (3023): accuracy: 0.7210, mnli_loss: 0.6732
09/05 09:31:16 PM: Update 3043: task mnli, batch 43 (3043): accuracy: 0.7103, mnli_loss: 0.6825
09/05 09:31:26 PM: Update 3062: task mnli, batch 62 (3062): accuracy: 0.6962, mnli_loss: 0.6915
09/05 09:31:36 PM: Update 3081: task mnli, batch 81 (3081): accuracy: 0.6996, mnli_loss: 0.6968
09/05 09:31:46 PM: Update 3100: task mnli, batch 100 (3100): accuracy: 0.7058, mnli_loss: 0.6884
09/05 09:31:57 PM: Update 3119: task mnli, batch 119 (3119): accuracy: 0.7059, mnli_loss: 0.6927
09/05 09:32:07 PM: Update 3141: task mnli, batch 141 (3141): accuracy: 0.7069, mnli_loss: 0.6877
09/05 09:32:17 PM: Update 3160: task mnli, batch 160 (3160): accuracy: 0.7076, mnli_loss: 0.6892
09/05 09:32:27 PM: Update 3181: task mnli, batch 181 (3181): accuracy: 0.7097, mnli_loss: 0.6892
09/05 09:32:37 PM: Update 3199: task mnli, batch 199 (3199): accuracy: 0.7073, mnli_loss: 0.6880
09/05 09:32:48 PM: Update 3219: task mnli, batch 219 (3219): accuracy: 0.7081, mnli_loss: 0.6891
09/05 09:32:58 PM: Update 3238: task mnli, batch 238 (3238): accuracy: 0.7096, mnli_loss: 0.6877
09/05 09:33:08 PM: Update 3259: task mnli, batch 259 (3259): accuracy: 0.7075, mnli_loss: 0.6885
09/05 09:33:19 PM: Update 3279: task mnli, batch 279 (3279): accuracy: 0.7053, mnli_loss: 0.6931
09/05 09:33:29 PM: Update 3296: task mnli, batch 296 (3296): accuracy: 0.7055, mnli_loss: 0.6915
09/05 09:33:39 PM: Update 3314: task mnli, batch 314 (3314): accuracy: 0.7075, mnli_loss: 0.6908
09/05 09:33:49 PM: Update 3332: task mnli, batch 332 (3332): accuracy: 0.7059, mnli_loss: 0.6908
09/05 09:33:59 PM: Update 3347: task mnli, batch 347 (3347): accuracy: 0.7064, mnli_loss: 0.6914
09/05 09:34:10 PM: Update 3366: task mnli, batch 366 (3366): accuracy: 0.7060, mnli_loss: 0.6932
09/05 09:34:20 PM: Update 3385: task mnli, batch 385 (3385): accuracy: 0.7058, mnli_loss: 0.6922
09/05 09:34:31 PM: Update 3404: task mnli, batch 404 (3404): accuracy: 0.7053, mnli_loss: 0.6945
09/05 09:34:41 PM: Update 3422: task mnli, batch 422 (3422): accuracy: 0.7072, mnli_loss: 0.6921
09/05 09:34:51 PM: Update 3443: task mnli, batch 443 (3443): accuracy: 0.7079, mnli_loss: 0.6919
09/05 09:35:02 PM: Update 3464: task mnli, batch 464 (3464): accuracy: 0.7079, mnli_loss: 0.6910
09/05 09:35:12 PM: Update 3484: task mnli, batch 484 (3484): accuracy: 0.7093, mnli_loss: 0.6896
09/05 09:35:23 PM: Update 3502: task mnli, batch 502 (3502): accuracy: 0.7086, mnli_loss: 0.6921
09/05 09:35:33 PM: Update 3523: task mnli, batch 523 (3523): accuracy: 0.7085, mnli_loss: 0.6925
09/05 09:35:44 PM: Update 3543: task mnli, batch 543 (3543): accuracy: 0.7099, mnli_loss: 0.6906
09/05 09:35:54 PM: Update 3562: task mnli, batch 562 (3562): accuracy: 0.7112, mnli_loss: 0.6890
09/05 09:36:04 PM: Update 3582: task mnli, batch 582 (3582): accuracy: 0.7122, mnli_loss: 0.6879
09/05 09:36:14 PM: Update 3602: task mnli, batch 602 (3602): accuracy: 0.7130, mnli_loss: 0.6862
09/05 09:36:24 PM: Update 3619: task mnli, batch 619 (3619): accuracy: 0.7127, mnli_loss: 0.6856
09/05 09:36:35 PM: Update 3639: task mnli, batch 639 (3639): accuracy: 0.7133, mnli_loss: 0.6846
09/05 09:36:45 PM: Update 3658: task mnli, batch 658 (3658): accuracy: 0.7140, mnli_loss: 0.6833
09/05 09:36:55 PM: Update 3677: task mnli, batch 677 (3677): accuracy: 0.7148, mnli_loss: 0.6820
09/05 09:37:06 PM: Update 3697: task mnli, batch 697 (3697): accuracy: 0.7147, mnli_loss: 0.6817
09/05 09:37:16 PM: Update 3715: task mnli, batch 715 (3715): accuracy: 0.7143, mnli_loss: 0.6821
09/05 09:37:26 PM: Update 3734: task mnli, batch 734 (3734): accuracy: 0.7141, mnli_loss: 0.6822
09/05 09:37:38 PM: Update 3754: task mnli, batch 754 (3754): accuracy: 0.7142, mnli_loss: 0.6812
09/05 09:37:49 PM: Update 3772: task mnli, batch 772 (3772): accuracy: 0.7150, mnli_loss: 0.6797
09/05 09:37:59 PM: Update 3791: task mnli, batch 791 (3791): accuracy: 0.7148, mnli_loss: 0.6794
09/05 09:38:10 PM: Update 3810: task mnli, batch 810 (3810): accuracy: 0.7150, mnli_loss: 0.6798
09/05 09:38:20 PM: Update 3828: task mnli, batch 828 (3828): accuracy: 0.7153, mnli_loss: 0.6794
09/05 09:38:30 PM: Update 3848: task mnli, batch 848 (3848): accuracy: 0.7161, mnli_loss: 0.6783
09/05 09:38:41 PM: Update 3867: task mnli, batch 867 (3867): accuracy: 0.7169, mnli_loss: 0.6768
09/05 09:38:51 PM: Update 3888: task mnli, batch 888 (3888): accuracy: 0.7181, mnli_loss: 0.6754
09/05 09:39:01 PM: Update 3906: task mnli, batch 906 (3906): accuracy: 0.7174, mnli_loss: 0.6764
09/05 09:39:11 PM: Update 3926: task mnli, batch 926 (3926): accuracy: 0.7176, mnli_loss: 0.6763
09/05 09:39:21 PM: Update 3945: task mnli, batch 945 (3945): accuracy: 0.7178, mnli_loss: 0.6762
09/05 09:39:32 PM: Update 3965: task mnli, batch 965 (3965): accuracy: 0.7189, mnli_loss: 0.6740
09/05 09:39:42 PM: Update 3982: task mnli, batch 982 (3982): accuracy: 0.7185, mnli_loss: 0.6746
09/05 09:39:52 PM: ***** Step 4000 / Validation 4 *****
09/05 09:39:52 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:39:52 PM: Validating...
09/05 09:39:52 PM: Evaluate: task mnli, batch 2 (209): accuracy: 0.6458, mnli_loss: 0.7682
09/05 09:40:02 PM: Evaluate: task mnli, batch 52 (209): accuracy: 0.7372, mnli_loss: 0.6144
09/05 09:40:12 PM: Evaluate: task mnli, batch 101 (209): accuracy: 0.7384, mnli_loss: 0.6221
09/05 09:40:22 PM: Evaluate: task mnli, batch 150 (209): accuracy: 0.7378, mnli_loss: 0.6253
09/05 09:40:32 PM: Evaluate: task mnli, batch 199 (209): accuracy: 0.7410, mnli_loss: 0.6245
09/05 09:40:34 PM: Best result seen so far for mnli.
09/05 09:40:34 PM: Best result seen so far for micro.
09/05 09:40:34 PM: Best result seen so far for macro.
09/05 09:40:34 PM: Updating LR scheduler:
09/05 09:40:34 PM: 	Best result seen so far for macro_avg: 0.739
09/05 09:40:34 PM: 	# validation passes without improvement: 0
09/05 09:40:34 PM: mnli_loss: training: 0.673733 validation: 0.626414
09/05 09:40:34 PM: macro_avg: validation: 0.739400
09/05 09:40:34 PM: micro_avg: validation: 0.739400
09/05 09:40:34 PM: mnli_accuracy: training: 0.718979 validation: 0.739400
09/05 09:40:34 PM: Global learning rate: 1e-05
09/05 09:40:34 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 09:40:42 PM: Update 4014: task mnli, batch 14 (4014): accuracy: 0.7054, mnli_loss: 0.6736
09/05 09:40:53 PM: Update 4034: task mnli, batch 34 (4034): accuracy: 0.7230, mnli_loss: 0.6672
09/05 09:41:03 PM: Update 4053: task mnli, batch 53 (4053): accuracy: 0.7327, mnli_loss: 0.6528
09/05 09:41:13 PM: Update 4072: task mnli, batch 72 (4072): accuracy: 0.7315, mnli_loss: 0.6457
09/05 09:41:23 PM: Update 4091: task mnli, batch 91 (4091): accuracy: 0.7363, mnli_loss: 0.6350
09/05 09:41:33 PM: Update 4110: task mnli, batch 110 (4110): accuracy: 0.7352, mnli_loss: 0.6441
09/05 09:41:44 PM: Update 4129: task mnli, batch 129 (4129): accuracy: 0.7335, mnli_loss: 0.6464
09/05 09:41:54 PM: Update 4149: task mnli, batch 149 (4149): accuracy: 0.7307, mnli_loss: 0.6498
09/05 09:42:04 PM: Update 4170: task mnli, batch 170 (4170): accuracy: 0.7282, mnli_loss: 0.6476
09/05 09:42:15 PM: Update 4185: task mnli, batch 185 (4185): accuracy: 0.7281, mnli_loss: 0.6457
09/05 09:42:25 PM: Update 4206: task mnli, batch 206 (4206): accuracy: 0.7328, mnli_loss: 0.6426
09/05 09:42:36 PM: Update 4225: task mnli, batch 225 (4225): accuracy: 0.7328, mnli_loss: 0.6432
09/05 09:42:46 PM: Update 4244: task mnli, batch 244 (4244): accuracy: 0.7326, mnli_loss: 0.6436
09/05 09:42:56 PM: Update 4263: task mnli, batch 263 (4263): accuracy: 0.7316, mnli_loss: 0.6442
09/05 09:43:06 PM: Update 4283: task mnli, batch 283 (4283): accuracy: 0.7332, mnli_loss: 0.6414
09/05 09:43:17 PM: Update 4302: task mnli, batch 302 (4302): accuracy: 0.7316, mnli_loss: 0.6454
09/05 09:43:27 PM: Update 4320: task mnli, batch 320 (4320): accuracy: 0.7316, mnli_loss: 0.6471
09/05 09:43:38 PM: Update 4341: task mnli, batch 341 (4341): accuracy: 0.7320, mnli_loss: 0.6475
09/05 09:43:48 PM: Update 4361: task mnli, batch 361 (4361): accuracy: 0.7322, mnli_loss: 0.6482
09/05 09:43:59 PM: Update 4383: task mnli, batch 383 (4383): accuracy: 0.7319, mnli_loss: 0.6502
09/05 09:44:09 PM: Update 4401: task mnli, batch 401 (4401): accuracy: 0.7299, mnli_loss: 0.6528
09/05 09:44:19 PM: Update 4418: task mnli, batch 418 (4418): accuracy: 0.7293, mnli_loss: 0.6537
09/05 09:44:30 PM: Update 4437: task mnli, batch 437 (4437): accuracy: 0.7284, mnli_loss: 0.6549
09/05 09:44:40 PM: Update 4456: task mnli, batch 456 (4456): accuracy: 0.7302, mnli_loss: 0.6541
09/05 09:44:50 PM: Update 4474: task mnli, batch 474 (4474): accuracy: 0.7289, mnli_loss: 0.6568
09/05 09:45:01 PM: Update 4495: task mnli, batch 495 (4495): accuracy: 0.7291, mnli_loss: 0.6556
09/05 09:45:11 PM: Update 4513: task mnli, batch 513 (4513): accuracy: 0.7298, mnli_loss: 0.6545
09/05 09:45:21 PM: Update 4533: task mnli, batch 533 (4533): accuracy: 0.7305, mnli_loss: 0.6517
09/05 09:45:32 PM: Update 4552: task mnli, batch 552 (4552): accuracy: 0.7313, mnli_loss: 0.6507
09/05 09:45:42 PM: Update 4572: task mnli, batch 572 (4572): accuracy: 0.7326, mnli_loss: 0.6488
09/05 09:45:53 PM: Update 4588: task mnli, batch 588 (4588): accuracy: 0.7323, mnli_loss: 0.6507
09/05 09:46:03 PM: Update 4605: task mnli, batch 605 (4605): accuracy: 0.7315, mnli_loss: 0.6513
09/05 09:46:14 PM: Update 4625: task mnli, batch 625 (4625): accuracy: 0.7326, mnli_loss: 0.6496
09/05 09:46:24 PM: Update 4647: task mnli, batch 647 (4647): accuracy: 0.7325, mnli_loss: 0.6496
09/05 09:46:34 PM: Update 4667: task mnli, batch 667 (4667): accuracy: 0.7336, mnli_loss: 0.6475
09/05 09:46:45 PM: Update 4685: task mnli, batch 685 (4685): accuracy: 0.7340, mnli_loss: 0.6458
09/05 09:46:55 PM: Update 4706: task mnli, batch 706 (4706): accuracy: 0.7343, mnli_loss: 0.6463
09/05 09:47:05 PM: Update 4725: task mnli, batch 725 (4725): accuracy: 0.7344, mnli_loss: 0.6464
09/05 09:47:16 PM: Update 4743: task mnli, batch 743 (4743): accuracy: 0.7342, mnli_loss: 0.6462
09/05 09:47:26 PM: Update 4761: task mnli, batch 761 (4761): accuracy: 0.7336, mnli_loss: 0.6472
09/05 09:47:36 PM: Update 4780: task mnli, batch 780 (4780): accuracy: 0.7341, mnli_loss: 0.6459
09/05 09:47:46 PM: Update 4799: task mnli, batch 799 (4799): accuracy: 0.7342, mnli_loss: 0.6448
09/05 09:47:56 PM: Update 4819: task mnli, batch 819 (4819): accuracy: 0.7339, mnli_loss: 0.6455
09/05 09:48:06 PM: Update 4838: task mnli, batch 838 (4838): accuracy: 0.7334, mnli_loss: 0.6465
09/05 09:48:17 PM: Update 4858: task mnli, batch 858 (4858): accuracy: 0.7338, mnli_loss: 0.6465
09/05 09:48:27 PM: Update 4877: task mnli, batch 877 (4877): accuracy: 0.7337, mnli_loss: 0.6464
09/05 09:48:38 PM: Update 4897: task mnli, batch 897 (4897): accuracy: 0.7345, mnli_loss: 0.6452
09/05 09:48:49 PM: Update 4916: task mnli, batch 916 (4916): accuracy: 0.7342, mnli_loss: 0.6461
09/05 09:48:59 PM: Update 4935: task mnli, batch 935 (4935): accuracy: 0.7340, mnli_loss: 0.6457
09/05 09:49:09 PM: Update 4954: task mnli, batch 954 (4954): accuracy: 0.7342, mnli_loss: 0.6452
09/05 09:49:20 PM: Update 4973: task mnli, batch 973 (4973): accuracy: 0.7329, mnli_loss: 0.6473
09/05 09:49:30 PM: Update 4993: task mnli, batch 993 (4993): accuracy: 0.7324, mnli_loss: 0.6480
09/05 09:49:34 PM: ***** Step 5000 / Validation 5 *****
09/05 09:49:34 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:49:34 PM: Validating...
09/05 09:49:40 PM: Evaluate: task mnli, batch 32 (209): accuracy: 0.7383, mnli_loss: 0.5992
09/05 09:49:51 PM: Evaluate: task mnli, batch 82 (209): accuracy: 0.7525, mnli_loss: 0.5771
09/05 09:50:01 PM: Evaluate: task mnli, batch 132 (209): accuracy: 0.7453, mnli_loss: 0.5931
09/05 09:50:11 PM: Evaluate: task mnli, batch 181 (209): accuracy: 0.7516, mnli_loss: 0.5838
09/05 09:50:16 PM: Best result seen so far for mnli.
09/05 09:50:16 PM: Best result seen so far for micro.
09/05 09:50:16 PM: Best result seen so far for macro.
09/05 09:50:16 PM: Updating LR scheduler:
09/05 09:50:16 PM: 	Best result seen so far for macro_avg: 0.749
09/05 09:50:16 PM: 	# validation passes without improvement: 0
09/05 09:50:16 PM: mnli_loss: training: 0.647191 validation: 0.591342
09/05 09:50:16 PM: macro_avg: validation: 0.749200
09/05 09:50:16 PM: micro_avg: validation: 0.749200
09/05 09:50:16 PM: mnli_accuracy: training: 0.732947 validation: 0.749200
09/05 09:50:16 PM: Global learning rate: 1e-05
09/05 09:50:16 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 09:50:22 PM: Update 5005: task mnli, batch 5 (5005): accuracy: 0.7321, mnli_loss: 0.6377
09/05 09:50:32 PM: Update 5024: task mnli, batch 24 (5024): accuracy: 0.7377, mnli_loss: 0.6173
09/05 09:50:43 PM: Update 5044: task mnli, batch 44 (5044): accuracy: 0.7366, mnli_loss: 0.6251
09/05 09:50:53 PM: Update 5064: task mnli, batch 64 (5064): accuracy: 0.7304, mnli_loss: 0.6435
09/05 09:51:04 PM: Update 5085: task mnli, batch 85 (5085): accuracy: 0.7416, mnli_loss: 0.6233
09/05 09:51:14 PM: Update 5104: task mnli, batch 104 (5104): accuracy: 0.7387, mnli_loss: 0.6344
09/05 09:51:24 PM: Update 5122: task mnli, batch 122 (5122): accuracy: 0.7356, mnli_loss: 0.6334
09/05 09:51:34 PM: Update 5142: task mnli, batch 142 (5142): accuracy: 0.7409, mnli_loss: 0.6227
09/05 09:51:44 PM: Update 5160: task mnli, batch 160 (5160): accuracy: 0.7416, mnli_loss: 0.6250
09/05 09:51:54 PM: Update 5179: task mnli, batch 179 (5179): accuracy: 0.7418, mnli_loss: 0.6269
09/05 09:52:05 PM: Update 5198: task mnli, batch 198 (5198): accuracy: 0.7386, mnli_loss: 0.6347
09/05 09:52:15 PM: Update 5217: task mnli, batch 217 (5217): accuracy: 0.7367, mnli_loss: 0.6346
09/05 09:52:26 PM: Update 5239: task mnli, batch 239 (5239): accuracy: 0.7371, mnli_loss: 0.6340
09/05 09:52:36 PM: Update 5256: task mnli, batch 256 (5256): accuracy: 0.7339, mnli_loss: 0.6393
09/05 09:52:46 PM: Update 5274: task mnli, batch 274 (5274): accuracy: 0.7363, mnli_loss: 0.6349
09/05 09:52:56 PM: Update 5294: task mnli, batch 294 (5294): accuracy: 0.7385, mnli_loss: 0.6314
09/05 09:53:06 PM: Update 5313: task mnli, batch 313 (5313): accuracy: 0.7376, mnli_loss: 0.6308
09/05 09:53:16 PM: Update 5331: task mnli, batch 331 (5331): accuracy: 0.7371, mnli_loss: 0.6322
09/05 09:53:27 PM: Update 5350: task mnli, batch 350 (5350): accuracy: 0.7377, mnli_loss: 0.6307
09/05 09:53:37 PM: Update 5369: task mnli, batch 369 (5369): accuracy: 0.7378, mnli_loss: 0.6306
09/05 09:53:47 PM: Update 5387: task mnli, batch 387 (5387): accuracy: 0.7375, mnli_loss: 0.6321
09/05 09:53:58 PM: Update 5408: task mnli, batch 408 (5408): accuracy: 0.7373, mnli_loss: 0.6311
09/05 09:54:09 PM: Update 5423: task mnli, batch 423 (5423): accuracy: 0.7384, mnli_loss: 0.6306
09/05 09:54:19 PM: Update 5442: task mnli, batch 442 (5442): accuracy: 0.7381, mnli_loss: 0.6309
09/05 09:54:29 PM: Update 5460: task mnli, batch 460 (5460): accuracy: 0.7383, mnli_loss: 0.6303
09/05 09:54:39 PM: Update 5479: task mnli, batch 479 (5479): accuracy: 0.7390, mnli_loss: 0.6294
09/05 09:54:50 PM: Update 5499: task mnli, batch 499 (5499): accuracy: 0.7372, mnli_loss: 0.6306
09/05 09:55:00 PM: Update 5519: task mnli, batch 519 (5519): accuracy: 0.7381, mnli_loss: 0.6294
09/05 09:55:10 PM: Update 5538: task mnli, batch 538 (5538): accuracy: 0.7379, mnli_loss: 0.6280
09/05 09:55:20 PM: Update 5558: task mnli, batch 558 (5558): accuracy: 0.7374, mnli_loss: 0.6283
09/05 09:55:31 PM: Update 5579: task mnli, batch 579 (5579): accuracy: 0.7389, mnli_loss: 0.6269
09/05 09:55:41 PM: Update 5600: task mnli, batch 600 (5600): accuracy: 0.7382, mnli_loss: 0.6287
09/05 09:55:51 PM: Update 5619: task mnli, batch 619 (5619): accuracy: 0.7377, mnli_loss: 0.6284
09/05 09:56:02 PM: Update 5637: task mnli, batch 637 (5637): accuracy: 0.7372, mnli_loss: 0.6297
09/05 09:56:12 PM: Update 5658: task mnli, batch 658 (5658): accuracy: 0.7382, mnli_loss: 0.6277
09/05 09:56:22 PM: Update 5677: task mnli, batch 677 (5677): accuracy: 0.7390, mnli_loss: 0.6263
09/05 09:56:33 PM: Update 5694: task mnli, batch 694 (5694): accuracy: 0.7385, mnli_loss: 0.6268
09/05 09:56:43 PM: Update 5713: task mnli, batch 713 (5713): accuracy: 0.7391, mnli_loss: 0.6256
09/05 09:56:53 PM: Update 5732: task mnli, batch 732 (5732): accuracy: 0.7397, mnli_loss: 0.6245
09/05 09:57:04 PM: Update 5751: task mnli, batch 751 (5751): accuracy: 0.7405, mnli_loss: 0.6232
09/05 09:57:14 PM: Update 5769: task mnli, batch 769 (5769): accuracy: 0.7407, mnli_loss: 0.6229
09/05 09:57:24 PM: Update 5788: task mnli, batch 788 (5788): accuracy: 0.7414, mnli_loss: 0.6219
09/05 09:57:34 PM: Update 5806: task mnli, batch 806 (5806): accuracy: 0.7416, mnli_loss: 0.6224
09/05 09:57:44 PM: Update 5827: task mnli, batch 827 (5827): accuracy: 0.7422, mnli_loss: 0.6210
09/05 09:57:55 PM: Update 5841: task mnli, batch 841 (5841): accuracy: 0.7421, mnli_loss: 0.6219
09/05 09:58:05 PM: Update 5861: task mnli, batch 861 (5861): accuracy: 0.7429, mnli_loss: 0.6203
09/05 09:58:15 PM: Update 5880: task mnli, batch 880 (5880): accuracy: 0.7432, mnli_loss: 0.6200
09/05 09:58:25 PM: Update 5899: task mnli, batch 899 (5899): accuracy: 0.7429, mnli_loss: 0.6201
09/05 09:58:36 PM: Update 5918: task mnli, batch 918 (5918): accuracy: 0.7434, mnli_loss: 0.6186
09/05 09:58:46 PM: Update 5937: task mnli, batch 937 (5937): accuracy: 0.7430, mnli_loss: 0.6189
09/05 09:58:56 PM: Update 5956: task mnli, batch 956 (5956): accuracy: 0.7431, mnli_loss: 0.6191
09/05 09:59:06 PM: Update 5976: task mnli, batch 976 (5976): accuracy: 0.7432, mnli_loss: 0.6189
09/05 09:59:17 PM: Update 5997: task mnli, batch 997 (5997): accuracy: 0.7440, mnli_loss: 0.6174
09/05 09:59:18 PM: ***** Step 6000 / Validation 6 *****
09/05 09:59:18 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 09:59:18 PM: Validating...
09/05 09:59:27 PM: Evaluate: task mnli, batch 43 (209): accuracy: 0.7626, mnli_loss: 0.5624
09/05 09:59:37 PM: Evaluate: task mnli, batch 93 (209): accuracy: 0.7693, mnli_loss: 0.5705
09/05 09:59:47 PM: Evaluate: task mnli, batch 143 (209): accuracy: 0.7646, mnli_loss: 0.5756
09/05 09:59:57 PM: Evaluate: task mnli, batch 192 (209): accuracy: 0.7719, mnli_loss: 0.5700
09/05 10:00:00 PM: Best result seen so far for mnli.
09/05 10:00:00 PM: Best result seen so far for micro.
09/05 10:00:00 PM: Best result seen so far for macro.
09/05 10:00:00 PM: Updating LR scheduler:
09/05 10:00:00 PM: 	Best result seen so far for macro_avg: 0.770
09/05 10:00:00 PM: 	# validation passes without improvement: 0
09/05 10:00:00 PM: mnli_loss: training: 0.617312 validation: 0.577415
09/05 10:00:00 PM: macro_avg: validation: 0.770000
09/05 10:00:00 PM: micro_avg: validation: 0.770000
09/05 10:00:00 PM: mnli_accuracy: training: 0.744119 validation: 0.770000
09/05 10:00:00 PM: Global learning rate: 1e-05
09/05 10:00:00 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:00:07 PM: Update 6011: task mnli, batch 11 (6011): accuracy: 0.7235, mnli_loss: 0.6543
09/05 10:00:18 PM: Update 6029: task mnli, batch 29 (6029): accuracy: 0.7213, mnli_loss: 0.6438
09/05 10:00:28 PM: Update 6049: task mnli, batch 49 (6049): accuracy: 0.7202, mnli_loss: 0.6480
09/05 10:00:38 PM: Update 6069: task mnli, batch 69 (6069): accuracy: 0.7343, mnli_loss: 0.6251
09/05 10:00:48 PM: Update 6087: task mnli, batch 87 (6087): accuracy: 0.7438, mnli_loss: 0.6051
09/05 10:00:58 PM: Update 6106: task mnli, batch 106 (6106): accuracy: 0.7453, mnli_loss: 0.6055
09/05 10:01:08 PM: Update 6127: task mnli, batch 127 (6127): accuracy: 0.7467, mnli_loss: 0.6022
09/05 10:01:19 PM: Update 6147: task mnli, batch 147 (6147): accuracy: 0.7477, mnli_loss: 0.6023
09/05 10:01:29 PM: Update 6167: task mnli, batch 167 (6167): accuracy: 0.7522, mnli_loss: 0.5948
09/05 10:01:39 PM: Update 6185: task mnli, batch 185 (6185): accuracy: 0.7520, mnli_loss: 0.5947
09/05 10:01:49 PM: Update 6204: task mnli, batch 204 (6204): accuracy: 0.7531, mnli_loss: 0.5954
09/05 10:02:00 PM: Update 6222: task mnli, batch 222 (6222): accuracy: 0.7538, mnli_loss: 0.5952
09/05 10:02:10 PM: Update 6240: task mnli, batch 240 (6240): accuracy: 0.7562, mnli_loss: 0.5950
09/05 10:02:21 PM: Update 6256: task mnli, batch 256 (6256): accuracy: 0.7559, mnli_loss: 0.5944
09/05 10:02:31 PM: Update 6274: task mnli, batch 274 (6274): accuracy: 0.7567, mnli_loss: 0.5917
09/05 10:02:42 PM: Update 6294: task mnli, batch 294 (6294): accuracy: 0.7554, mnli_loss: 0.5935
09/05 10:02:52 PM: Update 6316: task mnli, batch 316 (6316): accuracy: 0.7573, mnli_loss: 0.5906
09/05 10:03:02 PM: Update 6336: task mnli, batch 336 (6336): accuracy: 0.7583, mnli_loss: 0.5907
09/05 10:03:12 PM: Update 6354: task mnli, batch 354 (6354): accuracy: 0.7571, mnli_loss: 0.5920
09/05 10:03:23 PM: Update 6373: task mnli, batch 373 (6373): accuracy: 0.7584, mnli_loss: 0.5889
09/05 10:03:33 PM: Update 6392: task mnli, batch 392 (6392): accuracy: 0.7572, mnli_loss: 0.5910
09/05 10:03:44 PM: Update 6412: task mnli, batch 412 (6412): accuracy: 0.7573, mnli_loss: 0.5916
09/05 10:03:54 PM: Update 6431: task mnli, batch 431 (6431): accuracy: 0.7561, mnli_loss: 0.5939
09/05 10:04:04 PM: Update 6449: task mnli, batch 449 (6449): accuracy: 0.7556, mnli_loss: 0.5955
09/05 10:04:14 PM: Update 6468: task mnli, batch 468 (6468): accuracy: 0.7560, mnli_loss: 0.5943
09/05 10:04:24 PM: Update 6486: task mnli, batch 486 (6486): accuracy: 0.7569, mnli_loss: 0.5929
09/05 10:04:34 PM: Update 6505: task mnli, batch 505 (6505): accuracy: 0.7559, mnli_loss: 0.5943
09/05 10:04:45 PM: Update 6523: task mnli, batch 523 (6523): accuracy: 0.7571, mnli_loss: 0.5927
09/05 10:04:55 PM: Update 6542: task mnli, batch 542 (6542): accuracy: 0.7566, mnli_loss: 0.5920
09/05 10:05:05 PM: Update 6560: task mnli, batch 560 (6560): accuracy: 0.7571, mnli_loss: 0.5929
09/05 10:05:16 PM: Update 6581: task mnli, batch 581 (6581): accuracy: 0.7569, mnli_loss: 0.5938
09/05 10:05:26 PM: Update 6601: task mnli, batch 601 (6601): accuracy: 0.7571, mnli_loss: 0.5947
09/05 10:05:36 PM: Update 6620: task mnli, batch 620 (6620): accuracy: 0.7566, mnli_loss: 0.5952
09/05 10:05:47 PM: Update 6639: task mnli, batch 639 (6639): accuracy: 0.7562, mnli_loss: 0.5961
09/05 10:05:57 PM: Update 6658: task mnli, batch 658 (6658): accuracy: 0.7561, mnli_loss: 0.5962
09/05 10:06:08 PM: Update 6673: task mnli, batch 673 (6673): accuracy: 0.7551, mnli_loss: 0.5979
09/05 10:06:18 PM: Update 6691: task mnli, batch 691 (6691): accuracy: 0.7551, mnli_loss: 0.5982
09/05 10:06:28 PM: Update 6711: task mnli, batch 711 (6711): accuracy: 0.7553, mnli_loss: 0.5983
09/05 10:06:39 PM: Update 6729: task mnli, batch 729 (6729): accuracy: 0.7555, mnli_loss: 0.5980
09/05 10:06:49 PM: Update 6749: task mnli, batch 749 (6749): accuracy: 0.7554, mnli_loss: 0.5975
09/05 10:06:59 PM: Update 6767: task mnli, batch 767 (6767): accuracy: 0.7543, mnli_loss: 0.5990
09/05 10:07:09 PM: Update 6786: task mnli, batch 786 (6786): accuracy: 0.7549, mnli_loss: 0.5977
09/05 10:07:19 PM: Update 6805: task mnli, batch 805 (6805): accuracy: 0.7548, mnli_loss: 0.5979
09/05 10:07:30 PM: Update 6825: task mnli, batch 825 (6825): accuracy: 0.7541, mnli_loss: 0.5991
09/05 10:07:40 PM: Update 6846: task mnli, batch 846 (6846): accuracy: 0.7543, mnli_loss: 0.5983
09/05 10:07:50 PM: Update 6866: task mnli, batch 866 (6866): accuracy: 0.7545, mnli_loss: 0.5980
09/05 10:08:00 PM: Update 6885: task mnli, batch 885 (6885): accuracy: 0.7545, mnli_loss: 0.5977
09/05 10:08:11 PM: Update 6903: task mnli, batch 903 (6903): accuracy: 0.7544, mnli_loss: 0.5974
09/05 10:08:21 PM: Update 6922: task mnli, batch 922 (6922): accuracy: 0.7546, mnli_loss: 0.5975
09/05 10:08:31 PM: Update 6941: task mnli, batch 941 (6941): accuracy: 0.7551, mnli_loss: 0.5965
09/05 10:08:41 PM: Update 6959: task mnli, batch 959 (6959): accuracy: 0.7550, mnli_loss: 0.5962
09/05 10:08:51 PM: Update 6979: task mnli, batch 979 (6979): accuracy: 0.7555, mnli_loss: 0.5955
09/05 10:09:02 PM: Update 6998: task mnli, batch 998 (6998): accuracy: 0.7552, mnli_loss: 0.5963
09/05 10:09:03 PM: ***** Step 7000 / Validation 7 *****
09/05 10:09:03 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:09:03 PM: Validating...
09/05 10:09:12 PM: Evaluate: task mnli, batch 43 (209): accuracy: 0.7655, mnli_loss: 0.5531
09/05 10:09:22 PM: Evaluate: task mnli, batch 93 (209): accuracy: 0.7733, mnli_loss: 0.5617
09/05 10:09:32 PM: Evaluate: task mnli, batch 143 (209): accuracy: 0.7727, mnli_loss: 0.5580
09/05 10:09:42 PM: Evaluate: task mnli, batch 192 (209): accuracy: 0.7763, mnli_loss: 0.5533
09/05 10:09:45 PM: Best result seen so far for mnli.
09/05 10:09:45 PM: Best result seen so far for micro.
09/05 10:09:45 PM: Best result seen so far for macro.
09/05 10:09:45 PM: Updating LR scheduler:
09/05 10:09:45 PM: 	Best result seen so far for macro_avg: 0.775
09/05 10:09:45 PM: 	# validation passes without improvement: 0
09/05 10:09:45 PM: mnli_loss: training: 0.596171 validation: 0.558318
09/05 10:09:45 PM: macro_avg: validation: 0.775000
09/05 10:09:45 PM: micro_avg: validation: 0.775000
09/05 10:09:45 PM: mnli_accuracy: training: 0.755254 validation: 0.775000
09/05 10:09:45 PM: Global learning rate: 1e-05
09/05 10:09:45 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:09:52 PM: Update 7012: task mnli, batch 12 (7012): accuracy: 0.7778, mnli_loss: 0.5432
09/05 10:10:02 PM: Update 7031: task mnli, batch 31 (7031): accuracy: 0.7849, mnli_loss: 0.5381
09/05 10:10:13 PM: Update 7049: task mnli, batch 49 (7049): accuracy: 0.7874, mnli_loss: 0.5416
09/05 10:10:23 PM: Update 7067: task mnli, batch 67 (7067): accuracy: 0.7879, mnli_loss: 0.5488
09/05 10:10:33 PM: Update 7086: task mnli, batch 86 (7086): accuracy: 0.7810, mnli_loss: 0.5561
09/05 10:10:43 PM: Update 7100: task mnli, batch 100 (7100): accuracy: 0.7776, mnli_loss: 0.5597
09/05 10:10:53 PM: Update 7120: task mnli, batch 120 (7120): accuracy: 0.7747, mnli_loss: 0.5661
09/05 10:11:04 PM: Update 7139: task mnli, batch 139 (7139): accuracy: 0.7734, mnli_loss: 0.5738
09/05 10:11:14 PM: Update 7158: task mnli, batch 158 (7158): accuracy: 0.7714, mnli_loss: 0.5769
09/05 10:11:24 PM: Update 7177: task mnli, batch 177 (7177): accuracy: 0.7708, mnli_loss: 0.5772
09/05 10:11:34 PM: Update 7196: task mnli, batch 196 (7196): accuracy: 0.7732, mnli_loss: 0.5751
09/05 10:11:44 PM: Update 7215: task mnli, batch 215 (7215): accuracy: 0.7721, mnli_loss: 0.5749
09/05 10:11:55 PM: Update 7235: task mnli, batch 235 (7235): accuracy: 0.7704, mnli_loss: 0.5780
09/05 10:12:05 PM: Update 7253: task mnli, batch 253 (7253): accuracy: 0.7698, mnli_loss: 0.5805
09/05 10:12:15 PM: Update 7273: task mnli, batch 273 (7273): accuracy: 0.7725, mnli_loss: 0.5763
09/05 10:12:25 PM: Update 7292: task mnli, batch 292 (7292): accuracy: 0.7706, mnli_loss: 0.5784
09/05 10:12:35 PM: Update 7310: task mnli, batch 310 (7310): accuracy: 0.7715, mnli_loss: 0.5760
09/05 10:12:46 PM: Update 7329: task mnli, batch 329 (7329): accuracy: 0.7694, mnli_loss: 0.5810
09/05 10:12:56 PM: Update 7348: task mnli, batch 348 (7348): accuracy: 0.7691, mnli_loss: 0.5803
09/05 10:13:06 PM: Update 7367: task mnli, batch 367 (7367): accuracy: 0.7681, mnli_loss: 0.5813
09/05 10:13:16 PM: Update 7387: task mnli, batch 387 (7387): accuracy: 0.7684, mnli_loss: 0.5792
09/05 10:13:27 PM: Update 7406: task mnli, batch 406 (7406): accuracy: 0.7686, mnli_loss: 0.5780
09/05 10:13:37 PM: Update 7425: task mnli, batch 425 (7425): accuracy: 0.7682, mnli_loss: 0.5772
09/05 10:13:47 PM: Update 7445: task mnli, batch 445 (7445): accuracy: 0.7667, mnli_loss: 0.5797
09/05 10:13:58 PM: Update 7465: task mnli, batch 465 (7465): accuracy: 0.7674, mnli_loss: 0.5772
09/05 10:14:08 PM: Update 7485: task mnli, batch 485 (7485): accuracy: 0.7668, mnli_loss: 0.5780
09/05 10:14:18 PM: Update 7502: task mnli, batch 502 (7502): accuracy: 0.7659, mnli_loss: 0.5791
09/05 10:14:28 PM: Update 7517: task mnli, batch 517 (7517): accuracy: 0.7653, mnli_loss: 0.5796
09/05 10:14:39 PM: Update 7537: task mnli, batch 537 (7537): accuracy: 0.7662, mnli_loss: 0.5775
09/05 10:14:50 PM: Update 7559: task mnli, batch 559 (7559): accuracy: 0.7673, mnli_loss: 0.5755
09/05 10:15:00 PM: Update 7578: task mnli, batch 578 (7578): accuracy: 0.7684, mnli_loss: 0.5738
09/05 10:15:10 PM: Update 7597: task mnli, batch 597 (7597): accuracy: 0.7699, mnli_loss: 0.5716
09/05 10:15:21 PM: Update 7616: task mnli, batch 616 (7616): accuracy: 0.7700, mnli_loss: 0.5720
09/05 10:15:31 PM: Update 7636: task mnli, batch 636 (7636): accuracy: 0.7702, mnli_loss: 0.5722
09/05 10:15:42 PM: Update 7654: task mnli, batch 654 (7654): accuracy: 0.7694, mnli_loss: 0.5733
09/05 10:15:52 PM: Update 7672: task mnli, batch 672 (7672): accuracy: 0.7699, mnli_loss: 0.5722
09/05 10:16:02 PM: Update 7691: task mnli, batch 691 (7691): accuracy: 0.7694, mnli_loss: 0.5726
09/05 10:16:13 PM: Update 7710: task mnli, batch 710 (7710): accuracy: 0.7696, mnli_loss: 0.5732
09/05 10:16:23 PM: Update 7730: task mnli, batch 730 (7730): accuracy: 0.7702, mnli_loss: 0.5719
09/05 10:16:33 PM: Update 7749: task mnli, batch 749 (7749): accuracy: 0.7697, mnli_loss: 0.5733
09/05 10:16:43 PM: Update 7769: task mnli, batch 769 (7769): accuracy: 0.7694, mnli_loss: 0.5734
09/05 10:16:53 PM: Update 7788: task mnli, batch 788 (7788): accuracy: 0.7687, mnli_loss: 0.5739
09/05 10:17:04 PM: Update 7807: task mnli, batch 807 (7807): accuracy: 0.7687, mnli_loss: 0.5743
09/05 10:17:14 PM: Update 7826: task mnli, batch 826 (7826): accuracy: 0.7683, mnli_loss: 0.5742
09/05 10:17:24 PM: Update 7845: task mnli, batch 845 (7845): accuracy: 0.7682, mnli_loss: 0.5743
09/05 10:17:35 PM: Update 7864: task mnli, batch 864 (7864): accuracy: 0.7679, mnli_loss: 0.5746
09/05 10:17:45 PM: Update 7884: task mnli, batch 884 (7884): accuracy: 0.7685, mnli_loss: 0.5740
09/05 10:17:55 PM: Update 7903: task mnli, batch 903 (7903): accuracy: 0.7691, mnli_loss: 0.5731
09/05 10:18:06 PM: Update 7922: task mnli, batch 922 (7922): accuracy: 0.7688, mnli_loss: 0.5730
09/05 10:18:16 PM: Update 7936: task mnli, batch 936 (7936): accuracy: 0.7685, mnli_loss: 0.5732
09/05 10:18:26 PM: Update 7955: task mnli, batch 955 (7955): accuracy: 0.7687, mnli_loss: 0.5729
09/05 10:18:36 PM: Update 7974: task mnli, batch 974 (7974): accuracy: 0.7691, mnli_loss: 0.5723
09/05 10:18:47 PM: Update 7994: task mnli, batch 994 (7994): accuracy: 0.7687, mnli_loss: 0.5737
09/05 10:18:50 PM: ***** Step 8000 / Validation 8 *****
09/05 10:18:50 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:18:50 PM: Validating...
09/05 10:18:57 PM: Evaluate: task mnli, batch 33 (209): accuracy: 0.7929, mnli_loss: 0.5052
09/05 10:19:07 PM: Evaluate: task mnli, batch 83 (209): accuracy: 0.7932, mnli_loss: 0.5085
09/05 10:19:17 PM: Evaluate: task mnli, batch 132 (209): accuracy: 0.7847, mnli_loss: 0.5281
09/05 10:19:27 PM: Evaluate: task mnli, batch 181 (209): accuracy: 0.7894, mnli_loss: 0.5257
09/05 10:19:32 PM: Best result seen so far for mnli.
09/05 10:19:32 PM: Best result seen so far for micro.
09/05 10:19:32 PM: Best result seen so far for macro.
09/05 10:19:32 PM: Updating LR scheduler:
09/05 10:19:32 PM: 	Best result seen so far for macro_avg: 0.786
09/05 10:19:32 PM: 	# validation passes without improvement: 0
09/05 10:19:32 PM: mnli_loss: training: 0.573531 validation: 0.532354
09/05 10:19:32 PM: macro_avg: validation: 0.786000
09/05 10:19:32 PM: micro_avg: validation: 0.786000
09/05 10:19:32 PM: mnli_accuracy: training: 0.768560 validation: 0.786000
09/05 10:19:32 PM: Global learning rate: 1e-05
09/05 10:19:32 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:19:37 PM: Update 8008: task mnli, batch 8 (8008): accuracy: 0.8125, mnli_loss: 0.5579
09/05 10:19:47 PM: Update 8027: task mnli, batch 27 (8027): accuracy: 0.7793, mnli_loss: 0.5742
09/05 10:19:58 PM: Update 8047: task mnli, batch 47 (8047): accuracy: 0.7819, mnli_loss: 0.5628
09/05 10:20:08 PM: Update 8066: task mnli, batch 66 (8066): accuracy: 0.7765, mnli_loss: 0.5692
09/05 10:20:19 PM: Update 8088: task mnli, batch 88 (8088): accuracy: 0.7760, mnli_loss: 0.5670
09/05 10:20:29 PM: Update 8107: task mnli, batch 107 (8107): accuracy: 0.7738, mnli_loss: 0.5720
09/05 10:20:39 PM: Update 8126: task mnli, batch 126 (8126): accuracy: 0.7692, mnli_loss: 0.5809
09/05 10:20:50 PM: Update 8145: task mnli, batch 145 (8145): accuracy: 0.7739, mnli_loss: 0.5727
09/05 10:21:00 PM: Update 8164: task mnli, batch 164 (8164): accuracy: 0.7693, mnli_loss: 0.5827
09/05 10:21:10 PM: Update 8183: task mnli, batch 183 (8183): accuracy: 0.7675, mnli_loss: 0.5860
09/05 10:21:20 PM: Update 8202: task mnli, batch 202 (8202): accuracy: 0.7663, mnli_loss: 0.5878
09/05 10:21:31 PM: Update 8220: task mnli, batch 220 (8220): accuracy: 0.7646, mnli_loss: 0.5887
09/05 10:21:41 PM: Update 8238: task mnli, batch 238 (8238): accuracy: 0.7670, mnli_loss: 0.5863
09/05 10:21:51 PM: Update 8257: task mnli, batch 257 (8257): accuracy: 0.7664, mnli_loss: 0.5848
09/05 10:22:01 PM: Update 8276: task mnli, batch 276 (8276): accuracy: 0.7665, mnli_loss: 0.5833
09/05 10:22:12 PM: Update 8295: task mnli, batch 295 (8295): accuracy: 0.7669, mnli_loss: 0.5808
09/05 10:22:22 PM: Update 8314: task mnli, batch 314 (8314): accuracy: 0.7666, mnli_loss: 0.5822
09/05 10:22:33 PM: Update 8334: task mnli, batch 334 (8334): accuracy: 0.7665, mnli_loss: 0.5819
09/05 10:22:43 PM: Update 8349: task mnli, batch 349 (8349): accuracy: 0.7654, mnli_loss: 0.5831
09/05 10:22:53 PM: Update 8368: task mnli, batch 368 (8368): accuracy: 0.7645, mnli_loss: 0.5841
09/05 10:23:03 PM: Update 8387: task mnli, batch 387 (8387): accuracy: 0.7651, mnli_loss: 0.5835
09/05 10:23:14 PM: Update 8406: task mnli, batch 406 (8406): accuracy: 0.7654, mnli_loss: 0.5835
09/05 10:23:24 PM: Update 8426: task mnli, batch 426 (8426): accuracy: 0.7663, mnli_loss: 0.5818
09/05 10:23:35 PM: Update 8445: task mnli, batch 445 (8445): accuracy: 0.7657, mnli_loss: 0.5827
09/05 10:23:45 PM: Update 8463: task mnli, batch 463 (8463): accuracy: 0.7642, mnli_loss: 0.5854
09/05 10:23:55 PM: Update 8484: task mnli, batch 484 (8484): accuracy: 0.7645, mnli_loss: 0.5831
09/05 10:24:06 PM: Update 8505: task mnli, batch 505 (8505): accuracy: 0.7661, mnli_loss: 0.5797
09/05 10:24:16 PM: Update 8525: task mnli, batch 525 (8525): accuracy: 0.7666, mnli_loss: 0.5800
09/05 10:24:27 PM: Update 8543: task mnli, batch 543 (8543): accuracy: 0.7660, mnli_loss: 0.5808
09/05 10:24:37 PM: Update 8562: task mnli, batch 562 (8562): accuracy: 0.7668, mnli_loss: 0.5794
09/05 10:24:47 PM: Update 8580: task mnli, batch 580 (8580): accuracy: 0.7675, mnli_loss: 0.5776
09/05 10:24:57 PM: Update 8600: task mnli, batch 600 (8600): accuracy: 0.7679, mnli_loss: 0.5765
09/05 10:25:08 PM: Update 8619: task mnli, batch 619 (8619): accuracy: 0.7683, mnli_loss: 0.5758
09/05 10:25:18 PM: Update 8637: task mnli, batch 637 (8637): accuracy: 0.7680, mnli_loss: 0.5765
09/05 10:25:28 PM: Update 8656: task mnli, batch 656 (8656): accuracy: 0.7673, mnli_loss: 0.5776
09/05 10:25:38 PM: Update 8675: task mnli, batch 675 (8675): accuracy: 0.7669, mnli_loss: 0.5775
09/05 10:25:48 PM: Update 8694: task mnli, batch 694 (8694): accuracy: 0.7670, mnli_loss: 0.5766
09/05 10:25:58 PM: Update 8714: task mnli, batch 714 (8714): accuracy: 0.7669, mnli_loss: 0.5763
09/05 10:26:08 PM: Update 8732: task mnli, batch 732 (8732): accuracy: 0.7674, mnli_loss: 0.5747
09/05 10:26:18 PM: Update 8751: task mnli, batch 751 (8751): accuracy: 0.7675, mnli_loss: 0.5747
09/05 10:26:29 PM: Update 8766: task mnli, batch 766 (8766): accuracy: 0.7670, mnli_loss: 0.5758
09/05 10:26:40 PM: Update 8787: task mnli, batch 787 (8787): accuracy: 0.7675, mnli_loss: 0.5743
09/05 10:26:50 PM: Update 8805: task mnli, batch 805 (8805): accuracy: 0.7678, mnli_loss: 0.5743
09/05 10:27:00 PM: Update 8825: task mnli, batch 825 (8825): accuracy: 0.7674, mnli_loss: 0.5746
09/05 10:27:10 PM: Update 8845: task mnli, batch 845 (8845): accuracy: 0.7678, mnli_loss: 0.5739
09/05 10:27:21 PM: Update 8865: task mnli, batch 865 (8865): accuracy: 0.7672, mnli_loss: 0.5748
09/05 10:27:31 PM: Update 8884: task mnli, batch 884 (8884): accuracy: 0.7668, mnli_loss: 0.5750
09/05 10:27:41 PM: Update 8905: task mnli, batch 905 (8905): accuracy: 0.7666, mnli_loss: 0.5752
09/05 10:27:51 PM: Update 8922: task mnli, batch 922 (8922): accuracy: 0.7665, mnli_loss: 0.5747
09/05 10:28:02 PM: Update 8942: task mnli, batch 942 (8942): accuracy: 0.7668, mnli_loss: 0.5751
09/05 10:28:12 PM: Update 8961: task mnli, batch 961 (8961): accuracy: 0.7667, mnli_loss: 0.5762
09/05 10:28:22 PM: Update 8982: task mnli, batch 982 (8982): accuracy: 0.7670, mnli_loss: 0.5749
09/05 10:28:32 PM: ***** Step 9000 / Validation 9 *****
09/05 10:28:32 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:28:32 PM: Validating...
09/05 10:28:32 PM: Evaluate: task mnli, batch 1 (209): accuracy: 0.8333, mnli_loss: 0.3225
09/05 10:28:42 PM: Evaluate: task mnli, batch 52 (209): accuracy: 0.7764, mnli_loss: 0.5187
09/05 10:28:53 PM: Evaluate: task mnli, batch 102 (209): accuracy: 0.7774, mnli_loss: 0.5303
09/05 10:29:03 PM: Evaluate: task mnli, batch 152 (209): accuracy: 0.7777, mnli_loss: 0.5335
09/05 10:29:13 PM: Evaluate: task mnli, batch 201 (209): accuracy: 0.7815, mnli_loss: 0.5309
09/05 10:29:14 PM: Updating LR scheduler:
09/05 10:29:14 PM: 	Best result seen so far for macro_avg: 0.786
09/05 10:29:14 PM: 	# validation passes without improvement: 1
09/05 10:29:14 PM: mnli_loss: training: 0.575163 validation: 0.535713
09/05 10:29:14 PM: macro_avg: validation: 0.778800
09/05 10:29:14 PM: micro_avg: validation: 0.778800
09/05 10:29:14 PM: mnli_accuracy: training: 0.766928 validation: 0.778800
09/05 10:29:14 PM: Global learning rate: 1e-05
09/05 10:29:14 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:29:23 PM: Update 9014: task mnli, batch 14 (9014): accuracy: 0.7589, mnli_loss: 0.5715
09/05 10:29:33 PM: Update 9034: task mnli, batch 34 (9034): accuracy: 0.7684, mnli_loss: 0.5776
09/05 10:29:43 PM: Update 9053: task mnli, batch 53 (9053): accuracy: 0.7657, mnli_loss: 0.5708
09/05 10:29:54 PM: Update 9071: task mnli, batch 71 (9071): accuracy: 0.7500, mnli_loss: 0.5979
09/05 10:30:04 PM: Update 9090: task mnli, batch 90 (9090): accuracy: 0.7597, mnli_loss: 0.5873
09/05 10:30:14 PM: Update 9108: task mnli, batch 108 (9108): accuracy: 0.7600, mnli_loss: 0.5914
09/05 10:30:24 PM: Update 9125: task mnli, batch 125 (9125): accuracy: 0.7603, mnli_loss: 0.5971
09/05 10:30:34 PM: Update 9143: task mnli, batch 143 (9143): accuracy: 0.7608, mnli_loss: 0.5956
09/05 10:30:45 PM: Update 9164: task mnli, batch 164 (9164): accuracy: 0.7632, mnli_loss: 0.5893
09/05 10:30:55 PM: Update 9179: task mnli, batch 179 (9179): accuracy: 0.7635, mnli_loss: 0.5893
09/05 10:31:05 PM: Update 9198: task mnli, batch 198 (9198): accuracy: 0.7660, mnli_loss: 0.5862
09/05 10:31:15 PM: Update 9217: task mnli, batch 217 (9217): accuracy: 0.7671, mnli_loss: 0.5861
09/05 10:31:26 PM: Update 9237: task mnli, batch 237 (9237): accuracy: 0.7665, mnli_loss: 0.5839
09/05 10:31:36 PM: Update 9255: task mnli, batch 255 (9255): accuracy: 0.7677, mnli_loss: 0.5818
09/05 10:31:47 PM: Update 9275: task mnli, batch 275 (9275): accuracy: 0.7673, mnli_loss: 0.5810
09/05 10:31:57 PM: Update 9295: task mnli, batch 295 (9295): accuracy: 0.7661, mnli_loss: 0.5817
09/05 10:32:07 PM: Update 9314: task mnli, batch 314 (9314): accuracy: 0.7674, mnli_loss: 0.5788
09/05 10:32:18 PM: Update 9334: task mnli, batch 334 (9334): accuracy: 0.7692, mnli_loss: 0.5762
09/05 10:32:28 PM: Update 9352: task mnli, batch 352 (9352): accuracy: 0.7701, mnli_loss: 0.5737
09/05 10:32:39 PM: Update 9372: task mnli, batch 372 (9372): accuracy: 0.7728, mnli_loss: 0.5687
09/05 10:32:49 PM: Update 9393: task mnli, batch 393 (9393): accuracy: 0.7707, mnli_loss: 0.5701
09/05 10:32:59 PM: Update 9412: task mnli, batch 412 (9412): accuracy: 0.7712, mnli_loss: 0.5699
09/05 10:33:10 PM: Update 9431: task mnli, batch 431 (9431): accuracy: 0.7712, mnli_loss: 0.5710
09/05 10:33:20 PM: Update 9449: task mnli, batch 449 (9449): accuracy: 0.7725, mnli_loss: 0.5692
09/05 10:33:30 PM: Update 9469: task mnli, batch 469 (9469): accuracy: 0.7710, mnli_loss: 0.5721
09/05 10:33:41 PM: Update 9488: task mnli, batch 488 (9488): accuracy: 0.7699, mnli_loss: 0.5744
09/05 10:33:51 PM: Update 9507: task mnli, batch 507 (9507): accuracy: 0.7706, mnli_loss: 0.5727
09/05 10:34:02 PM: Update 9526: task mnli, batch 526 (9526): accuracy: 0.7706, mnli_loss: 0.5718
09/05 10:34:12 PM: Update 9544: task mnli, batch 544 (9544): accuracy: 0.7704, mnli_loss: 0.5727
09/05 10:34:22 PM: Update 9563: task mnli, batch 563 (9563): accuracy: 0.7710, mnli_loss: 0.5713
09/05 10:34:32 PM: Update 9583: task mnli, batch 583 (9583): accuracy: 0.7727, mnli_loss: 0.5691
09/05 10:34:42 PM: Update 9598: task mnli, batch 598 (9598): accuracy: 0.7713, mnli_loss: 0.5711
09/05 10:34:53 PM: Update 9620: task mnli, batch 620 (9620): accuracy: 0.7721, mnli_loss: 0.5707
09/05 10:35:03 PM: Update 9639: task mnli, batch 639 (9639): accuracy: 0.7732, mnli_loss: 0.5699
09/05 10:35:13 PM: Update 9658: task mnli, batch 658 (9658): accuracy: 0.7731, mnli_loss: 0.5702
09/05 10:35:23 PM: Update 9677: task mnli, batch 677 (9677): accuracy: 0.7720, mnli_loss: 0.5719
09/05 10:35:34 PM: Update 9696: task mnli, batch 696 (9696): accuracy: 0.7725, mnli_loss: 0.5706
09/05 10:35:44 PM: Update 9715: task mnli, batch 715 (9715): accuracy: 0.7721, mnli_loss: 0.5712
09/05 10:35:54 PM: Update 9734: task mnli, batch 734 (9734): accuracy: 0.7720, mnli_loss: 0.5711
09/05 10:36:04 PM: Update 9755: task mnli, batch 755 (9755): accuracy: 0.7728, mnli_loss: 0.5697
09/05 10:36:14 PM: Update 9774: task mnli, batch 774 (9774): accuracy: 0.7740, mnli_loss: 0.5681
09/05 10:36:25 PM: Update 9794: task mnli, batch 794 (9794): accuracy: 0.7742, mnli_loss: 0.5678
09/05 10:36:35 PM: Update 9811: task mnli, batch 811 (9811): accuracy: 0.7738, mnli_loss: 0.5684
09/05 10:36:45 PM: Update 9829: task mnli, batch 829 (9829): accuracy: 0.7736, mnli_loss: 0.5679
09/05 10:36:56 PM: Update 9847: task mnli, batch 847 (9847): accuracy: 0.7735, mnli_loss: 0.5682
09/05 10:37:06 PM: Update 9866: task mnli, batch 866 (9866): accuracy: 0.7739, mnli_loss: 0.5662
09/05 10:37:16 PM: Update 9885: task mnli, batch 885 (9885): accuracy: 0.7736, mnli_loss: 0.5671
09/05 10:37:26 PM: Update 9905: task mnli, batch 905 (9905): accuracy: 0.7736, mnli_loss: 0.5672
09/05 10:37:37 PM: Update 9925: task mnli, batch 925 (9925): accuracy: 0.7737, mnli_loss: 0.5673
09/05 10:37:47 PM: Update 9944: task mnli, batch 944 (9944): accuracy: 0.7742, mnli_loss: 0.5663
09/05 10:37:57 PM: Update 9963: task mnli, batch 963 (9963): accuracy: 0.7739, mnli_loss: 0.5669
09/05 10:38:08 PM: Update 9982: task mnli, batch 982 (9982): accuracy: 0.7733, mnli_loss: 0.5670
09/05 10:38:17 PM: ***** Step 10000 / Validation 10 *****
09/05 10:38:17 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:38:17 PM: Validating...
09/05 10:38:18 PM: Evaluate: task mnli, batch 7 (209): accuracy: 0.8036, mnli_loss: 0.4859
09/05 10:38:28 PM: Evaluate: task mnli, batch 57 (209): accuracy: 0.7939, mnli_loss: 0.5046
09/05 10:38:38 PM: Evaluate: task mnli, batch 107 (209): accuracy: 0.7843, mnli_loss: 0.5189
09/05 10:38:48 PM: Evaluate: task mnli, batch 157 (209): accuracy: 0.7858, mnli_loss: 0.5208
09/05 10:38:58 PM: Evaluate: task mnli, batch 207 (209): accuracy: 0.7854, mnli_loss: 0.5267
09/05 10:38:59 PM: Updating LR scheduler:
09/05 10:38:59 PM: 	Best result seen so far for macro_avg: 0.786
09/05 10:38:59 PM: 	# validation passes without improvement: 2
09/05 10:38:59 PM: mnli_loss: training: 0.566099 validation: 0.529024
09/05 10:38:59 PM: macro_avg: validation: 0.784800
09/05 10:38:59 PM: micro_avg: validation: 0.784800
09/05 10:38:59 PM: mnli_accuracy: training: 0.773766 validation: 0.784800
09/05 10:38:59 PM: Global learning rate: 1e-05
09/05 10:38:59 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:39:09 PM: Update 10013: task mnli, batch 13 (10013): accuracy: 0.7632, mnli_loss: 0.6122
09/05 10:39:19 PM: Update 10033: task mnli, batch 33 (10033): accuracy: 0.7895, mnli_loss: 0.5404
09/05 10:39:29 PM: Update 10051: task mnli, batch 51 (10051): accuracy: 0.7854, mnli_loss: 0.5467
09/05 10:39:39 PM: Update 10070: task mnli, batch 70 (10070): accuracy: 0.7799, mnli_loss: 0.5516
09/05 10:39:50 PM: Update 10090: task mnli, batch 90 (10090): accuracy: 0.7830, mnli_loss: 0.5438
09/05 10:40:00 PM: Update 10110: task mnli, batch 110 (10110): accuracy: 0.7872, mnli_loss: 0.5357
09/05 10:40:11 PM: Update 10128: task mnli, batch 128 (10128): accuracy: 0.7862, mnli_loss: 0.5336
09/05 10:40:21 PM: Update 10147: task mnli, batch 147 (10147): accuracy: 0.7869, mnli_loss: 0.5334
09/05 10:40:32 PM: Update 10167: task mnli, batch 167 (10167): accuracy: 0.7903, mnli_loss: 0.5264
09/05 10:40:42 PM: Update 10187: task mnli, batch 187 (10187): accuracy: 0.7882, mnli_loss: 0.5338
09/05 10:40:52 PM: Update 10207: task mnli, batch 207 (10207): accuracy: 0.7875, mnli_loss: 0.5328
09/05 10:41:03 PM: Update 10227: task mnli, batch 227 (10227): accuracy: 0.7881, mnli_loss: 0.5300
09/05 10:41:13 PM: Update 10246: task mnli, batch 246 (10246): accuracy: 0.7870, mnli_loss: 0.5314
09/05 10:41:23 PM: Update 10265: task mnli, batch 265 (10265): accuracy: 0.7873, mnli_loss: 0.5339
09/05 10:41:33 PM: Update 10284: task mnli, batch 284 (10284): accuracy: 0.7894, mnli_loss: 0.5275
09/05 10:41:44 PM: Update 10303: task mnli, batch 303 (10303): accuracy: 0.7887, mnli_loss: 0.5272
09/05 10:41:54 PM: Update 10323: task mnli, batch 323 (10323): accuracy: 0.7874, mnli_loss: 0.5280
09/05 10:42:04 PM: Update 10341: task mnli, batch 341 (10341): accuracy: 0.7855, mnli_loss: 0.5303
09/05 10:42:15 PM: Update 10360: task mnli, batch 360 (10360): accuracy: 0.7854, mnli_loss: 0.5304
09/05 10:42:25 PM: Update 10380: task mnli, batch 380 (10380): accuracy: 0.7846, mnli_loss: 0.5346
09/05 10:42:35 PM: Update 10399: task mnli, batch 399 (10399): accuracy: 0.7826, mnli_loss: 0.5398
09/05 10:42:45 PM: Update 10418: task mnli, batch 418 (10418): accuracy: 0.7820, mnli_loss: 0.5420
09/05 10:42:55 PM: Update 10433: task mnli, batch 433 (10433): accuracy: 0.7819, mnli_loss: 0.5427
09/05 10:43:06 PM: Update 10453: task mnli, batch 453 (10453): accuracy: 0.7825, mnli_loss: 0.5405
09/05 10:43:16 PM: Update 10471: task mnli, batch 471 (10471): accuracy: 0.7830, mnli_loss: 0.5395
09/05 10:43:26 PM: Update 10490: task mnli, batch 490 (10490): accuracy: 0.7837, mnli_loss: 0.5372
09/05 10:43:36 PM: Update 10509: task mnli, batch 509 (10509): accuracy: 0.7834, mnli_loss: 0.5385
09/05 10:43:47 PM: Update 10530: task mnli, batch 530 (10530): accuracy: 0.7841, mnli_loss: 0.5376
09/05 10:43:57 PM: Update 10549: task mnli, batch 549 (10549): accuracy: 0.7840, mnli_loss: 0.5380
09/05 10:44:08 PM: Update 10569: task mnli, batch 569 (10569): accuracy: 0.7852, mnli_loss: 0.5358
09/05 10:44:18 PM: Update 10587: task mnli, batch 587 (10587): accuracy: 0.7846, mnli_loss: 0.5364
09/05 10:44:28 PM: Update 10606: task mnli, batch 606 (10606): accuracy: 0.7848, mnli_loss: 0.5358
09/05 10:44:39 PM: Update 10625: task mnli, batch 625 (10625): accuracy: 0.7845, mnli_loss: 0.5372
09/05 10:44:49 PM: Update 10643: task mnli, batch 643 (10643): accuracy: 0.7843, mnli_loss: 0.5372
09/05 10:44:59 PM: Update 10662: task mnli, batch 662 (10662): accuracy: 0.7838, mnli_loss: 0.5387
09/05 10:45:09 PM: Update 10681: task mnli, batch 681 (10681): accuracy: 0.7839, mnli_loss: 0.5387
09/05 10:45:20 PM: Update 10701: task mnli, batch 701 (10701): accuracy: 0.7834, mnli_loss: 0.5399
09/05 10:45:30 PM: Update 10721: task mnli, batch 721 (10721): accuracy: 0.7834, mnli_loss: 0.5400
09/05 10:45:40 PM: Update 10740: task mnli, batch 740 (10740): accuracy: 0.7834, mnli_loss: 0.5397
09/05 10:45:51 PM: Update 10759: task mnli, batch 759 (10759): accuracy: 0.7839, mnli_loss: 0.5387
09/05 10:46:01 PM: Update 10781: task mnli, batch 781 (10781): accuracy: 0.7837, mnli_loss: 0.5394
09/05 10:46:11 PM: Update 10800: task mnli, batch 800 (10800): accuracy: 0.7836, mnli_loss: 0.5398
09/05 10:46:22 PM: Update 10820: task mnli, batch 820 (10820): accuracy: 0.7838, mnli_loss: 0.5392
09/05 10:46:32 PM: Update 10839: task mnli, batch 839 (10839): accuracy: 0.7834, mnli_loss: 0.5391
09/05 10:46:42 PM: Update 10853: task mnli, batch 853 (10853): accuracy: 0.7835, mnli_loss: 0.5395
09/05 10:46:53 PM: Update 10873: task mnli, batch 873 (10873): accuracy: 0.7836, mnli_loss: 0.5400
09/05 10:47:03 PM: Update 10892: task mnli, batch 892 (10892): accuracy: 0.7826, mnli_loss: 0.5412
09/05 10:47:14 PM: Update 10911: task mnli, batch 911 (10911): accuracy: 0.7822, mnli_loss: 0.5418
09/05 10:47:24 PM: Update 10931: task mnli, batch 931 (10931): accuracy: 0.7815, mnli_loss: 0.5431
09/05 10:47:34 PM: Update 10950: task mnli, batch 950 (10950): accuracy: 0.7817, mnli_loss: 0.5426
09/05 10:47:45 PM: Update 10968: task mnli, batch 968 (10968): accuracy: 0.7812, mnli_loss: 0.5432
09/05 10:47:55 PM: Update 10987: task mnli, batch 987 (10987): accuracy: 0.7816, mnli_loss: 0.5424
09/05 10:48:02 PM: ***** Step 11000 / Validation 11 *****
09/05 10:48:02 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:48:02 PM: Validating...
09/05 10:48:05 PM: Evaluate: task mnli, batch 14 (209): accuracy: 0.8274, mnli_loss: 0.4538
09/05 10:48:15 PM: Evaluate: task mnli, batch 65 (209): accuracy: 0.8109, mnli_loss: 0.4948
09/05 10:48:25 PM: Evaluate: task mnli, batch 115 (209): accuracy: 0.7978, mnli_loss: 0.5144
09/05 10:48:35 PM: Evaluate: task mnli, batch 165 (209): accuracy: 0.7975, mnli_loss: 0.5109
09/05 10:48:44 PM: Best result seen so far for mnli.
09/05 10:48:44 PM: Best result seen so far for micro.
09/05 10:48:44 PM: Best result seen so far for macro.
09/05 10:48:44 PM: Updating LR scheduler:
09/05 10:48:44 PM: 	Best result seen so far for macro_avg: 0.793
09/05 10:48:44 PM: 	# validation passes without improvement: 0
09/05 10:48:44 PM: mnli_loss: training: 0.542321 validation: 0.521495
09/05 10:48:44 PM: macro_avg: validation: 0.792800
09/05 10:48:44 PM: micro_avg: validation: 0.792800
09/05 10:48:44 PM: mnli_accuracy: training: 0.781448 validation: 0.792800
09/05 10:48:44 PM: Global learning rate: 1e-05
09/05 10:48:44 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:48:45 PM: Update 11001: task mnli, batch 1 (11001): accuracy: 0.8333, mnli_loss: 0.3754
09/05 10:48:56 PM: Update 11020: task mnli, batch 20 (11020): accuracy: 0.7688, mnli_loss: 0.5422
09/05 10:49:06 PM: Update 11039: task mnli, batch 39 (11039): accuracy: 0.7639, mnli_loss: 0.5421
09/05 10:49:16 PM: Update 11058: task mnli, batch 58 (11058): accuracy: 0.7701, mnli_loss: 0.5408
09/05 10:49:26 PM: Update 11076: task mnli, batch 76 (11076): accuracy: 0.7741, mnli_loss: 0.5405
09/05 10:49:37 PM: Update 11095: task mnli, batch 95 (11095): accuracy: 0.7759, mnli_loss: 0.5412
09/05 10:49:47 PM: Update 11115: task mnli, batch 115 (11115): accuracy: 0.7804, mnli_loss: 0.5334
09/05 10:49:57 PM: Update 11135: task mnli, batch 135 (11135): accuracy: 0.7843, mnli_loss: 0.5311
09/05 10:50:07 PM: Update 11153: task mnli, batch 153 (11153): accuracy: 0.7849, mnli_loss: 0.5303
09/05 10:50:18 PM: Update 11173: task mnli, batch 173 (11173): accuracy: 0.7837, mnli_loss: 0.5322
09/05 10:50:28 PM: Update 11192: task mnli, batch 192 (11192): accuracy: 0.7836, mnli_loss: 0.5305
09/05 10:50:38 PM: Update 11211: task mnli, batch 211 (11211): accuracy: 0.7842, mnli_loss: 0.5305
09/05 10:50:48 PM: Update 11231: task mnli, batch 231 (11231): accuracy: 0.7848, mnli_loss: 0.5272
09/05 10:50:59 PM: Update 11251: task mnli, batch 251 (11251): accuracy: 0.7845, mnli_loss: 0.5290
09/05 10:51:09 PM: Update 11267: task mnli, batch 267 (11267): accuracy: 0.7856, mnli_loss: 0.5268
09/05 10:51:19 PM: Update 11285: task mnli, batch 285 (11285): accuracy: 0.7859, mnli_loss: 0.5262
09/05 10:51:29 PM: Update 11303: task mnli, batch 303 (11303): accuracy: 0.7846, mnli_loss: 0.5279
09/05 10:51:40 PM: Update 11325: task mnli, batch 325 (11325): accuracy: 0.7871, mnli_loss: 0.5226
09/05 10:51:50 PM: Update 11346: task mnli, batch 346 (11346): accuracy: 0.7863, mnli_loss: 0.5244
09/05 10:52:00 PM: Update 11363: task mnli, batch 363 (11363): accuracy: 0.7849, mnli_loss: 0.5278
09/05 10:52:10 PM: Update 11382: task mnli, batch 382 (11382): accuracy: 0.7850, mnli_loss: 0.5283
09/05 10:52:20 PM: Update 11400: task mnli, batch 400 (11400): accuracy: 0.7840, mnli_loss: 0.5315
09/05 10:52:31 PM: Update 11420: task mnli, batch 420 (11420): accuracy: 0.7827, mnli_loss: 0.5336
09/05 10:52:41 PM: Update 11441: task mnli, batch 441 (11441): accuracy: 0.7831, mnli_loss: 0.5332
09/05 10:52:52 PM: Update 11460: task mnli, batch 460 (11460): accuracy: 0.7836, mnli_loss: 0.5331
09/05 10:53:02 PM: Update 11479: task mnli, batch 479 (11479): accuracy: 0.7839, mnli_loss: 0.5332
09/05 10:53:12 PM: Update 11500: task mnli, batch 500 (11500): accuracy: 0.7842, mnli_loss: 0.5326
09/05 10:53:23 PM: Update 11518: task mnli, batch 518 (11518): accuracy: 0.7833, mnli_loss: 0.5346
09/05 10:53:33 PM: Update 11537: task mnli, batch 537 (11537): accuracy: 0.7840, mnli_loss: 0.5334
09/05 10:53:43 PM: Update 11557: task mnli, batch 557 (11557): accuracy: 0.7837, mnli_loss: 0.5338
09/05 10:53:54 PM: Update 11577: task mnli, batch 577 (11577): accuracy: 0.7832, mnli_loss: 0.5348
09/05 10:54:04 PM: Update 11594: task mnli, batch 594 (11594): accuracy: 0.7819, mnli_loss: 0.5370
09/05 10:54:15 PM: Update 11615: task mnli, batch 615 (11615): accuracy: 0.7818, mnli_loss: 0.5368
09/05 10:54:25 PM: Update 11635: task mnli, batch 635 (11635): accuracy: 0.7817, mnli_loss: 0.5366
09/05 10:54:35 PM: Update 11655: task mnli, batch 655 (11655): accuracy: 0.7816, mnli_loss: 0.5376
09/05 10:54:45 PM: Update 11673: task mnli, batch 673 (11673): accuracy: 0.7820, mnli_loss: 0.5375
09/05 10:54:56 PM: Update 11688: task mnli, batch 688 (11688): accuracy: 0.7823, mnli_loss: 0.5372
09/05 10:55:06 PM: Update 11708: task mnli, batch 708 (11708): accuracy: 0.7826, mnli_loss: 0.5368
09/05 10:55:16 PM: Update 11728: task mnli, batch 728 (11728): accuracy: 0.7831, mnli_loss: 0.5369
09/05 10:55:27 PM: Update 11746: task mnli, batch 746 (11746): accuracy: 0.7824, mnli_loss: 0.5382
09/05 10:55:37 PM: Update 11764: task mnli, batch 764 (11764): accuracy: 0.7817, mnli_loss: 0.5393
09/05 10:55:48 PM: Update 11784: task mnli, batch 784 (11784): accuracy: 0.7808, mnli_loss: 0.5403
09/05 10:55:58 PM: Update 11803: task mnli, batch 803 (11803): accuracy: 0.7815, mnli_loss: 0.5395
09/05 10:56:08 PM: Update 11821: task mnli, batch 821 (11821): accuracy: 0.7818, mnli_loss: 0.5384
09/05 10:56:18 PM: Update 11839: task mnli, batch 839 (11839): accuracy: 0.7820, mnli_loss: 0.5383
09/05 10:56:28 PM: Update 11860: task mnli, batch 860 (11860): accuracy: 0.7829, mnli_loss: 0.5369
09/05 10:56:38 PM: Update 11879: task mnli, batch 879 (11879): accuracy: 0.7828, mnli_loss: 0.5379
09/05 10:56:48 PM: Update 11898: task mnli, batch 898 (11898): accuracy: 0.7833, mnli_loss: 0.5363
09/05 10:56:59 PM: Update 11917: task mnli, batch 917 (11917): accuracy: 0.7836, mnli_loss: 0.5359
09/05 10:57:09 PM: Update 11938: task mnli, batch 938 (11938): accuracy: 0.7840, mnli_loss: 0.5351
09/05 10:57:19 PM: Update 11957: task mnli, batch 957 (11957): accuracy: 0.7830, mnli_loss: 0.5373
09/05 10:57:30 PM: Update 11976: task mnli, batch 976 (11976): accuracy: 0.7835, mnli_loss: 0.5370
09/05 10:57:40 PM: Update 11995: task mnli, batch 995 (11995): accuracy: 0.7833, mnli_loss: 0.5374
09/05 10:57:42 PM: ***** Step 12000 / Validation 12 *****
09/05 10:57:42 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 10:57:42 PM: Validating...
09/05 10:57:50 PM: Evaluate: task mnli, batch 38 (209): accuracy: 0.7873, mnli_loss: 0.5264
09/05 10:58:00 PM: Evaluate: task mnli, batch 88 (209): accuracy: 0.7898, mnli_loss: 0.5203
09/05 10:58:10 PM: Evaluate: task mnli, batch 138 (209): accuracy: 0.7871, mnli_loss: 0.5278
09/05 10:58:20 PM: Evaluate: task mnli, batch 184 (209): accuracy: 0.7896, mnli_loss: 0.5232
09/05 10:58:25 PM: Updating LR scheduler:
09/05 10:58:25 PM: 	Best result seen so far for macro_avg: 0.793
09/05 10:58:25 PM: 	# validation passes without improvement: 1
09/05 10:58:25 PM: mnli_loss: training: 0.537273 validation: 0.528770
09/05 10:58:25 PM: macro_avg: validation: 0.789000
09/05 10:58:25 PM: micro_avg: validation: 0.789000
09/05 10:58:25 PM: mnli_accuracy: training: 0.783272 validation: 0.789000
09/05 10:58:25 PM: Global learning rate: 1e-05
09/05 10:58:25 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 10:58:30 PM: Update 12007: task mnli, batch 7 (12007): accuracy: 0.7798, mnli_loss: 0.5593
09/05 10:58:40 PM: Update 12027: task mnli, batch 27 (12027): accuracy: 0.7994, mnli_loss: 0.5276
09/05 10:58:50 PM: Update 12046: task mnli, batch 46 (12046): accuracy: 0.7926, mnli_loss: 0.5379
09/05 10:59:01 PM: Update 12066: task mnli, batch 66 (12066): accuracy: 0.7797, mnli_loss: 0.5493
09/05 10:59:11 PM: Update 12085: task mnli, batch 85 (12085): accuracy: 0.7784, mnli_loss: 0.5512
09/05 10:59:21 PM: Update 12100: task mnli, batch 100 (12100): accuracy: 0.7814, mnli_loss: 0.5493
09/05 10:59:31 PM: Update 12120: task mnli, batch 120 (12120): accuracy: 0.7792, mnli_loss: 0.5522
09/05 10:59:42 PM: Update 12140: task mnli, batch 140 (12140): accuracy: 0.7760, mnli_loss: 0.5583
09/05 10:59:52 PM: Update 12160: task mnli, batch 160 (12160): accuracy: 0.7779, mnli_loss: 0.5532
09/05 11:00:02 PM: Update 12179: task mnli, batch 179 (12179): accuracy: 0.7794, mnli_loss: 0.5501
09/05 11:00:12 PM: Update 12199: task mnli, batch 199 (12199): accuracy: 0.7827, mnli_loss: 0.5383
09/05 11:00:23 PM: Update 12217: task mnli, batch 217 (12217): accuracy: 0.7831, mnli_loss: 0.5356
09/05 11:00:33 PM: Update 12237: task mnli, batch 237 (12237): accuracy: 0.7838, mnli_loss: 0.5347
09/05 11:00:43 PM: Update 12257: task mnli, batch 257 (12257): accuracy: 0.7841, mnli_loss: 0.5323
09/05 11:00:53 PM: Update 12275: task mnli, batch 275 (12275): accuracy: 0.7825, mnli_loss: 0.5398
09/05 11:01:03 PM: Update 12294: task mnli, batch 294 (12294): accuracy: 0.7808, mnli_loss: 0.5428
09/05 11:01:13 PM: Update 12311: task mnli, batch 311 (12311): accuracy: 0.7821, mnli_loss: 0.5409
09/05 11:01:23 PM: Update 12330: task mnli, batch 330 (12330): accuracy: 0.7829, mnli_loss: 0.5385
09/05 11:01:34 PM: Update 12349: task mnli, batch 349 (12349): accuracy: 0.7845, mnli_loss: 0.5377
09/05 11:01:44 PM: Update 12369: task mnli, batch 369 (12369): accuracy: 0.7844, mnli_loss: 0.5390
09/05 11:01:54 PM: Update 12387: task mnli, batch 387 (12387): accuracy: 0.7844, mnli_loss: 0.5393
09/05 11:02:05 PM: Update 12406: task mnli, batch 406 (12406): accuracy: 0.7858, mnli_loss: 0.5369
09/05 11:02:15 PM: Update 12425: task mnli, batch 425 (12425): accuracy: 0.7867, mnli_loss: 0.5345
09/05 11:02:25 PM: Update 12442: task mnli, batch 442 (12442): accuracy: 0.7862, mnli_loss: 0.5350
09/05 11:02:35 PM: Update 12462: task mnli, batch 462 (12462): accuracy: 0.7851, mnli_loss: 0.5362
09/05 11:02:45 PM: Update 12481: task mnli, batch 481 (12481): accuracy: 0.7855, mnli_loss: 0.5372
09/05 11:02:55 PM: Update 12501: task mnli, batch 501 (12501): accuracy: 0.7853, mnli_loss: 0.5375
09/05 11:03:06 PM: Update 12515: task mnli, batch 515 (12515): accuracy: 0.7848, mnli_loss: 0.5383
09/05 11:03:16 PM: Update 12534: task mnli, batch 534 (12534): accuracy: 0.7853, mnli_loss: 0.5370
09/05 11:03:27 PM: Update 12553: task mnli, batch 553 (12553): accuracy: 0.7847, mnli_loss: 0.5377
09/05 11:03:37 PM: Update 12573: task mnli, batch 573 (12573): accuracy: 0.7859, mnli_loss: 0.5363
09/05 11:03:48 PM: Update 12592: task mnli, batch 592 (12592): accuracy: 0.7861, mnli_loss: 0.5358
09/05 11:03:58 PM: Update 12611: task mnli, batch 611 (12611): accuracy: 0.7863, mnli_loss: 0.5354
09/05 11:04:08 PM: Update 12629: task mnli, batch 629 (12629): accuracy: 0.7855, mnli_loss: 0.5370
09/05 11:04:18 PM: Update 12647: task mnli, batch 647 (12647): accuracy: 0.7860, mnli_loss: 0.5363
09/05 11:04:28 PM: Update 12665: task mnli, batch 665 (12665): accuracy: 0.7862, mnli_loss: 0.5354
09/05 11:04:39 PM: Update 12683: task mnli, batch 683 (12683): accuracy: 0.7862, mnli_loss: 0.5355
09/05 11:04:49 PM: Update 12702: task mnli, batch 702 (12702): accuracy: 0.7873, mnli_loss: 0.5339
09/05 11:04:59 PM: Update 12720: task mnli, batch 720 (12720): accuracy: 0.7878, mnli_loss: 0.5328
09/05 11:05:10 PM: Update 12738: task mnli, batch 738 (12738): accuracy: 0.7879, mnli_loss: 0.5325
09/05 11:05:20 PM: Update 12756: task mnli, batch 756 (12756): accuracy: 0.7886, mnli_loss: 0.5319
09/05 11:05:30 PM: Update 12776: task mnli, batch 776 (12776): accuracy: 0.7883, mnli_loss: 0.5319
09/05 11:05:41 PM: Update 12796: task mnli, batch 796 (12796): accuracy: 0.7875, mnli_loss: 0.5326
09/05 11:05:51 PM: Update 12815: task mnli, batch 815 (12815): accuracy: 0.7879, mnli_loss: 0.5317
09/05 11:06:01 PM: Update 12836: task mnli, batch 836 (12836): accuracy: 0.7889, mnli_loss: 0.5297
09/05 11:06:11 PM: Update 12855: task mnli, batch 855 (12855): accuracy: 0.7886, mnli_loss: 0.5299
09/05 11:06:22 PM: Update 12874: task mnli, batch 874 (12874): accuracy: 0.7880, mnli_loss: 0.5303
09/05 11:06:32 PM: Update 12892: task mnli, batch 892 (12892): accuracy: 0.7882, mnli_loss: 0.5304
09/05 11:06:43 PM: Update 12912: task mnli, batch 912 (12912): accuracy: 0.7887, mnli_loss: 0.5299
09/05 11:06:54 PM: Update 12928: task mnli, batch 928 (12928): accuracy: 0.7884, mnli_loss: 0.5299
09/05 11:07:04 PM: Update 12947: task mnli, batch 947 (12947): accuracy: 0.7880, mnli_loss: 0.5306
09/05 11:07:14 PM: Update 12965: task mnli, batch 965 (12965): accuracy: 0.7876, mnli_loss: 0.5310
09/05 11:07:25 PM: Update 12983: task mnli, batch 983 (12983): accuracy: 0.7876, mnli_loss: 0.5313
09/05 11:07:34 PM: ***** Step 13000 / Validation 13 *****
09/05 11:07:34 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:07:34 PM: Validating...
09/05 11:07:35 PM: Evaluate: task mnli, batch 4 (209): accuracy: 0.8333, mnli_loss: 0.4615
09/05 11:07:45 PM: Evaluate: task mnli, batch 55 (209): accuracy: 0.8091, mnli_loss: 0.4762
09/05 11:07:55 PM: Evaluate: task mnli, batch 105 (209): accuracy: 0.7976, mnli_loss: 0.4908
09/05 11:08:05 PM: Evaluate: task mnli, batch 155 (209): accuracy: 0.7952, mnli_loss: 0.4976
09/05 11:08:16 PM: Evaluate: task mnli, batch 205 (209): accuracy: 0.7945, mnli_loss: 0.5011
09/05 11:08:16 PM: Best result seen so far for mnli.
09/05 11:08:16 PM: Best result seen so far for micro.
09/05 11:08:16 PM: Best result seen so far for macro.
09/05 11:08:16 PM: Updating LR scheduler:
09/05 11:08:16 PM: 	Best result seen so far for macro_avg: 0.794
09/05 11:08:16 PM: 	# validation passes without improvement: 0
09/05 11:08:16 PM: mnli_loss: training: 0.531418 validation: 0.503453
09/05 11:08:16 PM: macro_avg: validation: 0.793600
09/05 11:08:16 PM: micro_avg: validation: 0.793600
09/05 11:08:16 PM: mnli_accuracy: training: 0.787371 validation: 0.793600
09/05 11:08:16 PM: Global learning rate: 1e-05
09/05 11:08:16 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:08:26 PM: Update 13014: task mnli, batch 14 (13014): accuracy: 0.7768, mnli_loss: 0.5984
09/05 11:08:36 PM: Update 13034: task mnli, batch 34 (13034): accuracy: 0.7880, mnli_loss: 0.5625
09/05 11:08:46 PM: Update 13053: task mnli, batch 53 (13053): accuracy: 0.7995, mnli_loss: 0.5373
09/05 11:08:56 PM: Update 13072: task mnli, batch 72 (13072): accuracy: 0.7940, mnli_loss: 0.5476
09/05 11:09:07 PM: Update 13090: task mnli, batch 90 (13090): accuracy: 0.7977, mnli_loss: 0.5392
09/05 11:09:17 PM: Update 13109: task mnli, batch 109 (13109): accuracy: 0.7913, mnli_loss: 0.5442
09/05 11:09:28 PM: Update 13129: task mnli, batch 129 (13129): accuracy: 0.7901, mnli_loss: 0.5500
09/05 11:09:38 PM: Update 13147: task mnli, batch 147 (13147): accuracy: 0.7905, mnli_loss: 0.5466
09/05 11:09:48 PM: Update 13165: task mnli, batch 165 (13165): accuracy: 0.7902, mnli_loss: 0.5422
09/05 11:09:59 PM: Update 13185: task mnli, batch 185 (13185): accuracy: 0.7914, mnli_loss: 0.5359
09/05 11:10:09 PM: Update 13204: task mnli, batch 204 (13204): accuracy: 0.7931, mnli_loss: 0.5291
09/05 11:10:19 PM: Update 13223: task mnli, batch 223 (13223): accuracy: 0.7920, mnli_loss: 0.5310
09/05 11:10:30 PM: Update 13242: task mnli, batch 242 (13242): accuracy: 0.7918, mnli_loss: 0.5323
09/05 11:10:40 PM: Update 13262: task mnli, batch 262 (13262): accuracy: 0.7923, mnli_loss: 0.5309
09/05 11:10:50 PM: Update 13282: task mnli, batch 282 (13282): accuracy: 0.7905, mnli_loss: 0.5382
09/05 11:11:01 PM: Update 13301: task mnli, batch 301 (13301): accuracy: 0.7900, mnli_loss: 0.5398
09/05 11:11:11 PM: Update 13321: task mnli, batch 321 (13321): accuracy: 0.7904, mnli_loss: 0.5370
09/05 11:11:21 PM: Update 13340: task mnli, batch 340 (13340): accuracy: 0.7863, mnli_loss: 0.5447
09/05 11:11:31 PM: Update 13352: task mnli, batch 352 (13352): accuracy: 0.7867, mnli_loss: 0.5447
09/05 11:11:42 PM: Update 13370: task mnli, batch 370 (13370): accuracy: 0.7863, mnli_loss: 0.5457
09/05 11:11:52 PM: Update 13388: task mnli, batch 388 (13388): accuracy: 0.7862, mnli_loss: 0.5458
09/05 11:12:03 PM: Update 13407: task mnli, batch 407 (13407): accuracy: 0.7872, mnli_loss: 0.5428
09/05 11:12:13 PM: Update 13428: task mnli, batch 428 (13428): accuracy: 0.7867, mnli_loss: 0.5443
09/05 11:12:23 PM: Update 13448: task mnli, batch 448 (13448): accuracy: 0.7867, mnli_loss: 0.5430
09/05 11:12:34 PM: Update 13467: task mnli, batch 467 (13467): accuracy: 0.7868, mnli_loss: 0.5440
09/05 11:12:44 PM: Update 13485: task mnli, batch 485 (13485): accuracy: 0.7882, mnli_loss: 0.5412
09/05 11:12:54 PM: Update 13504: task mnli, batch 504 (13504): accuracy: 0.7890, mnli_loss: 0.5382
09/05 11:13:04 PM: Update 13525: task mnli, batch 525 (13525): accuracy: 0.7895, mnli_loss: 0.5370
09/05 11:13:15 PM: Update 13543: task mnli, batch 543 (13543): accuracy: 0.7900, mnli_loss: 0.5354
09/05 11:13:25 PM: Update 13561: task mnli, batch 561 (13561): accuracy: 0.7902, mnli_loss: 0.5353
09/05 11:13:36 PM: Update 13580: task mnli, batch 580 (13580): accuracy: 0.7900, mnli_loss: 0.5351
09/05 11:13:46 PM: Update 13599: task mnli, batch 599 (13599): accuracy: 0.7892, mnli_loss: 0.5363
09/05 11:13:56 PM: Update 13619: task mnli, batch 619 (13619): accuracy: 0.7891, mnli_loss: 0.5350
09/05 11:14:06 PM: Update 13639: task mnli, batch 639 (13639): accuracy: 0.7903, mnli_loss: 0.5327
09/05 11:14:16 PM: Update 13658: task mnli, batch 658 (13658): accuracy: 0.7903, mnli_loss: 0.5321
09/05 11:14:27 PM: Update 13675: task mnli, batch 675 (13675): accuracy: 0.7900, mnli_loss: 0.5323
09/05 11:14:37 PM: Update 13693: task mnli, batch 693 (13693): accuracy: 0.7907, mnli_loss: 0.5307
09/05 11:14:47 PM: Update 13711: task mnli, batch 711 (13711): accuracy: 0.7913, mnli_loss: 0.5293
09/05 11:14:57 PM: Update 13731: task mnli, batch 731 (13731): accuracy: 0.7914, mnli_loss: 0.5286
09/05 11:15:08 PM: Update 13749: task mnli, batch 749 (13749): accuracy: 0.7915, mnli_loss: 0.5286
09/05 11:15:18 PM: Update 13763: task mnli, batch 763 (13763): accuracy: 0.7908, mnli_loss: 0.5294
09/05 11:15:29 PM: Update 13783: task mnli, batch 783 (13783): accuracy: 0.7907, mnli_loss: 0.5296
09/05 11:15:39 PM: Update 13803: task mnli, batch 803 (13803): accuracy: 0.7907, mnli_loss: 0.5293
09/05 11:15:49 PM: Update 13821: task mnli, batch 821 (13821): accuracy: 0.7908, mnli_loss: 0.5292
09/05 11:15:59 PM: Update 13839: task mnli, batch 839 (13839): accuracy: 0.7900, mnli_loss: 0.5300
09/05 11:16:09 PM: Update 13859: task mnli, batch 859 (13859): accuracy: 0.7900, mnli_loss: 0.5296
09/05 11:16:20 PM: Update 13878: task mnli, batch 878 (13878): accuracy: 0.7897, mnli_loss: 0.5298
09/05 11:16:30 PM: Update 13894: task mnli, batch 894 (13894): accuracy: 0.7883, mnli_loss: 0.5327
09/05 11:16:40 PM: Update 13911: task mnli, batch 911 (13911): accuracy: 0.7881, mnli_loss: 0.5331
09/05 11:16:50 PM: Update 13930: task mnli, batch 930 (13930): accuracy: 0.7880, mnli_loss: 0.5332
09/05 11:17:01 PM: Update 13948: task mnli, batch 948 (13948): accuracy: 0.7882, mnli_loss: 0.5326
09/05 11:17:11 PM: Update 13968: task mnli, batch 968 (13968): accuracy: 0.7874, mnli_loss: 0.5333
09/05 11:17:21 PM: Update 13988: task mnli, batch 988 (13988): accuracy: 0.7875, mnli_loss: 0.5337
09/05 11:17:27 PM: ***** Step 14000 / Validation 14 *****
09/05 11:17:27 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:17:27 PM: Validating...
09/05 11:17:31 PM: Evaluate: task mnli, batch 20 (209): accuracy: 0.8000, mnli_loss: 0.5245
09/05 11:17:41 PM: Evaluate: task mnli, batch 70 (209): accuracy: 0.7982, mnli_loss: 0.5154
09/05 11:17:51 PM: Evaluate: task mnli, batch 120 (209): accuracy: 0.7875, mnli_loss: 0.5314
09/05 11:18:01 PM: Evaluate: task mnli, batch 169 (209): accuracy: 0.7902, mnli_loss: 0.5252
09/05 11:18:09 PM: Updating LR scheduler:
09/05 11:18:09 PM: 	Best result seen so far for macro_avg: 0.794
09/05 11:18:09 PM: 	# validation passes without improvement: 1
09/05 11:18:09 PM: mnli_loss: training: 0.533222 validation: 0.529770
09/05 11:18:09 PM: macro_avg: validation: 0.786400
09/05 11:18:09 PM: micro_avg: validation: 0.786400
09/05 11:18:09 PM: mnli_accuracy: training: 0.787733 validation: 0.786400
09/05 11:18:09 PM: Global learning rate: 1e-05
09/05 11:18:09 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:18:11 PM: Update 14002: task mnli, batch 2 (14002): accuracy: 0.7500, mnli_loss: 0.4658
09/05 11:18:21 PM: Update 14020: task mnli, batch 20 (14020): accuracy: 0.8000, mnli_loss: 0.5130
09/05 11:18:32 PM: Update 14038: task mnli, batch 38 (14038): accuracy: 0.7862, mnli_loss: 0.5613
09/05 11:18:42 PM: Update 14057: task mnli, batch 57 (14057): accuracy: 0.7924, mnli_loss: 0.5412
09/05 11:18:52 PM: Update 14076: task mnli, batch 76 (14076): accuracy: 0.7955, mnli_loss: 0.5289
09/05 11:19:02 PM: Update 14094: task mnli, batch 94 (14094): accuracy: 0.7872, mnli_loss: 0.5446
09/05 11:19:13 PM: Update 14114: task mnli, batch 114 (14114): accuracy: 0.7865, mnli_loss: 0.5384
09/05 11:19:23 PM: Update 14133: task mnli, batch 133 (14133): accuracy: 0.7888, mnli_loss: 0.5298
09/05 11:19:34 PM: Update 14152: task mnli, batch 152 (14152): accuracy: 0.7878, mnli_loss: 0.5320
09/05 11:19:44 PM: Update 14171: task mnli, batch 171 (14171): accuracy: 0.7880, mnli_loss: 0.5356
09/05 11:19:54 PM: Update 14185: task mnli, batch 185 (14185): accuracy: 0.7875, mnli_loss: 0.5364
09/05 11:20:04 PM: Update 14203: task mnli, batch 203 (14203): accuracy: 0.7897, mnli_loss: 0.5320
09/05 11:20:15 PM: Update 14221: task mnli, batch 221 (14221): accuracy: 0.7874, mnli_loss: 0.5366
09/05 11:20:25 PM: Update 14240: task mnli, batch 240 (14240): accuracy: 0.7879, mnli_loss: 0.5356
09/05 11:20:35 PM: Update 14259: task mnli, batch 259 (14259): accuracy: 0.7883, mnli_loss: 0.5358
09/05 11:20:46 PM: Update 14277: task mnli, batch 277 (14277): accuracy: 0.7881, mnli_loss: 0.5335
09/05 11:20:56 PM: Update 14295: task mnli, batch 295 (14295): accuracy: 0.7897, mnli_loss: 0.5294
09/05 11:21:06 PM: Update 14314: task mnli, batch 314 (14314): accuracy: 0.7888, mnli_loss: 0.5305
09/05 11:21:16 PM: Update 14333: task mnli, batch 333 (14333): accuracy: 0.7888, mnli_loss: 0.5312
09/05 11:21:26 PM: Update 14353: task mnli, batch 353 (14353): accuracy: 0.7910, mnli_loss: 0.5297
09/05 11:21:36 PM: Update 14371: task mnli, batch 371 (14371): accuracy: 0.7908, mnli_loss: 0.5298
09/05 11:21:46 PM: Update 14389: task mnli, batch 389 (14389): accuracy: 0.7903, mnli_loss: 0.5293
09/05 11:21:57 PM: Update 14408: task mnli, batch 408 (14408): accuracy: 0.7904, mnli_loss: 0.5278
09/05 11:22:07 PM: Update 14427: task mnli, batch 427 (14427): accuracy: 0.7905, mnli_loss: 0.5277
09/05 11:22:17 PM: Update 14446: task mnli, batch 446 (14446): accuracy: 0.7887, mnli_loss: 0.5295
09/05 11:22:27 PM: Update 14465: task mnli, batch 465 (14465): accuracy: 0.7895, mnli_loss: 0.5282
09/05 11:22:37 PM: Update 14485: task mnli, batch 485 (14485): accuracy: 0.7898, mnli_loss: 0.5279
09/05 11:22:48 PM: Update 14505: task mnli, batch 505 (14505): accuracy: 0.7905, mnli_loss: 0.5259
09/05 11:22:58 PM: Update 14524: task mnli, batch 524 (14524): accuracy: 0.7917, mnli_loss: 0.5238
09/05 11:23:08 PM: Update 14543: task mnli, batch 543 (14543): accuracy: 0.7923, mnli_loss: 0.5235
09/05 11:23:19 PM: Update 14562: task mnli, batch 562 (14562): accuracy: 0.7929, mnli_loss: 0.5226
09/05 11:23:29 PM: Update 14580: task mnli, batch 580 (14580): accuracy: 0.7921, mnli_loss: 0.5231
09/05 11:23:40 PM: Update 14596: task mnli, batch 596 (14596): accuracy: 0.7928, mnli_loss: 0.5216
09/05 11:23:50 PM: Update 14615: task mnli, batch 615 (14615): accuracy: 0.7923, mnli_loss: 0.5233
09/05 11:24:00 PM: Update 14633: task mnli, batch 633 (14633): accuracy: 0.7925, mnli_loss: 0.5231
09/05 11:24:10 PM: Update 14651: task mnli, batch 651 (14651): accuracy: 0.7929, mnli_loss: 0.5216
09/05 11:24:20 PM: Update 14671: task mnli, batch 671 (14671): accuracy: 0.7934, mnli_loss: 0.5198
09/05 11:24:31 PM: Update 14689: task mnli, batch 689 (14689): accuracy: 0.7936, mnli_loss: 0.5199
09/05 11:24:41 PM: Update 14707: task mnli, batch 707 (14707): accuracy: 0.7936, mnli_loss: 0.5192
09/05 11:24:51 PM: Update 14725: task mnli, batch 725 (14725): accuracy: 0.7935, mnli_loss: 0.5187
09/05 11:25:01 PM: Update 14744: task mnli, batch 744 (14744): accuracy: 0.7934, mnli_loss: 0.5192
09/05 11:25:11 PM: Update 14763: task mnli, batch 763 (14763): accuracy: 0.7937, mnli_loss: 0.5177
09/05 11:25:22 PM: Update 14784: task mnli, batch 784 (14784): accuracy: 0.7946, mnli_loss: 0.5157
09/05 11:25:32 PM: Update 14803: task mnli, batch 803 (14803): accuracy: 0.7941, mnli_loss: 0.5159
09/05 11:25:43 PM: Update 14823: task mnli, batch 823 (14823): accuracy: 0.7941, mnli_loss: 0.5168
09/05 11:25:53 PM: Update 14841: task mnli, batch 841 (14841): accuracy: 0.7932, mnli_loss: 0.5177
09/05 11:26:03 PM: Update 14860: task mnli, batch 860 (14860): accuracy: 0.7933, mnli_loss: 0.5180
09/05 11:26:13 PM: Update 14879: task mnli, batch 879 (14879): accuracy: 0.7936, mnli_loss: 0.5176
09/05 11:26:23 PM: Update 14896: task mnli, batch 896 (14896): accuracy: 0.7927, mnli_loss: 0.5201
09/05 11:26:33 PM: Update 14914: task mnli, batch 914 (14914): accuracy: 0.7926, mnli_loss: 0.5202
09/05 11:26:43 PM: Update 14933: task mnli, batch 933 (14933): accuracy: 0.7929, mnli_loss: 0.5197
09/05 11:26:54 PM: Update 14951: task mnli, batch 951 (14951): accuracy: 0.7929, mnli_loss: 0.5193
09/05 11:27:04 PM: Update 14970: task mnli, batch 970 (14970): accuracy: 0.7926, mnli_loss: 0.5198
09/05 11:27:15 PM: Update 14989: task mnli, batch 989 (14989): accuracy: 0.7923, mnli_loss: 0.5199
09/05 11:27:20 PM: ***** Step 15000 / Validation 15 *****
09/05 11:27:20 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:27:20 PM: Validating...
09/05 11:27:25 PM: Evaluate: task mnli, batch 23 (209): accuracy: 0.8080, mnli_loss: 0.4813
09/05 11:27:35 PM: Evaluate: task mnli, batch 73 (209): accuracy: 0.8031, mnli_loss: 0.4933
09/05 11:27:45 PM: Evaluate: task mnli, batch 123 (209): accuracy: 0.7957, mnli_loss: 0.5044
09/05 11:27:55 PM: Evaluate: task mnli, batch 173 (209): accuracy: 0.8003, mnli_loss: 0.4994
09/05 11:28:02 PM: Best result seen so far for mnli.
09/05 11:28:02 PM: Best result seen so far for micro.
09/05 11:28:02 PM: Best result seen so far for macro.
09/05 11:28:02 PM: Updating LR scheduler:
09/05 11:28:02 PM: 	Best result seen so far for macro_avg: 0.798
09/05 11:28:02 PM: 	# validation passes without improvement: 0
09/05 11:28:02 PM: mnli_loss: training: 0.519700 validation: 0.506493
09/05 11:28:02 PM: macro_avg: validation: 0.797800
09/05 11:28:02 PM: micro_avg: validation: 0.797800
09/05 11:28:02 PM: mnli_accuracy: training: 0.792487 validation: 0.797800
09/05 11:28:02 PM: Global learning rate: 1e-05
09/05 11:28:02 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:28:05 PM: Update 15004: task mnli, batch 4 (15004): accuracy: 0.8229, mnli_loss: 0.4017
09/05 11:28:15 PM: Update 15016: task mnli, batch 16 (15016): accuracy: 0.7553, mnli_loss: 0.5412
09/05 11:28:26 PM: Update 15034: task mnli, batch 34 (15034): accuracy: 0.7673, mnli_loss: 0.5467
09/05 11:28:36 PM: Update 15053: task mnli, batch 53 (15053): accuracy: 0.7832, mnli_loss: 0.5131
09/05 11:28:46 PM: Update 15071: task mnli, batch 71 (15071): accuracy: 0.7848, mnli_loss: 0.5123
09/05 11:28:56 PM: Update 15090: task mnli, batch 90 (15090): accuracy: 0.7858, mnli_loss: 0.5171
09/05 11:29:07 PM: Update 15110: task mnli, batch 110 (15110): accuracy: 0.7918, mnli_loss: 0.5111
09/05 11:29:17 PM: Update 15128: task mnli, batch 128 (15128): accuracy: 0.7901, mnli_loss: 0.5152
09/05 11:29:28 PM: Update 15147: task mnli, batch 147 (15147): accuracy: 0.7889, mnli_loss: 0.5193
09/05 11:29:38 PM: Update 15166: task mnli, batch 166 (15166): accuracy: 0.7875, mnli_loss: 0.5249
09/05 11:29:48 PM: Update 15186: task mnli, batch 186 (15186): accuracy: 0.7870, mnli_loss: 0.5277
09/05 11:29:58 PM: Update 15205: task mnli, batch 205 (15205): accuracy: 0.7875, mnli_loss: 0.5262
09/05 11:30:08 PM: Update 15223: task mnli, batch 223 (15223): accuracy: 0.7854, mnli_loss: 0.5313
09/05 11:30:18 PM: Update 15241: task mnli, batch 241 (15241): accuracy: 0.7860, mnli_loss: 0.5266
09/05 11:30:28 PM: Update 15261: task mnli, batch 261 (15261): accuracy: 0.7844, mnli_loss: 0.5277
09/05 11:30:39 PM: Update 15280: task mnli, batch 280 (15280): accuracy: 0.7850, mnli_loss: 0.5252
09/05 11:30:49 PM: Update 15299: task mnli, batch 299 (15299): accuracy: 0.7849, mnli_loss: 0.5242
09/05 11:31:00 PM: Update 15318: task mnli, batch 318 (15318): accuracy: 0.7859, mnli_loss: 0.5233
09/05 11:31:10 PM: Update 15337: task mnli, batch 337 (15337): accuracy: 0.7864, mnli_loss: 0.5217
09/05 11:31:21 PM: Update 15357: task mnli, batch 357 (15357): accuracy: 0.7859, mnli_loss: 0.5218
09/05 11:31:31 PM: Update 15375: task mnli, batch 375 (15375): accuracy: 0.7853, mnli_loss: 0.5238
09/05 11:31:42 PM: Update 15393: task mnli, batch 393 (15393): accuracy: 0.7843, mnli_loss: 0.5266
09/05 11:31:52 PM: Update 15412: task mnli, batch 412 (15412): accuracy: 0.7845, mnli_loss: 0.5276
09/05 11:32:03 PM: Update 15430: task mnli, batch 430 (15430): accuracy: 0.7840, mnli_loss: 0.5282
09/05 11:32:14 PM: Update 15450: task mnli, batch 450 (15450): accuracy: 0.7850, mnli_loss: 0.5281
09/05 11:32:24 PM: Update 15467: task mnli, batch 467 (15467): accuracy: 0.7848, mnli_loss: 0.5293
09/05 11:32:34 PM: Update 15486: task mnli, batch 486 (15486): accuracy: 0.7839, mnli_loss: 0.5295
09/05 11:32:45 PM: Update 15505: task mnli, batch 505 (15505): accuracy: 0.7838, mnli_loss: 0.5287
09/05 11:32:55 PM: Update 15525: task mnli, batch 525 (15525): accuracy: 0.7837, mnli_loss: 0.5287
09/05 11:33:05 PM: Update 15546: task mnli, batch 546 (15546): accuracy: 0.7844, mnli_loss: 0.5280
09/05 11:33:15 PM: Update 15563: task mnli, batch 563 (15563): accuracy: 0.7855, mnli_loss: 0.5267
09/05 11:33:26 PM: Update 15581: task mnli, batch 581 (15581): accuracy: 0.7853, mnli_loss: 0.5260
09/05 11:33:36 PM: Update 15599: task mnli, batch 599 (15599): accuracy: 0.7851, mnli_loss: 0.5265
09/05 11:33:46 PM: Update 15618: task mnli, batch 618 (15618): accuracy: 0.7855, mnli_loss: 0.5256
09/05 11:33:57 PM: Update 15640: task mnli, batch 640 (15640): accuracy: 0.7863, mnli_loss: 0.5239
09/05 11:34:07 PM: Update 15659: task mnli, batch 659 (15659): accuracy: 0.7868, mnli_loss: 0.5228
09/05 11:34:18 PM: Update 15677: task mnli, batch 677 (15677): accuracy: 0.7872, mnli_loss: 0.5218
09/05 11:34:28 PM: Update 15694: task mnli, batch 694 (15694): accuracy: 0.7864, mnli_loss: 0.5230
09/05 11:34:39 PM: Update 15713: task mnli, batch 713 (15713): accuracy: 0.7867, mnli_loss: 0.5223
09/05 11:34:49 PM: Update 15732: task mnli, batch 732 (15732): accuracy: 0.7869, mnli_loss: 0.5229
09/05 11:34:59 PM: Update 15750: task mnli, batch 750 (15750): accuracy: 0.7869, mnli_loss: 0.5225
09/05 11:35:10 PM: Update 15771: task mnli, batch 771 (15771): accuracy: 0.7880, mnli_loss: 0.5211
09/05 11:35:20 PM: Update 15792: task mnli, batch 792 (15792): accuracy: 0.7890, mnli_loss: 0.5190
09/05 11:35:30 PM: Update 15809: task mnli, batch 809 (15809): accuracy: 0.7893, mnli_loss: 0.5191
09/05 11:35:40 PM: Update 15828: task mnli, batch 828 (15828): accuracy: 0.7894, mnli_loss: 0.5187
09/05 11:35:50 PM: Update 15846: task mnli, batch 846 (15846): accuracy: 0.7894, mnli_loss: 0.5193
09/05 11:36:01 PM: Update 15860: task mnli, batch 860 (15860): accuracy: 0.7901, mnli_loss: 0.5179
09/05 11:36:11 PM: Update 15877: task mnli, batch 877 (15877): accuracy: 0.7894, mnli_loss: 0.5194
09/05 11:36:21 PM: Update 15896: task mnli, batch 896 (15896): accuracy: 0.7898, mnli_loss: 0.5189
09/05 11:36:32 PM: Update 15916: task mnli, batch 916 (15916): accuracy: 0.7900, mnli_loss: 0.5187
09/05 11:36:42 PM: Update 15936: task mnli, batch 936 (15936): accuracy: 0.7902, mnli_loss: 0.5179
09/05 11:36:52 PM: Update 15955: task mnli, batch 955 (15955): accuracy: 0.7898, mnli_loss: 0.5180
09/05 11:37:03 PM: Update 15976: task mnli, batch 976 (15976): accuracy: 0.7897, mnli_loss: 0.5182
09/05 11:37:13 PM: Update 15993: task mnli, batch 993 (15993): accuracy: 0.7901, mnli_loss: 0.5177
09/05 11:37:17 PM: ***** Step 16000 / Validation 16 *****
09/05 11:37:17 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:37:17 PM: Validating...
09/05 11:37:23 PM: Evaluate: task mnli, batch 30 (209): accuracy: 0.8042, mnli_loss: 0.5249
09/05 11:37:33 PM: Evaluate: task mnli, batch 80 (209): accuracy: 0.8109, mnli_loss: 0.5081
09/05 11:37:43 PM: Evaluate: task mnli, batch 130 (209): accuracy: 0.8016, mnli_loss: 0.5257
09/05 11:37:53 PM: Evaluate: task mnli, batch 179 (209): accuracy: 0.7980, mnli_loss: 0.5251
09/05 11:37:59 PM: Updating LR scheduler:
09/05 11:37:59 PM: 	Best result seen so far for macro_avg: 0.798
09/05 11:37:59 PM: 	# validation passes without improvement: 1
09/05 11:37:59 PM: mnli_loss: training: 0.517208 validation: 0.529987
09/05 11:37:59 PM: macro_avg: validation: 0.796000
09/05 11:37:59 PM: micro_avg: validation: 0.796000
09/05 11:37:59 PM: mnli_accuracy: training: 0.790499 validation: 0.796000
09/05 11:37:59 PM: Global learning rate: 1e-05
09/05 11:37:59 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:38:04 PM: Update 16007: task mnli, batch 7 (16007): accuracy: 0.7976, mnli_loss: 0.5124
09/05 11:38:14 PM: Update 16027: task mnli, batch 27 (16027): accuracy: 0.7994, mnli_loss: 0.5073
09/05 11:38:24 PM: Update 16046: task mnli, batch 46 (16046): accuracy: 0.8089, mnli_loss: 0.4978
09/05 11:38:35 PM: Update 16065: task mnli, batch 65 (16065): accuracy: 0.8032, mnli_loss: 0.5007
09/05 11:38:45 PM: Update 16085: task mnli, batch 85 (16085): accuracy: 0.8054, mnli_loss: 0.4998
09/05 11:38:56 PM: Update 16104: task mnli, batch 104 (16104): accuracy: 0.8081, mnli_loss: 0.5018
09/05 11:39:07 PM: Update 16124: task mnli, batch 124 (16124): accuracy: 0.8054, mnli_loss: 0.5078
09/05 11:39:17 PM: Update 16143: task mnli, batch 143 (16143): accuracy: 0.8045, mnli_loss: 0.5083
09/05 11:39:27 PM: Update 16161: task mnli, batch 161 (16161): accuracy: 0.8038, mnli_loss: 0.5059
09/05 11:39:37 PM: Update 16178: task mnli, batch 178 (16178): accuracy: 0.8017, mnli_loss: 0.5092
09/05 11:39:48 PM: Update 16197: task mnli, batch 197 (16197): accuracy: 0.7980, mnli_loss: 0.5162
09/05 11:39:58 PM: Update 16217: task mnli, batch 217 (16217): accuracy: 0.7944, mnli_loss: 0.5202
09/05 11:40:09 PM: Update 16236: task mnli, batch 236 (16236): accuracy: 0.7941, mnli_loss: 0.5214
09/05 11:40:19 PM: Update 16254: task mnli, batch 254 (16254): accuracy: 0.7936, mnli_loss: 0.5201
09/05 11:40:29 PM: Update 16271: task mnli, batch 271 (16271): accuracy: 0.7912, mnli_loss: 0.5253
09/05 11:40:39 PM: Update 16290: task mnli, batch 290 (16290): accuracy: 0.7898, mnli_loss: 0.5249
09/05 11:40:49 PM: Update 16308: task mnli, batch 308 (16308): accuracy: 0.7884, mnli_loss: 0.5265
09/05 11:40:59 PM: Update 16326: task mnli, batch 326 (16326): accuracy: 0.7864, mnli_loss: 0.5288
09/05 11:41:10 PM: Update 16344: task mnli, batch 344 (16344): accuracy: 0.7869, mnli_loss: 0.5273
09/05 11:41:20 PM: Update 16364: task mnli, batch 364 (16364): accuracy: 0.7868, mnli_loss: 0.5254
09/05 11:41:30 PM: Update 16379: task mnli, batch 379 (16379): accuracy: 0.7860, mnli_loss: 0.5273
09/05 11:41:40 PM: Update 16397: task mnli, batch 397 (16397): accuracy: 0.7864, mnli_loss: 0.5267
09/05 11:41:51 PM: Update 16417: task mnli, batch 417 (16417): accuracy: 0.7879, mnli_loss: 0.5224
09/05 11:42:01 PM: Update 16434: task mnli, batch 434 (16434): accuracy: 0.7871, mnli_loss: 0.5236
09/05 11:42:12 PM: Update 16453: task mnli, batch 453 (16453): accuracy: 0.7885, mnli_loss: 0.5219
09/05 11:42:22 PM: Update 16473: task mnli, batch 473 (16473): accuracy: 0.7898, mnli_loss: 0.5195
09/05 11:42:32 PM: Update 16490: task mnli, batch 490 (16490): accuracy: 0.7902, mnli_loss: 0.5181
09/05 11:42:43 PM: Update 16509: task mnli, batch 509 (16509): accuracy: 0.7919, mnli_loss: 0.5139
09/05 11:42:53 PM: Update 16528: task mnli, batch 528 (16528): accuracy: 0.7914, mnli_loss: 0.5146
09/05 11:43:03 PM: Update 16548: task mnli, batch 548 (16548): accuracy: 0.7928, mnli_loss: 0.5135
09/05 11:43:13 PM: Update 16566: task mnli, batch 566 (16566): accuracy: 0.7929, mnli_loss: 0.5135
09/05 11:43:23 PM: Update 16585: task mnli, batch 585 (16585): accuracy: 0.7933, mnli_loss: 0.5132
09/05 11:43:34 PM: Update 16604: task mnli, batch 604 (16604): accuracy: 0.7935, mnli_loss: 0.5122
09/05 11:43:44 PM: Update 16623: task mnli, batch 623 (16623): accuracy: 0.7932, mnli_loss: 0.5126
09/05 11:43:54 PM: Update 16643: task mnli, batch 643 (16643): accuracy: 0.7930, mnli_loss: 0.5141
09/05 11:44:04 PM: Update 16661: task mnli, batch 661 (16661): accuracy: 0.7936, mnli_loss: 0.5145
09/05 11:44:15 PM: Update 16679: task mnli, batch 679 (16679): accuracy: 0.7936, mnli_loss: 0.5140
09/05 11:44:25 PM: Update 16698: task mnli, batch 698 (16698): accuracy: 0.7942, mnli_loss: 0.5130
09/05 11:44:36 PM: Update 16718: task mnli, batch 718 (16718): accuracy: 0.7949, mnli_loss: 0.5116
09/05 11:44:46 PM: Update 16739: task mnli, batch 739 (16739): accuracy: 0.7952, mnli_loss: 0.5104
09/05 11:44:56 PM: Update 16759: task mnli, batch 759 (16759): accuracy: 0.7955, mnli_loss: 0.5097
09/05 11:45:07 PM: Update 16779: task mnli, batch 779 (16779): accuracy: 0.7962, mnli_loss: 0.5087
09/05 11:45:17 PM: Update 16794: task mnli, batch 794 (16794): accuracy: 0.7961, mnli_loss: 0.5080
09/05 11:45:27 PM: Update 16812: task mnli, batch 812 (16812): accuracy: 0.7962, mnli_loss: 0.5078
09/05 11:45:38 PM: Update 16832: task mnli, batch 832 (16832): accuracy: 0.7966, mnli_loss: 0.5076
09/05 11:45:48 PM: Update 16852: task mnli, batch 852 (16852): accuracy: 0.7962, mnli_loss: 0.5082
09/05 11:45:58 PM: Update 16872: task mnli, batch 872 (16872): accuracy: 0.7965, mnli_loss: 0.5076
09/05 11:46:08 PM: Update 16890: task mnli, batch 890 (16890): accuracy: 0.7966, mnli_loss: 0.5077
09/05 11:46:19 PM: Update 16911: task mnli, batch 911 (16911): accuracy: 0.7971, mnli_loss: 0.5067
09/05 11:46:29 PM: Update 16929: task mnli, batch 929 (16929): accuracy: 0.7974, mnli_loss: 0.5072
09/05 11:46:39 PM: Update 16948: task mnli, batch 948 (16948): accuracy: 0.7982, mnli_loss: 0.5052
09/05 11:46:49 PM: Update 16968: task mnli, batch 968 (16968): accuracy: 0.7986, mnli_loss: 0.5042
09/05 11:47:00 PM: Update 16988: task mnli, batch 988 (16988): accuracy: 0.7983, mnli_loss: 0.5048
09/05 11:47:07 PM: ***** Step 17000 / Validation 17 *****
09/05 11:47:07 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:47:07 PM: Validating...
09/05 11:47:10 PM: Evaluate: task mnli, batch 14 (209): accuracy: 0.8244, mnli_loss: 0.4463
09/05 11:47:20 PM: Evaluate: task mnli, batch 64 (209): accuracy: 0.8223, mnli_loss: 0.4668
09/05 11:47:30 PM: Evaluate: task mnli, batch 114 (209): accuracy: 0.8081, mnli_loss: 0.4917
09/05 11:47:40 PM: Evaluate: task mnli, batch 164 (209): accuracy: 0.8087, mnli_loss: 0.4932
09/05 11:47:50 PM: Best result seen so far for mnli.
09/05 11:47:50 PM: Best result seen so far for micro.
09/05 11:47:50 PM: Best result seen so far for macro.
09/05 11:47:50 PM: Updating LR scheduler:
09/05 11:47:50 PM: 	Best result seen so far for macro_avg: 0.806
09/05 11:47:50 PM: 	# validation passes without improvement: 0
09/05 11:47:50 PM: mnli_loss: training: 0.505086 validation: 0.500158
09/05 11:47:50 PM: macro_avg: validation: 0.805600
09/05 11:47:50 PM: micro_avg: validation: 0.805600
09/05 11:47:50 PM: mnli_accuracy: training: 0.798198 validation: 0.805600
09/05 11:47:50 PM: Global learning rate: 1e-05
09/05 11:47:50 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:47:52 PM: Update 17001: task mnli, batch 1 (17001): accuracy: 0.8333, mnli_loss: 0.3315
09/05 11:48:02 PM: Update 17020: task mnli, batch 20 (17020): accuracy: 0.8021, mnli_loss: 0.4834
09/05 11:48:13 PM: Update 17038: task mnli, batch 38 (17038): accuracy: 0.7851, mnli_loss: 0.5297
09/05 11:48:23 PM: Update 17058: task mnli, batch 58 (17058): accuracy: 0.7945, mnli_loss: 0.5051
09/05 11:48:33 PM: Update 17077: task mnli, batch 77 (17077): accuracy: 0.7982, mnli_loss: 0.4922
09/05 11:48:44 PM: Update 17095: task mnli, batch 95 (17095): accuracy: 0.7947, mnli_loss: 0.5009
09/05 11:48:54 PM: Update 17114: task mnli, batch 114 (17114): accuracy: 0.7950, mnli_loss: 0.5017
09/05 11:49:04 PM: Update 17133: task mnli, batch 133 (17133): accuracy: 0.7986, mnli_loss: 0.4996
09/05 11:49:15 PM: Update 17153: task mnli, batch 153 (17153): accuracy: 0.8015, mnli_loss: 0.4939
09/05 11:49:25 PM: Update 17171: task mnli, batch 171 (17171): accuracy: 0.8017, mnli_loss: 0.4905
09/05 11:49:35 PM: Update 17190: task mnli, batch 190 (17190): accuracy: 0.8000, mnli_loss: 0.4958
09/05 11:49:46 PM: Update 17209: task mnli, batch 209 (17209): accuracy: 0.7998, mnli_loss: 0.4935
09/05 11:49:56 PM: Update 17224: task mnli, batch 224 (17224): accuracy: 0.7992, mnli_loss: 0.4934
09/05 11:50:07 PM: Update 17244: task mnli, batch 244 (17244): accuracy: 0.7989, mnli_loss: 0.4944
09/05 11:50:17 PM: Update 17264: task mnli, batch 264 (17264): accuracy: 0.7980, mnli_loss: 0.4956
09/05 11:50:27 PM: Update 17283: task mnli, batch 283 (17283): accuracy: 0.8004, mnli_loss: 0.4893
09/05 11:50:37 PM: Update 17302: task mnli, batch 302 (17302): accuracy: 0.8000, mnli_loss: 0.4887
09/05 11:50:48 PM: Update 17319: task mnli, batch 319 (17319): accuracy: 0.7990, mnli_loss: 0.4918
09/05 11:50:58 PM: Update 17337: task mnli, batch 337 (17337): accuracy: 0.7998, mnli_loss: 0.4910
09/05 11:51:08 PM: Update 17355: task mnli, batch 355 (17355): accuracy: 0.7988, mnli_loss: 0.4931
09/05 11:51:19 PM: Update 17375: task mnli, batch 375 (17375): accuracy: 0.7983, mnli_loss: 0.4938
09/05 11:51:29 PM: Update 17395: task mnli, batch 395 (17395): accuracy: 0.7982, mnli_loss: 0.4921
09/05 11:51:39 PM: Update 17412: task mnli, batch 412 (17412): accuracy: 0.7980, mnli_loss: 0.4944
09/05 11:51:49 PM: Update 17431: task mnli, batch 431 (17431): accuracy: 0.7975, mnli_loss: 0.4960
09/05 11:52:00 PM: Update 17450: task mnli, batch 450 (17450): accuracy: 0.7965, mnli_loss: 0.4975
09/05 11:52:10 PM: Update 17470: task mnli, batch 470 (17470): accuracy: 0.7968, mnli_loss: 0.4976
09/05 11:52:20 PM: Update 17489: task mnli, batch 489 (17489): accuracy: 0.7960, mnli_loss: 0.4985
09/05 11:52:31 PM: Update 17507: task mnli, batch 507 (17507): accuracy: 0.7962, mnli_loss: 0.4980
09/05 11:52:41 PM: Update 17525: task mnli, batch 525 (17525): accuracy: 0.7953, mnli_loss: 0.5004
09/05 11:52:51 PM: Update 17546: task mnli, batch 546 (17546): accuracy: 0.7966, mnli_loss: 0.4987
09/05 11:53:02 PM: Update 17566: task mnli, batch 566 (17566): accuracy: 0.7968, mnli_loss: 0.4991
09/05 11:53:12 PM: Update 17585: task mnli, batch 585 (17585): accuracy: 0.7970, mnli_loss: 0.4993
09/05 11:53:22 PM: Update 17605: task mnli, batch 605 (17605): accuracy: 0.7971, mnli_loss: 0.4997
09/05 11:53:33 PM: Update 17623: task mnli, batch 623 (17623): accuracy: 0.7976, mnli_loss: 0.4981
09/05 11:53:43 PM: Update 17636: task mnli, batch 636 (17636): accuracy: 0.7974, mnli_loss: 0.4983
09/05 11:53:53 PM: Update 17655: task mnli, batch 655 (17655): accuracy: 0.7981, mnli_loss: 0.4975
09/05 11:54:04 PM: Update 17674: task mnli, batch 674 (17674): accuracy: 0.7968, mnli_loss: 0.5006
09/05 11:54:14 PM: Update 17692: task mnli, batch 692 (17692): accuracy: 0.7966, mnli_loss: 0.5009
09/05 11:54:24 PM: Update 17711: task mnli, batch 711 (17711): accuracy: 0.7966, mnli_loss: 0.5015
09/05 11:54:35 PM: Update 17730: task mnli, batch 730 (17730): accuracy: 0.7967, mnli_loss: 0.5024
09/05 11:54:45 PM: Update 17749: task mnli, batch 749 (17749): accuracy: 0.7972, mnli_loss: 0.5009
09/05 11:54:55 PM: Update 17766: task mnli, batch 766 (17766): accuracy: 0.7977, mnli_loss: 0.5003
09/05 11:55:05 PM: Update 17784: task mnli, batch 784 (17784): accuracy: 0.7976, mnli_loss: 0.5005
09/05 11:55:15 PM: Update 17803: task mnli, batch 803 (17803): accuracy: 0.7983, mnli_loss: 0.4987
09/05 11:55:26 PM: Update 17823: task mnli, batch 823 (17823): accuracy: 0.7986, mnli_loss: 0.4983
09/05 11:55:36 PM: Update 17842: task mnli, batch 842 (17842): accuracy: 0.7989, mnli_loss: 0.4978
09/05 11:55:46 PM: Update 17860: task mnli, batch 860 (17860): accuracy: 0.7990, mnli_loss: 0.4973
09/05 11:55:57 PM: Update 17881: task mnli, batch 881 (17881): accuracy: 0.7993, mnli_loss: 0.4973
09/05 11:56:07 PM: Update 17901: task mnli, batch 901 (17901): accuracy: 0.7994, mnli_loss: 0.4974
09/05 11:56:17 PM: Update 17921: task mnli, batch 921 (17921): accuracy: 0.7999, mnli_loss: 0.4972
09/05 11:56:27 PM: Update 17939: task mnli, batch 939 (17939): accuracy: 0.8001, mnli_loss: 0.4965
09/05 11:56:38 PM: Update 17957: task mnli, batch 957 (17957): accuracy: 0.7995, mnli_loss: 0.4972
09/05 11:56:48 PM: Update 17977: task mnli, batch 977 (17977): accuracy: 0.7995, mnli_loss: 0.4970
09/05 11:56:58 PM: Update 17997: task mnli, batch 997 (17997): accuracy: 0.7998, mnli_loss: 0.4963
09/05 11:57:00 PM: ***** Step 18000 / Validation 18 *****
09/05 11:57:00 PM: mnli: trained on 1000 batches, 0.061 epochs
09/05 11:57:00 PM: Validating...
09/05 11:57:08 PM: Evaluate: task mnli, batch 43 (209): accuracy: 0.8052, mnli_loss: 0.4907
09/05 11:57:18 PM: Evaluate: task mnli, batch 93 (209): accuracy: 0.8051, mnli_loss: 0.4927
09/05 11:57:29 PM: Evaluate: task mnli, batch 143 (209): accuracy: 0.8007, mnli_loss: 0.5020
09/05 11:57:39 PM: Evaluate: task mnli, batch 193 (209): accuracy: 0.8012, mnli_loss: 0.4981
09/05 11:57:42 PM: Updating LR scheduler:
09/05 11:57:42 PM: 	Best result seen so far for macro_avg: 0.806
09/05 11:57:42 PM: 	# validation passes without improvement: 1
09/05 11:57:42 PM: mnli_loss: training: 0.496286 validation: 0.503856
09/05 11:57:42 PM: macro_avg: validation: 0.798200
09/05 11:57:42 PM: micro_avg: validation: 0.798200
09/05 11:57:42 PM: mnli_accuracy: training: 0.799783 validation: 0.798200
09/05 11:57:42 PM: Global learning rate: 1e-05
09/05 11:57:42 PM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/05 11:57:49 PM: Update 18011: task mnli, batch 11 (18011): accuracy: 0.8106, mnli_loss: 0.4665
09/05 11:57:59 PM: Update 18029: task mnli, batch 29 (18029): accuracy: 0.7888, mnli_loss: 0.5296
09/05 11:58:10 PM: Update 18045: task mnli, batch 45 (18045): accuracy: 0.8022, mnli_loss: 0.5066
09/05 11:58:20 PM: Update 18063: task mnli, batch 63 (18063): accuracy: 0.7972, mnli_loss: 0.5118
09/05 11:58:31 PM: Update 18082: task mnli, batch 82 (18082): accuracy: 0.8036, mnli_loss: 0.5054
09/05 11:58:41 PM: Update 18101: task mnli, batch 101 (18101): accuracy: 0.8096, mnli_loss: 0.4920
09/05 11:58:52 PM: Update 18119: task mnli, batch 119 (18119): accuracy: 0.8086, mnli_loss: 0.4887
09/05 11:59:02 PM: Update 18138: task mnli, batch 138 (18138): accuracy: 0.8093, mnli_loss: 0.4915
09/05 11:59:12 PM: Update 18157: task mnli, batch 157 (18157): accuracy: 0.8106, mnli_loss: 0.4892
09/05 11:59:22 PM: Update 18178: task mnli, batch 178 (18178): accuracy: 0.8121, mnli_loss: 0.4857
09/05 11:59:33 PM: Update 18197: task mnli, batch 197 (18197): accuracy: 0.8078, mnli_loss: 0.4896
09/05 11:59:43 PM: Update 18218: task mnli, batch 218 (18218): accuracy: 0.8086, mnli_loss: 0.4855
09/05 11:59:54 PM: Update 18236: task mnli, batch 236 (18236): accuracy: 0.8071, mnli_loss: 0.4870
09/06 12:00:04 AM: Update 18253: task mnli, batch 253 (18253): accuracy: 0.8072, mnli_loss: 0.4875
09/06 12:00:14 AM: Update 18272: task mnli, batch 272 (18272): accuracy: 0.8090, mnli_loss: 0.4866
09/06 12:00:25 AM: Update 18292: task mnli, batch 292 (18292): accuracy: 0.8079, mnli_loss: 0.4903
09/06 12:00:35 AM: Update 18312: task mnli, batch 312 (18312): accuracy: 0.8094, mnli_loss: 0.4885
09/06 12:00:46 AM: Update 18332: task mnli, batch 332 (18332): accuracy: 0.8087, mnli_loss: 0.4875
09/06 12:00:56 AM: Update 18351: task mnli, batch 351 (18351): accuracy: 0.8093, mnli_loss: 0.4888
09/06 12:01:06 AM: Update 18370: task mnli, batch 370 (18370): accuracy: 0.8089, mnli_loss: 0.4881
09/06 12:01:16 AM: Update 18389: task mnli, batch 389 (18389): accuracy: 0.8075, mnli_loss: 0.4900
09/06 12:01:26 AM: Update 18407: task mnli, batch 407 (18407): accuracy: 0.8055, mnli_loss: 0.4940
09/06 12:01:37 AM: Update 18425: task mnli, batch 425 (18425): accuracy: 0.8042, mnli_loss: 0.4971
09/06 12:01:47 AM: Update 18443: task mnli, batch 443 (18443): accuracy: 0.8037, mnli_loss: 0.4966
09/06 12:02:01 AM: Update 18462: task mnli, batch 462 (18462): accuracy: 0.8027, mnli_loss: 0.4983
09/06 12:02:11 AM: Update 18480: task mnli, batch 480 (18480): accuracy: 0.8032, mnli_loss: 0.4985
09/06 12:02:22 AM: Update 18499: task mnli, batch 499 (18499): accuracy: 0.8041, mnli_loss: 0.4969
09/06 12:02:32 AM: Update 18517: task mnli, batch 517 (18517): accuracy: 0.8044, mnli_loss: 0.4967
09/06 12:02:42 AM: Update 18537: task mnli, batch 537 (18537): accuracy: 0.8045, mnli_loss: 0.4973
09/06 12:02:52 AM: Update 18556: task mnli, batch 556 (18556): accuracy: 0.8039, mnli_loss: 0.4975
09/06 12:03:02 AM: Update 18576: task mnli, batch 576 (18576): accuracy: 0.8044, mnli_loss: 0.4979
09/06 12:03:12 AM: Update 18594: task mnli, batch 594 (18594): accuracy: 0.8048, mnli_loss: 0.4968
09/06 12:03:23 AM: Update 18612: task mnli, batch 612 (18612): accuracy: 0.8042, mnli_loss: 0.4973
09/06 12:03:33 AM: Update 18630: task mnli, batch 630 (18630): accuracy: 0.8042, mnli_loss: 0.4984
09/06 12:03:43 AM: Update 18650: task mnli, batch 650 (18650): accuracy: 0.8045, mnli_loss: 0.4978
09/06 12:03:53 AM: Update 18668: task mnli, batch 668 (18668): accuracy: 0.8039, mnli_loss: 0.4986
09/06 12:04:04 AM: Update 18686: task mnli, batch 686 (18686): accuracy: 0.8042, mnli_loss: 0.4981
09/06 12:04:14 AM: Update 18707: task mnli, batch 707 (18707): accuracy: 0.8046, mnli_loss: 0.4957
09/06 12:04:24 AM: Update 18725: task mnli, batch 725 (18725): accuracy: 0.8047, mnli_loss: 0.4948
09/06 12:04:35 AM: Update 18745: task mnli, batch 745 (18745): accuracy: 0.8046, mnli_loss: 0.4950
09/06 12:04:45 AM: Update 18765: task mnli, batch 765 (18765): accuracy: 0.8047, mnli_loss: 0.4939
09/06 12:04:55 AM: Update 18784: task mnli, batch 784 (18784): accuracy: 0.8049, mnli_loss: 0.4933
09/06 12:05:06 AM: Update 18803: task mnli, batch 803 (18803): accuracy: 0.8055, mnli_loss: 0.4929
09/06 12:05:16 AM: Update 18822: task mnli, batch 822 (18822): accuracy: 0.8058, mnli_loss: 0.4923
09/06 12:05:26 AM: Update 18842: task mnli, batch 842 (18842): accuracy: 0.8057, mnli_loss: 0.4921
09/06 12:05:36 AM: Update 18860: task mnli, batch 860 (18860): accuracy: 0.8067, mnli_loss: 0.4906
09/06 12:05:49 AM: Update 18879: task mnli, batch 879 (18879): accuracy: 0.8067, mnli_loss: 0.4897
09/06 12:06:00 AM: Update 18899: task mnli, batch 899 (18899): accuracy: 0.8063, mnli_loss: 0.4898
09/06 12:06:10 AM: Update 18917: task mnli, batch 917 (18917): accuracy: 0.8065, mnli_loss: 0.4893
09/06 12:06:20 AM: Update 18937: task mnli, batch 937 (18937): accuracy: 0.8061, mnli_loss: 0.4906
09/06 12:06:31 AM: Update 18955: task mnli, batch 955 (18955): accuracy: 0.8056, mnli_loss: 0.4912
09/06 12:06:41 AM: Update 18974: task mnli, batch 974 (18974): accuracy: 0.8059, mnli_loss: 0.4906
09/06 12:06:51 AM: Update 18993: task mnli, batch 993 (18993): accuracy: 0.8057, mnli_loss: 0.4910
09/06 12:06:55 AM: ***** Step 19000 / Validation 19 *****
09/06 12:06:55 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:06:55 AM: Validating...
09/06 12:07:01 AM: Evaluate: task mnli, batch 34 (209): accuracy: 0.8027, mnli_loss: 0.4897
09/06 12:07:11 AM: Evaluate: task mnli, batch 84 (209): accuracy: 0.8110, mnli_loss: 0.4810
09/06 12:07:22 AM: Evaluate: task mnli, batch 134 (209): accuracy: 0.8019, mnli_loss: 0.4998
09/06 12:07:32 AM: Evaluate: task mnli, batch 184 (209): accuracy: 0.8057, mnli_loss: 0.5021
09/06 12:07:37 AM: Updating LR scheduler:
09/06 12:07:37 AM: 	Best result seen so far for macro_avg: 0.806
09/06 12:07:37 AM: 	# validation passes without improvement: 2
09/06 12:07:37 AM: mnli_loss: training: 0.490509 validation: 0.507864
09/06 12:07:37 AM: macro_avg: validation: 0.802800
09/06 12:07:37 AM: micro_avg: validation: 0.802800
09/06 12:07:37 AM: mnli_accuracy: training: 0.805973 validation: 0.802800
09/06 12:07:37 AM: Global learning rate: 1e-05
09/06 12:07:37 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:07:42 AM: Update 19008: task mnli, batch 8 (19008): accuracy: 0.7917, mnli_loss: 0.4855
09/06 12:07:52 AM: Update 19027: task mnli, batch 27 (19027): accuracy: 0.7793, mnli_loss: 0.5304
09/06 12:08:03 AM: Update 19046: task mnli, batch 46 (19046): accuracy: 0.7853, mnli_loss: 0.5247
09/06 12:08:13 AM: Update 19064: task mnli, batch 64 (19064): accuracy: 0.8086, mnli_loss: 0.4835
09/06 12:08:23 AM: Update 19082: task mnli, batch 82 (19082): accuracy: 0.8013, mnli_loss: 0.5037
09/06 12:08:33 AM: Update 19101: task mnli, batch 101 (19101): accuracy: 0.8086, mnli_loss: 0.4892
09/06 12:08:43 AM: Update 19119: task mnli, batch 119 (19119): accuracy: 0.8106, mnli_loss: 0.4830
09/06 12:08:54 AM: Update 19137: task mnli, batch 137 (19137): accuracy: 0.8102, mnli_loss: 0.4827
09/06 12:09:04 AM: Update 19155: task mnli, batch 155 (19155): accuracy: 0.8086, mnli_loss: 0.4801
09/06 12:09:15 AM: Update 19174: task mnli, batch 174 (19174): accuracy: 0.8075, mnli_loss: 0.4828
09/06 12:09:25 AM: Update 19193: task mnli, batch 193 (19193): accuracy: 0.8100, mnli_loss: 0.4759
09/06 12:09:35 AM: Update 19211: task mnli, batch 211 (19211): accuracy: 0.8124, mnli_loss: 0.4697
09/06 12:09:45 AM: Update 19230: task mnli, batch 230 (19230): accuracy: 0.8147, mnli_loss: 0.4653
09/06 12:09:56 AM: Update 19250: task mnli, batch 250 (19250): accuracy: 0.8153, mnli_loss: 0.4656
09/06 12:10:06 AM: Update 19271: task mnli, batch 271 (19271): accuracy: 0.8158, mnli_loss: 0.4643
09/06 12:10:16 AM: Update 19290: task mnli, batch 290 (19290): accuracy: 0.8148, mnli_loss: 0.4658
09/06 12:10:27 AM: Update 19304: task mnli, batch 304 (19304): accuracy: 0.8146, mnli_loss: 0.4635
09/06 12:10:37 AM: Update 19323: task mnli, batch 323 (19323): accuracy: 0.8146, mnli_loss: 0.4634
09/06 12:10:47 AM: Update 19342: task mnli, batch 342 (19342): accuracy: 0.8145, mnli_loss: 0.4664
09/06 12:10:57 AM: Update 19361: task mnli, batch 361 (19361): accuracy: 0.8140, mnli_loss: 0.4688
09/06 12:11:07 AM: Update 19379: task mnli, batch 379 (19379): accuracy: 0.8134, mnli_loss: 0.4694
09/06 12:11:18 AM: Update 19398: task mnli, batch 398 (19398): accuracy: 0.8131, mnli_loss: 0.4694
09/06 12:11:28 AM: Update 19417: task mnli, batch 417 (19417): accuracy: 0.8137, mnli_loss: 0.4667
09/06 12:11:38 AM: Update 19435: task mnli, batch 435 (19435): accuracy: 0.8136, mnli_loss: 0.4673
09/06 12:11:48 AM: Update 19455: task mnli, batch 455 (19455): accuracy: 0.8136, mnli_loss: 0.4670
09/06 12:11:59 AM: Update 19473: task mnli, batch 473 (19473): accuracy: 0.8139, mnli_loss: 0.4670
09/06 12:12:09 AM: Update 19492: task mnli, batch 492 (19492): accuracy: 0.8145, mnli_loss: 0.4662
09/06 12:12:19 AM: Update 19511: task mnli, batch 511 (19511): accuracy: 0.8152, mnli_loss: 0.4646
09/06 12:12:30 AM: Update 19531: task mnli, batch 531 (19531): accuracy: 0.8152, mnli_loss: 0.4640
09/06 12:12:40 AM: Update 19551: task mnli, batch 551 (19551): accuracy: 0.8164, mnli_loss: 0.4624
09/06 12:12:50 AM: Update 19568: task mnli, batch 568 (19568): accuracy: 0.8166, mnli_loss: 0.4611
09/06 12:13:01 AM: Update 19587: task mnli, batch 587 (19587): accuracy: 0.8171, mnli_loss: 0.4608
09/06 12:13:11 AM: Update 19606: task mnli, batch 606 (19606): accuracy: 0.8183, mnli_loss: 0.4584
09/06 12:13:21 AM: Update 19626: task mnli, batch 626 (19626): accuracy: 0.8184, mnli_loss: 0.4589
09/06 12:13:32 AM: Update 19645: task mnli, batch 645 (19645): accuracy: 0.8176, mnli_loss: 0.4595
09/06 12:13:42 AM: Update 19664: task mnli, batch 664 (19664): accuracy: 0.8177, mnli_loss: 0.4596
09/06 12:13:52 AM: Update 19682: task mnli, batch 682 (19682): accuracy: 0.8177, mnli_loss: 0.4604
09/06 12:14:02 AM: Update 19700: task mnli, batch 700 (19700): accuracy: 0.8173, mnli_loss: 0.4606
09/06 12:14:13 AM: Update 19714: task mnli, batch 714 (19714): accuracy: 0.8168, mnli_loss: 0.4617
09/06 12:14:23 AM: Update 19734: task mnli, batch 734 (19734): accuracy: 0.8171, mnli_loss: 0.4618
09/06 12:14:33 AM: Update 19753: task mnli, batch 753 (19753): accuracy: 0.8168, mnli_loss: 0.4633
09/06 12:14:44 AM: Update 19772: task mnli, batch 772 (19772): accuracy: 0.8160, mnli_loss: 0.4657
09/06 12:14:54 AM: Update 19789: task mnli, batch 789 (19789): accuracy: 0.8159, mnli_loss: 0.4655
09/06 12:15:05 AM: Update 19807: task mnli, batch 807 (19807): accuracy: 0.8158, mnli_loss: 0.4654
09/06 12:15:15 AM: Update 19827: task mnli, batch 827 (19827): accuracy: 0.8162, mnli_loss: 0.4650
09/06 12:15:25 AM: Update 19846: task mnli, batch 846 (19846): accuracy: 0.8164, mnli_loss: 0.4650
09/06 12:15:36 AM: Update 19865: task mnli, batch 865 (19865): accuracy: 0.8160, mnli_loss: 0.4656
09/06 12:15:46 AM: Update 19884: task mnli, batch 884 (19884): accuracy: 0.8158, mnli_loss: 0.4660
09/06 12:15:56 AM: Update 19902: task mnli, batch 902 (19902): accuracy: 0.8164, mnli_loss: 0.4648
09/06 12:16:06 AM: Update 19921: task mnli, batch 921 (19921): accuracy: 0.8167, mnli_loss: 0.4643
09/06 12:16:17 AM: Update 19941: task mnli, batch 941 (19941): accuracy: 0.8164, mnli_loss: 0.4653
09/06 12:16:27 AM: Update 19961: task mnli, batch 961 (19961): accuracy: 0.8156, mnli_loss: 0.4671
09/06 12:16:38 AM: Update 19980: task mnli, batch 980 (19980): accuracy: 0.8157, mnli_loss: 0.4675
09/06 12:16:48 AM: Update 19999: task mnli, batch 999 (19999): accuracy: 0.8157, mnli_loss: 0.4675
09/06 12:16:49 AM: ***** Step 20000 / Validation 20 *****
09/06 12:16:49 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:16:49 AM: Validating...
09/06 12:16:58 AM: Evaluate: task mnli, batch 48 (209): accuracy: 0.8186, mnli_loss: 0.4569
09/06 12:17:08 AM: Evaluate: task mnli, batch 98 (209): accuracy: 0.8129, mnli_loss: 0.4705
09/06 12:17:18 AM: Evaluate: task mnli, batch 148 (209): accuracy: 0.8102, mnli_loss: 0.4793
09/06 12:17:29 AM: Evaluate: task mnli, batch 198 (209): accuracy: 0.8133, mnli_loss: 0.4758
09/06 12:17:31 AM: Best result seen so far for mnli.
09/06 12:17:31 AM: Best result seen so far for micro.
09/06 12:17:31 AM: Best result seen so far for macro.
09/06 12:17:31 AM: Updating LR scheduler:
09/06 12:17:31 AM: 	Best result seen so far for macro_avg: 0.812
09/06 12:17:31 AM: 	# validation passes without improvement: 0
09/06 12:17:31 AM: mnli_loss: training: 0.467508 validation: 0.479994
09/06 12:17:31 AM: macro_avg: validation: 0.811800
09/06 12:17:31 AM: micro_avg: validation: 0.811800
09/06 12:17:31 AM: mnli_accuracy: training: 0.815627 validation: 0.811800
09/06 12:17:31 AM: Global learning rate: 1e-05
09/06 12:17:31 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:17:39 AM: Update 20013: task mnli, batch 13 (20013): accuracy: 0.8109, mnli_loss: 0.4524
09/06 12:17:49 AM: Update 20033: task mnli, batch 33 (20033): accuracy: 0.8119, mnli_loss: 0.4586
09/06 12:18:00 AM: Update 20051: task mnli, batch 51 (20051): accuracy: 0.8105, mnli_loss: 0.4699
09/06 12:18:10 AM: Update 20070: task mnli, batch 70 (20070): accuracy: 0.8179, mnli_loss: 0.4697
09/06 12:18:20 AM: Update 20089: task mnli, batch 89 (20089): accuracy: 0.8212, mnli_loss: 0.4591
09/06 12:18:31 AM: Update 20110: task mnli, batch 110 (20110): accuracy: 0.8261, mnli_loss: 0.4530
09/06 12:18:42 AM: Update 20129: task mnli, batch 129 (20129): accuracy: 0.8243, mnli_loss: 0.4552
09/06 12:18:52 AM: Update 20141: task mnli, batch 141 (20141): accuracy: 0.8232, mnli_loss: 0.4594
09/06 12:19:02 AM: Update 20159: task mnli, batch 159 (20159): accuracy: 0.8262, mnli_loss: 0.4555
09/06 12:19:13 AM: Update 20177: task mnli, batch 177 (20177): accuracy: 0.8248, mnli_loss: 0.4552
09/06 12:19:23 AM: Update 20194: task mnli, batch 194 (20194): accuracy: 0.8193, mnli_loss: 0.4656
09/06 12:19:33 AM: Update 20213: task mnli, batch 213 (20213): accuracy: 0.8217, mnli_loss: 0.4577
09/06 12:19:43 AM: Update 20230: task mnli, batch 230 (20230): accuracy: 0.8211, mnli_loss: 0.4584
09/06 12:19:54 AM: Update 20250: task mnli, batch 250 (20250): accuracy: 0.8226, mnli_loss: 0.4563
09/06 12:20:04 AM: Update 20270: task mnli, batch 270 (20270): accuracy: 0.8235, mnli_loss: 0.4547
09/06 12:20:15 AM: Update 20290: task mnli, batch 290 (20290): accuracy: 0.8251, mnli_loss: 0.4505
09/06 12:20:25 AM: Update 20310: task mnli, batch 310 (20310): accuracy: 0.8259, mnli_loss: 0.4490
09/06 12:20:35 AM: Update 20329: task mnli, batch 329 (20329): accuracy: 0.8253, mnli_loss: 0.4497
09/06 12:20:45 AM: Update 20349: task mnli, batch 349 (20349): accuracy: 0.8242, mnli_loss: 0.4498
09/06 12:20:55 AM: Update 20367: task mnli, batch 367 (20367): accuracy: 0.8247, mnli_loss: 0.4495
09/06 12:21:06 AM: Update 20385: task mnli, batch 385 (20385): accuracy: 0.8261, mnli_loss: 0.4469
09/06 12:21:16 AM: Update 20405: task mnli, batch 405 (20405): accuracy: 0.8266, mnli_loss: 0.4461
09/06 12:21:27 AM: Update 20424: task mnli, batch 424 (20424): accuracy: 0.8260, mnli_loss: 0.4468
09/06 12:21:37 AM: Update 20444: task mnli, batch 444 (20444): accuracy: 0.8272, mnli_loss: 0.4453
09/06 12:21:47 AM: Update 20463: task mnli, batch 463 (20463): accuracy: 0.8249, mnli_loss: 0.4499
09/06 12:21:58 AM: Update 20483: task mnli, batch 483 (20483): accuracy: 0.8254, mnli_loss: 0.4480
09/06 12:22:08 AM: Update 20503: task mnli, batch 503 (20503): accuracy: 0.8256, mnli_loss: 0.4465
09/06 12:22:18 AM: Update 20521: task mnli, batch 521 (20521): accuracy: 0.8252, mnli_loss: 0.4474
09/06 12:22:29 AM: Update 20541: task mnli, batch 541 (20541): accuracy: 0.8260, mnli_loss: 0.4457
09/06 12:22:39 AM: Update 20555: task mnli, batch 555 (20555): accuracy: 0.8263, mnli_loss: 0.4452
09/06 12:22:49 AM: Update 20575: task mnli, batch 575 (20575): accuracy: 0.8268, mnli_loss: 0.4455
09/06 12:22:59 AM: Update 20595: task mnli, batch 595 (20595): accuracy: 0.8272, mnli_loss: 0.4440
09/06 12:23:10 AM: Update 20615: task mnli, batch 615 (20615): accuracy: 0.8279, mnli_loss: 0.4418
09/06 12:23:20 AM: Update 20634: task mnli, batch 634 (20634): accuracy: 0.8287, mnli_loss: 0.4398
09/06 12:23:30 AM: Update 20654: task mnli, batch 654 (20654): accuracy: 0.8295, mnli_loss: 0.4382
09/06 12:23:41 AM: Update 20673: task mnli, batch 673 (20673): accuracy: 0.8303, mnli_loss: 0.4373
09/06 12:23:51 AM: Update 20691: task mnli, batch 691 (20691): accuracy: 0.8301, mnli_loss: 0.4386
09/06 12:24:01 AM: Update 20710: task mnli, batch 710 (20710): accuracy: 0.8302, mnli_loss: 0.4391
09/06 12:24:11 AM: Update 20728: task mnli, batch 728 (20728): accuracy: 0.8298, mnli_loss: 0.4394
09/06 12:24:22 AM: Update 20747: task mnli, batch 747 (20747): accuracy: 0.8304, mnli_loss: 0.4388
09/06 12:24:32 AM: Update 20765: task mnli, batch 765 (20765): accuracy: 0.8301, mnli_loss: 0.4393
09/06 12:24:42 AM: Update 20783: task mnli, batch 783 (20783): accuracy: 0.8304, mnli_loss: 0.4390
09/06 12:24:52 AM: Update 20801: task mnli, batch 801 (20801): accuracy: 0.8310, mnli_loss: 0.4381
09/06 12:25:02 AM: Update 20820: task mnli, batch 820 (20820): accuracy: 0.8312, mnli_loss: 0.4373
09/06 12:25:13 AM: Update 20839: task mnli, batch 839 (20839): accuracy: 0.8306, mnli_loss: 0.4393
09/06 12:25:23 AM: Update 20857: task mnli, batch 857 (20857): accuracy: 0.8299, mnli_loss: 0.4400
09/06 12:25:34 AM: Update 20877: task mnli, batch 877 (20877): accuracy: 0.8302, mnli_loss: 0.4397
09/06 12:25:44 AM: Update 20897: task mnli, batch 897 (20897): accuracy: 0.8303, mnli_loss: 0.4397
09/06 12:25:55 AM: Update 20916: task mnli, batch 916 (20916): accuracy: 0.8296, mnli_loss: 0.4415
09/06 12:26:05 AM: Update 20935: task mnli, batch 935 (20935): accuracy: 0.8292, mnli_loss: 0.4421
09/06 12:26:15 AM: Update 20954: task mnli, batch 954 (20954): accuracy: 0.8289, mnli_loss: 0.4426
09/06 12:26:25 AM: Update 20967: task mnli, batch 967 (20967): accuracy: 0.8288, mnli_loss: 0.4430
09/06 12:26:35 AM: Update 20986: task mnli, batch 986 (20986): accuracy: 0.8285, mnli_loss: 0.4432
09/06 12:26:43 AM: ***** Step 21000 / Validation 21 *****
09/06 12:26:43 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:26:43 AM: Validating...
09/06 12:26:46 AM: Evaluate: task mnli, batch 14 (209): accuracy: 0.8393, mnli_loss: 0.4346
09/06 12:26:56 AM: Evaluate: task mnli, batch 65 (209): accuracy: 0.8179, mnli_loss: 0.4660
09/06 12:27:06 AM: Evaluate: task mnli, batch 115 (209): accuracy: 0.8083, mnli_loss: 0.4811
09/06 12:27:16 AM: Evaluate: task mnli, batch 165 (209): accuracy: 0.8134, mnli_loss: 0.4774
09/06 12:27:25 AM: Updating LR scheduler:
09/06 12:27:25 AM: 	Best result seen so far for macro_avg: 0.812
09/06 12:27:25 AM: 	# validation passes without improvement: 1
09/06 12:27:25 AM: mnli_loss: training: 0.443068 validation: 0.486509
09/06 12:27:25 AM: macro_avg: validation: 0.809800
09/06 12:27:25 AM: micro_avg: validation: 0.809800
09/06 12:27:25 AM: mnli_accuracy: training: 0.828203 validation: 0.809800
09/06 12:27:25 AM: Global learning rate: 1e-05
09/06 12:27:25 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:27:26 AM: Update 21001: task mnli, batch 1 (21001): accuracy: 0.8750, mnli_loss: 0.2805
09/06 12:27:37 AM: Update 21019: task mnli, batch 19 (21019): accuracy: 0.8311, mnli_loss: 0.4193
09/06 12:27:47 AM: Update 21038: task mnli, batch 38 (21038): accuracy: 0.8366, mnli_loss: 0.4355
09/06 12:27:57 AM: Update 21057: task mnli, batch 57 (21057): accuracy: 0.8246, mnli_loss: 0.4589
09/06 12:28:08 AM: Update 21076: task mnli, batch 76 (21076): accuracy: 0.8213, mnli_loss: 0.4529
09/06 12:28:18 AM: Update 21095: task mnli, batch 95 (21095): accuracy: 0.8193, mnli_loss: 0.4475
09/06 12:28:28 AM: Update 21114: task mnli, batch 114 (21114): accuracy: 0.8238, mnli_loss: 0.4382
09/06 12:28:38 AM: Update 21132: task mnli, batch 132 (21132): accuracy: 0.8264, mnli_loss: 0.4375
09/06 12:28:48 AM: Update 21151: task mnli, batch 151 (21151): accuracy: 0.8248, mnli_loss: 0.4435
09/06 12:28:58 AM: Update 21170: task mnli, batch 170 (21170): accuracy: 0.8275, mnli_loss: 0.4417
09/06 12:29:09 AM: Update 21188: task mnli, batch 188 (21188): accuracy: 0.8251, mnli_loss: 0.4435
09/06 12:29:19 AM: Update 21207: task mnli, batch 207 (21207): accuracy: 0.8249, mnli_loss: 0.4431
09/06 12:29:29 AM: Update 21225: task mnli, batch 225 (21225): accuracy: 0.8204, mnli_loss: 0.4494
09/06 12:29:40 AM: Update 21244: task mnli, batch 244 (21244): accuracy: 0.8202, mnli_loss: 0.4501
09/06 12:29:50 AM: Update 21263: task mnli, batch 263 (21263): accuracy: 0.8194, mnli_loss: 0.4514
09/06 12:30:00 AM: Update 21282: task mnli, batch 282 (21282): accuracy: 0.8191, mnli_loss: 0.4533
09/06 12:30:11 AM: Update 21300: task mnli, batch 300 (21300): accuracy: 0.8187, mnli_loss: 0.4533
09/06 12:30:21 AM: Update 21319: task mnli, batch 319 (21319): accuracy: 0.8187, mnli_loss: 0.4536
09/06 12:30:31 AM: Update 21338: task mnli, batch 338 (21338): accuracy: 0.8201, mnli_loss: 0.4508
09/06 12:30:41 AM: Update 21358: task mnli, batch 358 (21358): accuracy: 0.8210, mnli_loss: 0.4501
09/06 12:30:52 AM: Update 21378: task mnli, batch 378 (21378): accuracy: 0.8220, mnli_loss: 0.4483
09/06 12:31:02 AM: Update 21390: task mnli, batch 390 (21390): accuracy: 0.8226, mnli_loss: 0.4471
09/06 12:31:12 AM: Update 21407: task mnli, batch 407 (21407): accuracy: 0.8218, mnli_loss: 0.4486
09/06 12:31:22 AM: Update 21426: task mnli, batch 426 (21426): accuracy: 0.8219, mnli_loss: 0.4481
09/06 12:31:32 AM: Update 21445: task mnli, batch 445 (21445): accuracy: 0.8229, mnli_loss: 0.4466
09/06 12:31:43 AM: Update 21463: task mnli, batch 463 (21463): accuracy: 0.8227, mnli_loss: 0.4478
09/06 12:31:53 AM: Update 21482: task mnli, batch 482 (21482): accuracy: 0.8241, mnli_loss: 0.4458
09/06 12:32:03 AM: Update 21502: task mnli, batch 502 (21502): accuracy: 0.8252, mnli_loss: 0.4436
09/06 12:32:13 AM: Update 21521: task mnli, batch 521 (21521): accuracy: 0.8236, mnli_loss: 0.4467
09/06 12:32:23 AM: Update 21541: task mnli, batch 541 (21541): accuracy: 0.8241, mnli_loss: 0.4471
09/06 12:32:34 AM: Update 21559: task mnli, batch 559 (21559): accuracy: 0.8241, mnli_loss: 0.4467
09/06 12:32:44 AM: Update 21578: task mnli, batch 578 (21578): accuracy: 0.8257, mnli_loss: 0.4441
09/06 12:32:54 AM: Update 21597: task mnli, batch 597 (21597): accuracy: 0.8268, mnli_loss: 0.4421
09/06 12:33:05 AM: Update 21616: task mnli, batch 616 (21616): accuracy: 0.8277, mnli_loss: 0.4408
09/06 12:33:15 AM: Update 21634: task mnli, batch 634 (21634): accuracy: 0.8280, mnli_loss: 0.4409
09/06 12:33:26 AM: Update 21654: task mnli, batch 654 (21654): accuracy: 0.8287, mnli_loss: 0.4397
09/06 12:33:36 AM: Update 21673: task mnli, batch 673 (21673): accuracy: 0.8290, mnli_loss: 0.4394
09/06 12:33:46 AM: Update 21693: task mnli, batch 693 (21693): accuracy: 0.8289, mnli_loss: 0.4400
09/06 12:33:56 AM: Update 21711: task mnli, batch 711 (21711): accuracy: 0.8289, mnli_loss: 0.4402
09/06 12:34:06 AM: Update 21729: task mnli, batch 729 (21729): accuracy: 0.8289, mnli_loss: 0.4405
09/06 12:34:17 AM: Update 21749: task mnli, batch 749 (21749): accuracy: 0.8291, mnli_loss: 0.4401
09/06 12:34:27 AM: Update 21767: task mnli, batch 767 (21767): accuracy: 0.8291, mnli_loss: 0.4406
09/06 12:34:37 AM: Update 21786: task mnli, batch 786 (21786): accuracy: 0.8280, mnli_loss: 0.4413
09/06 12:34:47 AM: Update 21801: task mnli, batch 801 (21801): accuracy: 0.8279, mnli_loss: 0.4416
09/06 12:34:57 AM: Update 21819: task mnli, batch 819 (21819): accuracy: 0.8279, mnli_loss: 0.4419
09/06 12:35:08 AM: Update 21839: task mnli, batch 839 (21839): accuracy: 0.8278, mnli_loss: 0.4413
09/06 12:35:18 AM: Update 21857: task mnli, batch 857 (21857): accuracy: 0.8277, mnli_loss: 0.4419
09/06 12:35:29 AM: Update 21875: task mnli, batch 875 (21875): accuracy: 0.8278, mnli_loss: 0.4412
09/06 12:35:39 AM: Update 21895: task mnli, batch 895 (21895): accuracy: 0.8282, mnli_loss: 0.4401
09/06 12:35:50 AM: Update 21914: task mnli, batch 914 (21914): accuracy: 0.8284, mnli_loss: 0.4395
09/06 12:36:00 AM: Update 21932: task mnli, batch 932 (21932): accuracy: 0.8287, mnli_loss: 0.4387
09/06 12:36:10 AM: Update 21950: task mnli, batch 950 (21950): accuracy: 0.8290, mnli_loss: 0.4387
09/06 12:36:21 AM: Update 21971: task mnli, batch 971 (21971): accuracy: 0.8294, mnli_loss: 0.4376
09/06 12:36:31 AM: Update 21989: task mnli, batch 989 (21989): accuracy: 0.8296, mnli_loss: 0.4366
09/06 12:36:37 AM: ***** Step 22000 / Validation 22 *****
09/06 12:36:37 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:36:37 AM: Validating...
09/06 12:36:41 AM: Evaluate: task mnli, batch 21 (209): accuracy: 0.8313, mnli_loss: 0.4516
09/06 12:36:51 AM: Evaluate: task mnli, batch 71 (209): accuracy: 0.8187, mnli_loss: 0.4736
09/06 12:37:01 AM: Evaluate: task mnli, batch 121 (209): accuracy: 0.8120, mnli_loss: 0.4822
09/06 12:37:11 AM: Evaluate: task mnli, batch 171 (209): accuracy: 0.8151, mnli_loss: 0.4843
09/06 12:37:19 AM: Updating LR scheduler:
09/06 12:37:19 AM: 	Best result seen so far for macro_avg: 0.812
09/06 12:37:19 AM: 	# validation passes without improvement: 2
09/06 12:37:19 AM: mnli_loss: training: 0.436781 validation: 0.496786
09/06 12:37:19 AM: macro_avg: validation: 0.810000
09/06 12:37:19 AM: micro_avg: validation: 0.810000
09/06 12:37:19 AM: mnli_accuracy: training: 0.829386 validation: 0.810000
09/06 12:37:19 AM: Global learning rate: 1e-05
09/06 12:37:19 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:37:22 AM: Update 22003: task mnli, batch 3 (22003): accuracy: 0.8889, mnli_loss: 0.2656
09/06 12:37:32 AM: Update 22023: task mnli, batch 23 (22023): accuracy: 0.8116, mnli_loss: 0.4649
09/06 12:37:42 AM: Update 22041: task mnli, batch 41 (22041): accuracy: 0.8343, mnli_loss: 0.4326
09/06 12:37:52 AM: Update 22060: task mnli, batch 60 (22060): accuracy: 0.8458, mnli_loss: 0.4031
09/06 12:38:03 AM: Update 22078: task mnli, batch 78 (22078): accuracy: 0.8339, mnli_loss: 0.4205
09/06 12:38:13 AM: Update 22096: task mnli, batch 96 (22096): accuracy: 0.8359, mnli_loss: 0.4102
09/06 12:38:23 AM: Update 22116: task mnli, batch 116 (22116): accuracy: 0.8333, mnli_loss: 0.4162
09/06 12:38:34 AM: Update 22136: task mnli, batch 136 (22136): accuracy: 0.8321, mnli_loss: 0.4230
09/06 12:38:44 AM: Update 22156: task mnli, batch 156 (22156): accuracy: 0.8328, mnli_loss: 0.4228
09/06 12:38:54 AM: Update 22178: task mnli, batch 178 (22178): accuracy: 0.8336, mnli_loss: 0.4172
09/06 12:39:04 AM: Update 22195: task mnli, batch 195 (22195): accuracy: 0.8301, mnli_loss: 0.4234
09/06 12:39:15 AM: Update 22213: task mnli, batch 213 (22213): accuracy: 0.8306, mnli_loss: 0.4254
09/06 12:39:25 AM: Update 22228: task mnli, batch 228 (22228): accuracy: 0.8320, mnli_loss: 0.4253
09/06 12:39:35 AM: Update 22246: task mnli, batch 246 (22246): accuracy: 0.8307, mnli_loss: 0.4259
09/06 12:39:45 AM: Update 22263: task mnli, batch 263 (22263): accuracy: 0.8298, mnli_loss: 0.4303
09/06 12:39:56 AM: Update 22281: task mnli, batch 281 (22281): accuracy: 0.8297, mnli_loss: 0.4309
09/06 12:40:06 AM: Update 22300: task mnli, batch 300 (22300): accuracy: 0.8290, mnli_loss: 0.4310
09/06 12:40:17 AM: Update 22319: task mnli, batch 319 (22319): accuracy: 0.8302, mnli_loss: 0.4286
09/06 12:40:27 AM: Update 22339: task mnli, batch 339 (22339): accuracy: 0.8326, mnli_loss: 0.4246
09/06 12:40:37 AM: Update 22359: task mnli, batch 359 (22359): accuracy: 0.8328, mnli_loss: 0.4252
09/06 12:40:47 AM: Update 22377: task mnli, batch 377 (22377): accuracy: 0.8331, mnli_loss: 0.4245
09/06 12:40:58 AM: Update 22396: task mnli, batch 396 (22396): accuracy: 0.8317, mnli_loss: 0.4265
09/06 12:41:08 AM: Update 22416: task mnli, batch 416 (22416): accuracy: 0.8311, mnli_loss: 0.4266
09/06 12:41:18 AM: Update 22434: task mnli, batch 434 (22434): accuracy: 0.8309, mnli_loss: 0.4270
09/06 12:41:28 AM: Update 22454: task mnli, batch 454 (22454): accuracy: 0.8318, mnli_loss: 0.4245
09/06 12:41:38 AM: Update 22473: task mnli, batch 473 (22473): accuracy: 0.8337, mnli_loss: 0.4207
09/06 12:41:49 AM: Update 22492: task mnli, batch 492 (22492): accuracy: 0.8339, mnli_loss: 0.4209
09/06 12:41:59 AM: Update 22511: task mnli, batch 511 (22511): accuracy: 0.8348, mnli_loss: 0.4196
09/06 12:42:09 AM: Update 22531: task mnli, batch 531 (22531): accuracy: 0.8353, mnli_loss: 0.4190
09/06 12:42:20 AM: Update 22551: task mnli, batch 551 (22551): accuracy: 0.8348, mnli_loss: 0.4198
09/06 12:42:30 AM: Update 22569: task mnli, batch 569 (22569): accuracy: 0.8354, mnli_loss: 0.4192
09/06 12:42:40 AM: Update 22588: task mnli, batch 588 (22588): accuracy: 0.8356, mnli_loss: 0.4184
09/06 12:42:51 AM: Update 22607: task mnli, batch 607 (22607): accuracy: 0.8353, mnli_loss: 0.4178
09/06 12:43:01 AM: Update 22626: task mnli, batch 626 (22626): accuracy: 0.8352, mnli_loss: 0.4183
09/06 12:43:11 AM: Update 22639: task mnli, batch 639 (22639): accuracy: 0.8345, mnli_loss: 0.4198
09/06 12:43:22 AM: Update 22658: task mnli, batch 658 (22658): accuracy: 0.8347, mnli_loss: 0.4199
09/06 12:43:32 AM: Update 22676: task mnli, batch 676 (22676): accuracy: 0.8345, mnli_loss: 0.4203
09/06 12:43:42 AM: Update 22696: task mnli, batch 696 (22696): accuracy: 0.8348, mnli_loss: 0.4203
09/06 12:43:52 AM: Update 22715: task mnli, batch 715 (22715): accuracy: 0.8354, mnli_loss: 0.4190
09/06 12:44:02 AM: Update 22733: task mnli, batch 733 (22733): accuracy: 0.8356, mnli_loss: 0.4195
09/06 12:44:13 AM: Update 22754: task mnli, batch 754 (22754): accuracy: 0.8352, mnli_loss: 0.4209
09/06 12:44:23 AM: Update 22772: task mnli, batch 772 (22772): accuracy: 0.8354, mnli_loss: 0.4210
09/06 12:44:34 AM: Update 22793: task mnli, batch 793 (22793): accuracy: 0.8353, mnli_loss: 0.4220
09/06 12:44:44 AM: Update 22813: task mnli, batch 813 (22813): accuracy: 0.8357, mnli_loss: 0.4219
09/06 12:44:54 AM: Update 22830: task mnli, batch 830 (22830): accuracy: 0.8352, mnli_loss: 0.4233
09/06 12:45:04 AM: Update 22849: task mnli, batch 849 (22849): accuracy: 0.8352, mnli_loss: 0.4226
09/06 12:45:14 AM: Update 22867: task mnli, batch 867 (22867): accuracy: 0.8352, mnli_loss: 0.4220
09/06 12:45:25 AM: Update 22885: task mnli, batch 885 (22885): accuracy: 0.8348, mnli_loss: 0.4232
09/06 12:45:35 AM: Update 22902: task mnli, batch 902 (22902): accuracy: 0.8352, mnli_loss: 0.4220
09/06 12:45:45 AM: Update 22921: task mnli, batch 921 (22921): accuracy: 0.8347, mnli_loss: 0.4229
09/06 12:45:55 AM: Update 22941: task mnli, batch 941 (22941): accuracy: 0.8345, mnli_loss: 0.4236
09/06 12:46:06 AM: Update 22960: task mnli, batch 960 (22960): accuracy: 0.8340, mnli_loss: 0.4242
09/06 12:46:16 AM: Update 22978: task mnli, batch 978 (22978): accuracy: 0.8345, mnli_loss: 0.4242
09/06 12:46:26 AM: Update 22997: task mnli, batch 997 (22997): accuracy: 0.8357, mnli_loss: 0.4214
09/06 12:46:28 AM: ***** Step 23000 / Validation 23 *****
09/06 12:46:28 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:46:28 AM: Validating...
09/06 12:46:36 AM: Evaluate: task mnli, batch 43 (209): accuracy: 0.8217, mnli_loss: 0.4752
09/06 12:46:46 AM: Evaluate: task mnli, batch 93 (209): accuracy: 0.8185, mnli_loss: 0.4840
09/06 12:46:57 AM: Evaluate: task mnli, batch 143 (209): accuracy: 0.8141, mnli_loss: 0.4929
09/06 12:47:07 AM: Evaluate: task mnli, batch 193 (209): accuracy: 0.8171, mnli_loss: 0.4933
09/06 12:47:10 AM: Best result seen so far for mnli.
09/06 12:47:10 AM: Best result seen so far for micro.
09/06 12:47:10 AM: Best result seen so far for macro.
09/06 12:47:10 AM: Updating LR scheduler:
09/06 12:47:10 AM: 	Best result seen so far for macro_avg: 0.814
09/06 12:47:10 AM: 	# validation passes without improvement: 0
09/06 12:47:10 AM: mnli_loss: training: 0.421134 validation: 0.502477
09/06 12:47:10 AM: macro_avg: validation: 0.814400
09/06 12:47:10 AM: micro_avg: validation: 0.814400
09/06 12:47:10 AM: mnli_accuracy: training: 0.835807 validation: 0.814400
09/06 12:47:10 AM: Global learning rate: 1e-05
09/06 12:47:10 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:47:17 AM: Update 23012: task mnli, batch 12 (23012): accuracy: 0.8368, mnli_loss: 0.4131
09/06 12:47:27 AM: Update 23032: task mnli, batch 32 (23032): accuracy: 0.8333, mnli_loss: 0.4289
09/06 12:47:40 AM: Update 23049: task mnli, batch 49 (23049): accuracy: 0.8322, mnli_loss: 0.4467
09/06 12:47:51 AM: Update 23068: task mnli, batch 68 (23068): accuracy: 0.8442, mnli_loss: 0.4165
09/06 12:48:01 AM: Update 23085: task mnli, batch 85 (23085): accuracy: 0.8391, mnli_loss: 0.4220
09/06 12:48:11 AM: Update 23103: task mnli, batch 103 (23103): accuracy: 0.8360, mnli_loss: 0.4324
09/06 12:48:21 AM: Update 23122: task mnli, batch 122 (23122): accuracy: 0.8408, mnli_loss: 0.4166
09/06 12:48:31 AM: Update 23139: task mnli, batch 139 (23139): accuracy: 0.8416, mnli_loss: 0.4168
09/06 12:48:42 AM: Update 23158: task mnli, batch 158 (23158): accuracy: 0.8425, mnli_loss: 0.4141
09/06 12:48:52 AM: Update 23178: task mnli, batch 178 (23178): accuracy: 0.8403, mnli_loss: 0.4216
09/06 12:49:02 AM: Update 23197: task mnli, batch 197 (23197): accuracy: 0.8396, mnli_loss: 0.4229
09/06 12:49:13 AM: Update 23217: task mnli, batch 217 (23217): accuracy: 0.8398, mnli_loss: 0.4231
09/06 12:49:23 AM: Update 23236: task mnli, batch 236 (23236): accuracy: 0.8419, mnli_loss: 0.4166
09/06 12:49:34 AM: Update 23256: task mnli, batch 256 (23256): accuracy: 0.8434, mnli_loss: 0.4147
09/06 12:49:44 AM: Update 23276: task mnli, batch 276 (23276): accuracy: 0.8428, mnli_loss: 0.4157
09/06 12:49:54 AM: Update 23295: task mnli, batch 295 (23295): accuracy: 0.8409, mnli_loss: 0.4193
09/06 12:50:05 AM: Update 23313: task mnli, batch 313 (23313): accuracy: 0.8416, mnli_loss: 0.4180
09/06 12:50:15 AM: Update 23334: task mnli, batch 334 (23334): accuracy: 0.8424, mnli_loss: 0.4159
09/06 12:50:25 AM: Update 23351: task mnli, batch 351 (23351): accuracy: 0.8438, mnli_loss: 0.4119
09/06 12:50:35 AM: Update 23369: task mnli, batch 369 (23369): accuracy: 0.8427, mnli_loss: 0.4150
09/06 12:50:46 AM: Update 23389: task mnli, batch 389 (23389): accuracy: 0.8422, mnli_loss: 0.4150
09/06 12:50:56 AM: Update 23408: task mnli, batch 408 (23408): accuracy: 0.8417, mnli_loss: 0.4154
09/06 12:51:06 AM: Update 23426: task mnli, batch 426 (23426): accuracy: 0.8403, mnli_loss: 0.4173
09/06 12:51:17 AM: Update 23445: task mnli, batch 445 (23445): accuracy: 0.8404, mnli_loss: 0.4173
09/06 12:51:27 AM: Update 23465: task mnli, batch 465 (23465): accuracy: 0.8400, mnli_loss: 0.4177
09/06 12:51:37 AM: Update 23479: task mnli, batch 479 (23479): accuracy: 0.8395, mnli_loss: 0.4181
09/06 12:51:48 AM: Update 23498: task mnli, batch 498 (23498): accuracy: 0.8398, mnli_loss: 0.4182
09/06 12:51:58 AM: Update 23516: task mnli, batch 516 (23516): accuracy: 0.8394, mnli_loss: 0.4176
09/06 12:52:08 AM: Update 23535: task mnli, batch 535 (23535): accuracy: 0.8398, mnli_loss: 0.4173
09/06 12:52:19 AM: Update 23554: task mnli, batch 554 (23554): accuracy: 0.8404, mnli_loss: 0.4172
09/06 12:52:29 AM: Update 23572: task mnli, batch 572 (23572): accuracy: 0.8402, mnli_loss: 0.4168
09/06 12:52:39 AM: Update 23592: task mnli, batch 592 (23592): accuracy: 0.8405, mnli_loss: 0.4163
09/06 12:52:50 AM: Update 23610: task mnli, batch 610 (23610): accuracy: 0.8405, mnli_loss: 0.4168
09/06 12:53:00 AM: Update 23628: task mnli, batch 628 (23628): accuracy: 0.8395, mnli_loss: 0.4181
09/06 12:53:10 AM: Update 23648: task mnli, batch 648 (23648): accuracy: 0.8401, mnli_loss: 0.4176
09/06 12:53:21 AM: Update 23667: task mnli, batch 667 (23667): accuracy: 0.8394, mnli_loss: 0.4180
09/06 12:53:31 AM: Update 23685: task mnli, batch 685 (23685): accuracy: 0.8387, mnli_loss: 0.4189
09/06 12:53:41 AM: Update 23703: task mnli, batch 703 (23703): accuracy: 0.8380, mnli_loss: 0.4206
09/06 12:53:51 AM: Update 23721: task mnli, batch 721 (23721): accuracy: 0.8378, mnli_loss: 0.4204
09/06 12:54:01 AM: Update 23739: task mnli, batch 739 (23739): accuracy: 0.8384, mnli_loss: 0.4193
09/06 12:54:11 AM: Update 23756: task mnli, batch 756 (23756): accuracy: 0.8380, mnli_loss: 0.4199
09/06 12:54:22 AM: Update 23775: task mnli, batch 775 (23775): accuracy: 0.8383, mnli_loss: 0.4194
09/06 12:54:32 AM: Update 23794: task mnli, batch 794 (23794): accuracy: 0.8379, mnli_loss: 0.4188
09/06 12:54:42 AM: Update 23814: task mnli, batch 814 (23814): accuracy: 0.8374, mnli_loss: 0.4195
09/06 12:54:52 AM: Update 23834: task mnli, batch 834 (23834): accuracy: 0.8375, mnli_loss: 0.4184
09/06 12:55:02 AM: Update 23854: task mnli, batch 854 (23854): accuracy: 0.8380, mnli_loss: 0.4178
09/06 12:55:12 AM: Update 23874: task mnli, batch 874 (23874): accuracy: 0.8384, mnli_loss: 0.4170
09/06 12:55:23 AM: Update 23889: task mnli, batch 889 (23889): accuracy: 0.8379, mnli_loss: 0.4172
09/06 12:55:33 AM: Update 23907: task mnli, batch 907 (23907): accuracy: 0.8380, mnli_loss: 0.4171
09/06 12:55:43 AM: Update 23927: task mnli, batch 927 (23927): accuracy: 0.8383, mnli_loss: 0.4170
09/06 12:55:53 AM: Update 23946: task mnli, batch 946 (23946): accuracy: 0.8382, mnli_loss: 0.4167
09/06 12:56:04 AM: Update 23966: task mnli, batch 966 (23966): accuracy: 0.8391, mnli_loss: 0.4147
09/06 12:56:14 AM: Update 23984: task mnli, batch 984 (23984): accuracy: 0.8391, mnli_loss: 0.4149
09/06 12:56:22 AM: ***** Step 24000 / Validation 24 *****
09/06 12:56:22 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 12:56:22 AM: Validating...
09/06 12:56:24 AM: Evaluate: task mnli, batch 10 (209): accuracy: 0.8208, mnli_loss: 0.4459
09/06 12:56:34 AM: Evaluate: task mnli, batch 59 (209): accuracy: 0.8093, mnli_loss: 0.4807
09/06 12:56:45 AM: Evaluate: task mnli, batch 109 (209): accuracy: 0.8115, mnli_loss: 0.4844
09/06 12:56:55 AM: Evaluate: task mnli, batch 159 (209): accuracy: 0.8121, mnli_loss: 0.4868
09/06 12:57:05 AM: Evaluate: task mnli, batch 208 (209): accuracy: 0.8075, mnli_loss: 0.4982
09/06 12:57:05 AM: Updating LR scheduler:
09/06 12:57:05 AM: 	Best result seen so far for macro_avg: 0.814
09/06 12:57:05 AM: 	# validation passes without improvement: 1
09/06 12:57:05 AM: mnli_loss: training: 0.414585 validation: 0.499372
09/06 12:57:05 AM: macro_avg: validation: 0.807200
09/06 12:57:05 AM: micro_avg: validation: 0.807200
09/06 12:57:05 AM: mnli_accuracy: training: 0.838922 validation: 0.807200
09/06 12:57:05 AM: Global learning rate: 1e-05
09/06 12:57:05 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 12:57:15 AM: Update 24016: task mnli, batch 16 (24016): accuracy: 0.8359, mnli_loss: 0.4097
09/06 12:57:25 AM: Update 24035: task mnli, batch 35 (24035): accuracy: 0.8500, mnli_loss: 0.3929
09/06 12:57:35 AM: Update 24055: task mnli, batch 55 (24055): accuracy: 0.8583, mnli_loss: 0.3592
09/06 12:57:45 AM: Update 24074: task mnli, batch 74 (24074): accuracy: 0.8485, mnli_loss: 0.3923
09/06 12:57:56 AM: Update 24093: task mnli, batch 93 (24093): accuracy: 0.8522, mnli_loss: 0.3835
09/06 12:58:06 AM: Update 24113: task mnli, batch 113 (24113): accuracy: 0.8503, mnli_loss: 0.3867
09/06 12:58:17 AM: Update 24131: task mnli, batch 131 (24131): accuracy: 0.8476, mnli_loss: 0.3922
09/06 12:58:27 AM: Update 24148: task mnli, batch 148 (24148): accuracy: 0.8452, mnli_loss: 0.3945
09/06 12:58:37 AM: Update 24166: task mnli, batch 166 (24166): accuracy: 0.8469, mnli_loss: 0.3904
09/06 12:58:47 AM: Update 24183: task mnli, batch 183 (24183): accuracy: 0.8438, mnli_loss: 0.3976
09/06 12:58:57 AM: Update 24202: task mnli, batch 202 (24202): accuracy: 0.8434, mnli_loss: 0.3994
09/06 12:59:08 AM: Update 24220: task mnli, batch 220 (24220): accuracy: 0.8428, mnli_loss: 0.4043
09/06 12:59:18 AM: Update 24240: task mnli, batch 240 (24240): accuracy: 0.8436, mnli_loss: 0.4012
09/06 12:59:28 AM: Update 24259: task mnli, batch 259 (24259): accuracy: 0.8423, mnli_loss: 0.4041
09/06 12:59:38 AM: Update 24279: task mnli, batch 279 (24279): accuracy: 0.8430, mnli_loss: 0.4046
09/06 12:59:49 AM: Update 24299: task mnli, batch 299 (24299): accuracy: 0.8436, mnli_loss: 0.4024
09/06 12:59:59 AM: Update 24311: task mnli, batch 311 (24311): accuracy: 0.8427, mnli_loss: 0.4049
09/06 01:00:09 AM: Update 24330: task mnli, batch 330 (24330): accuracy: 0.8415, mnli_loss: 0.4084
09/06 01:00:19 AM: Update 24350: task mnli, batch 350 (24350): accuracy: 0.8414, mnli_loss: 0.4090
09/06 01:00:30 AM: Update 24368: task mnli, batch 368 (24368): accuracy: 0.8402, mnli_loss: 0.4097
09/06 01:00:40 AM: Update 24387: task mnli, batch 387 (24387): accuracy: 0.8399, mnli_loss: 0.4116
09/06 01:00:50 AM: Update 24405: task mnli, batch 405 (24405): accuracy: 0.8382, mnli_loss: 0.4144
09/06 01:01:00 AM: Update 24424: task mnli, batch 424 (24424): accuracy: 0.8382, mnli_loss: 0.4150
09/06 01:01:11 AM: Update 24443: task mnli, batch 443 (24443): accuracy: 0.8374, mnli_loss: 0.4161
09/06 01:01:21 AM: Update 24463: task mnli, batch 463 (24463): accuracy: 0.8389, mnli_loss: 0.4139
09/06 01:01:32 AM: Update 24483: task mnli, batch 483 (24483): accuracy: 0.8398, mnli_loss: 0.4123
09/06 01:01:42 AM: Update 24503: task mnli, batch 503 (24503): accuracy: 0.8394, mnli_loss: 0.4124
09/06 01:01:52 AM: Update 24522: task mnli, batch 522 (24522): accuracy: 0.8400, mnli_loss: 0.4113
09/06 01:02:02 AM: Update 24540: task mnli, batch 540 (24540): accuracy: 0.8399, mnli_loss: 0.4118
09/06 01:02:13 AM: Update 24560: task mnli, batch 560 (24560): accuracy: 0.8395, mnli_loss: 0.4132
09/06 01:02:23 AM: Update 24579: task mnli, batch 579 (24579): accuracy: 0.8399, mnli_loss: 0.4120
09/06 01:02:33 AM: Update 24597: task mnli, batch 597 (24597): accuracy: 0.8387, mnli_loss: 0.4139
09/06 01:02:43 AM: Update 24615: task mnli, batch 615 (24615): accuracy: 0.8384, mnli_loss: 0.4149
09/06 01:02:53 AM: Update 24633: task mnli, batch 633 (24633): accuracy: 0.8388, mnli_loss: 0.4142
09/06 01:03:03 AM: Update 24651: task mnli, batch 651 (24651): accuracy: 0.8388, mnli_loss: 0.4142
09/06 01:03:14 AM: Update 24671: task mnli, batch 671 (24671): accuracy: 0.8396, mnli_loss: 0.4134
09/06 01:03:24 AM: Update 24688: task mnli, batch 688 (24688): accuracy: 0.8390, mnli_loss: 0.4136
09/06 01:03:34 AM: Update 24708: task mnli, batch 708 (24708): accuracy: 0.8386, mnli_loss: 0.4138
09/06 01:03:45 AM: Update 24722: task mnli, batch 722 (24722): accuracy: 0.8386, mnli_loss: 0.4135
09/06 01:03:55 AM: Update 24741: task mnli, batch 741 (24741): accuracy: 0.8379, mnli_loss: 0.4149
09/06 01:04:05 AM: Update 24760: task mnli, batch 760 (24760): accuracy: 0.8381, mnli_loss: 0.4151
09/06 01:04:15 AM: Update 24780: task mnli, batch 780 (24780): accuracy: 0.8388, mnli_loss: 0.4136
09/06 01:04:25 AM: Update 24798: task mnli, batch 798 (24798): accuracy: 0.8389, mnli_loss: 0.4139
09/06 01:04:36 AM: Update 24815: task mnli, batch 815 (24815): accuracy: 0.8387, mnli_loss: 0.4155
09/06 01:04:46 AM: Update 24833: task mnli, batch 833 (24833): accuracy: 0.8382, mnli_loss: 0.4159
09/06 01:04:56 AM: Update 24852: task mnli, batch 852 (24852): accuracy: 0.8390, mnli_loss: 0.4141
09/06 01:05:06 AM: Update 24871: task mnli, batch 871 (24871): accuracy: 0.8394, mnli_loss: 0.4139
09/06 01:05:17 AM: Update 24891: task mnli, batch 891 (24891): accuracy: 0.8391, mnli_loss: 0.4138
09/06 01:05:27 AM: Update 24910: task mnli, batch 910 (24910): accuracy: 0.8392, mnli_loss: 0.4131
09/06 01:05:38 AM: Update 24931: task mnli, batch 931 (24931): accuracy: 0.8392, mnli_loss: 0.4128
09/06 01:05:48 AM: Update 24949: task mnli, batch 949 (24949): accuracy: 0.8395, mnli_loss: 0.4118
09/06 01:05:58 AM: Update 24969: task mnli, batch 969 (24969): accuracy: 0.8395, mnli_loss: 0.4124
09/06 01:06:08 AM: Update 24986: task mnli, batch 986 (24986): accuracy: 0.8394, mnli_loss: 0.4119
09/06 01:06:16 AM: ***** Step 25000 / Validation 25 *****
09/06 01:06:16 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:06:16 AM: Validating...
09/06 01:06:18 AM: Evaluate: task mnli, batch 11 (209): accuracy: 0.8106, mnli_loss: 0.4836
09/06 01:06:28 AM: Evaluate: task mnli, batch 61 (209): accuracy: 0.8135, mnli_loss: 0.4928
09/06 01:06:39 AM: Evaluate: task mnli, batch 110 (209): accuracy: 0.8087, mnli_loss: 0.5086
09/06 01:06:49 AM: Evaluate: task mnli, batch 160 (209): accuracy: 0.8122, mnli_loss: 0.5078
09/06 01:06:58 AM: Updating LR scheduler:
09/06 01:06:58 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:06:58 AM: 	# validation passes without improvement: 2
09/06 01:06:58 AM: mnli_loss: training: 0.411494 validation: 0.516709
09/06 01:06:58 AM: macro_avg: validation: 0.809600
09/06 01:06:58 AM: micro_avg: validation: 0.809600
09/06 01:06:58 AM: mnli_accuracy: training: 0.839518 validation: 0.809600
09/06 01:06:58 AM: Global learning rate: 1e-05
09/06 01:06:58 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:07:00 AM: Update 25001: task mnli, batch 1 (25001): accuracy: 0.8750, mnli_loss: 0.3918
09/06 01:07:10 AM: Update 25020: task mnli, batch 20 (25020): accuracy: 0.8458, mnli_loss: 0.4075
09/06 01:07:20 AM: Update 25038: task mnli, batch 38 (25038): accuracy: 0.8509, mnli_loss: 0.4030
09/06 01:07:31 AM: Update 25058: task mnli, batch 58 (25058): accuracy: 0.8578, mnli_loss: 0.3798
09/06 01:07:41 AM: Update 25078: task mnli, batch 78 (25078): accuracy: 0.8547, mnli_loss: 0.3821
09/06 01:07:51 AM: Update 25097: task mnli, batch 97 (25097): accuracy: 0.8475, mnli_loss: 0.3984
09/06 01:08:02 AM: Update 25116: task mnli, batch 116 (25116): accuracy: 0.8438, mnli_loss: 0.4061
09/06 01:08:15 AM: Update 25134: task mnli, batch 134 (25134): accuracy: 0.8432, mnli_loss: 0.4075
09/06 01:08:25 AM: Update 25154: task mnli, batch 154 (25154): accuracy: 0.8400, mnli_loss: 0.4127
09/06 01:08:35 AM: Update 25172: task mnli, batch 172 (25172): accuracy: 0.8340, mnli_loss: 0.4252
09/06 01:08:46 AM: Update 25191: task mnli, batch 191 (25191): accuracy: 0.8357, mnli_loss: 0.4206
09/06 01:08:56 AM: Update 25212: task mnli, batch 212 (25212): accuracy: 0.8368, mnli_loss: 0.4165
09/06 01:09:06 AM: Update 25231: task mnli, batch 231 (25231): accuracy: 0.8389, mnli_loss: 0.4132
09/06 01:09:17 AM: Update 25251: task mnli, batch 251 (25251): accuracy: 0.8378, mnli_loss: 0.4150
09/06 01:09:27 AM: Update 25270: task mnli, batch 270 (25270): accuracy: 0.8373, mnli_loss: 0.4168
09/06 01:09:37 AM: Update 25290: task mnli, batch 290 (25290): accuracy: 0.8383, mnli_loss: 0.4158
09/06 01:09:47 AM: Update 25309: task mnli, batch 309 (25309): accuracy: 0.8375, mnli_loss: 0.4175
09/06 01:09:58 AM: Update 25328: task mnli, batch 328 (25328): accuracy: 0.8379, mnli_loss: 0.4174
09/06 01:10:08 AM: Update 25347: task mnli, batch 347 (25347): accuracy: 0.8387, mnli_loss: 0.4159
09/06 01:10:19 AM: Update 25366: task mnli, batch 366 (25366): accuracy: 0.8380, mnli_loss: 0.4175
09/06 01:10:29 AM: Update 25385: task mnli, batch 385 (25385): accuracy: 0.8387, mnli_loss: 0.4147
09/06 01:10:39 AM: Update 25404: task mnli, batch 404 (25404): accuracy: 0.8401, mnli_loss: 0.4121
09/06 01:10:49 AM: Update 25423: task mnli, batch 423 (25423): accuracy: 0.8401, mnli_loss: 0.4135
09/06 01:11:00 AM: Update 25440: task mnli, batch 440 (25440): accuracy: 0.8393, mnli_loss: 0.4163
09/06 01:11:10 AM: Update 25460: task mnli, batch 460 (25460): accuracy: 0.8403, mnli_loss: 0.4142
09/06 01:11:20 AM: Update 25479: task mnli, batch 479 (25479): accuracy: 0.8399, mnli_loss: 0.4127
09/06 01:11:30 AM: Update 25496: task mnli, batch 496 (25496): accuracy: 0.8386, mnli_loss: 0.4158
09/06 01:11:41 AM: Update 25514: task mnli, batch 514 (25514): accuracy: 0.8388, mnli_loss: 0.4150
09/06 01:11:51 AM: Update 25532: task mnli, batch 532 (25532): accuracy: 0.8386, mnli_loss: 0.4170
09/06 01:12:03 AM: Update 25551: task mnli, batch 551 (25551): accuracy: 0.8382, mnli_loss: 0.4166
09/06 01:12:14 AM: Update 25569: task mnli, batch 569 (25569): accuracy: 0.8386, mnli_loss: 0.4159
09/06 01:12:24 AM: Update 25589: task mnli, batch 589 (25589): accuracy: 0.8384, mnli_loss: 0.4160
09/06 01:12:34 AM: Update 25609: task mnli, batch 609 (25609): accuracy: 0.8380, mnli_loss: 0.4161
09/06 01:12:45 AM: Update 25627: task mnli, batch 627 (25627): accuracy: 0.8387, mnli_loss: 0.4143
09/06 01:12:55 AM: Update 25646: task mnli, batch 646 (25646): accuracy: 0.8392, mnli_loss: 0.4133
09/06 01:13:06 AM: Update 25665: task mnli, batch 665 (25665): accuracy: 0.8392, mnli_loss: 0.4128
09/06 01:13:16 AM: Update 25684: task mnli, batch 684 (25684): accuracy: 0.8392, mnli_loss: 0.4134
09/06 01:13:26 AM: Update 25702: task mnli, batch 702 (25702): accuracy: 0.8383, mnli_loss: 0.4143
09/06 01:13:36 AM: Update 25723: task mnli, batch 723 (25723): accuracy: 0.8394, mnli_loss: 0.4127
09/06 01:13:47 AM: Update 25742: task mnli, batch 742 (25742): accuracy: 0.8395, mnli_loss: 0.4123
09/06 01:13:57 AM: Update 25761: task mnli, batch 761 (25761): accuracy: 0.8393, mnli_loss: 0.4127
09/06 01:14:07 AM: Update 25779: task mnli, batch 779 (25779): accuracy: 0.8389, mnli_loss: 0.4148
09/06 01:14:18 AM: Update 25798: task mnli, batch 798 (25798): accuracy: 0.8390, mnli_loss: 0.4156
09/06 01:14:28 AM: Update 25819: task mnli, batch 819 (25819): accuracy: 0.8396, mnli_loss: 0.4154
09/06 01:14:38 AM: Update 25837: task mnli, batch 837 (25837): accuracy: 0.8394, mnli_loss: 0.4162
09/06 01:14:49 AM: Update 25855: task mnli, batch 855 (25855): accuracy: 0.8393, mnli_loss: 0.4160
09/06 01:14:59 AM: Update 25874: task mnli, batch 874 (25874): accuracy: 0.8396, mnli_loss: 0.4157
09/06 01:15:09 AM: Update 25892: task mnli, batch 892 (25892): accuracy: 0.8401, mnli_loss: 0.4145
09/06 01:15:19 AM: Update 25911: task mnli, batch 911 (25911): accuracy: 0.8396, mnli_loss: 0.4150
09/06 01:15:30 AM: Update 25929: task mnli, batch 929 (25929): accuracy: 0.8399, mnli_loss: 0.4150
09/06 01:15:40 AM: Update 25949: task mnli, batch 949 (25949): accuracy: 0.8398, mnli_loss: 0.4148
09/06 01:15:50 AM: Update 25967: task mnli, batch 967 (25967): accuracy: 0.8400, mnli_loss: 0.4145
09/06 01:16:01 AM: Update 25981: task mnli, batch 981 (25981): accuracy: 0.8397, mnli_loss: 0.4152
09/06 01:16:11 AM: Update 25999: task mnli, batch 999 (25999): accuracy: 0.8397, mnli_loss: 0.4150
09/06 01:16:12 AM: ***** Step 26000 / Validation 26 *****
09/06 01:16:12 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:16:12 AM: Validating...
09/06 01:16:21 AM: Evaluate: task mnli, batch 48 (209): accuracy: 0.8177, mnli_loss: 0.4690
09/06 01:16:31 AM: Evaluate: task mnli, batch 98 (209): accuracy: 0.8159, mnli_loss: 0.4828
09/06 01:16:41 AM: Evaluate: task mnli, batch 147 (209): accuracy: 0.8146, mnli_loss: 0.4895
09/06 01:16:52 AM: Evaluate: task mnli, batch 197 (209): accuracy: 0.8147, mnli_loss: 0.4901
09/06 01:16:54 AM: Updating LR scheduler:
09/06 01:16:54 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:16:54 AM: 	# validation passes without improvement: 3
09/06 01:16:54 AM: mnli_loss: training: 0.414888 validation: 0.495318
09/06 01:16:54 AM: macro_avg: validation: 0.813200
09/06 01:16:54 AM: micro_avg: validation: 0.813200
09/06 01:16:54 AM: mnli_accuracy: training: 0.839798 validation: 0.813200
09/06 01:16:54 AM: Global learning rate: 1e-05
09/06 01:16:54 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:17:02 AM: Update 26014: task mnli, batch 14 (26014): accuracy: 0.8363, mnli_loss: 0.4196
09/06 01:17:12 AM: Update 26034: task mnli, batch 34 (26034): accuracy: 0.8333, mnli_loss: 0.4153
09/06 01:17:23 AM: Update 26053: task mnli, batch 53 (26053): accuracy: 0.8373, mnli_loss: 0.4166
09/06 01:17:33 AM: Update 26072: task mnli, batch 72 (26072): accuracy: 0.8328, mnli_loss: 0.4236
09/06 01:17:43 AM: Update 26090: task mnli, batch 90 (26090): accuracy: 0.8319, mnli_loss: 0.4282
09/06 01:17:53 AM: Update 26110: task mnli, batch 110 (26110): accuracy: 0.8326, mnli_loss: 0.4322
09/06 01:18:04 AM: Update 26129: task mnli, batch 129 (26129): accuracy: 0.8382, mnli_loss: 0.4209
09/06 01:18:14 AM: Update 26149: task mnli, batch 149 (26149): accuracy: 0.8400, mnli_loss: 0.4160
09/06 01:18:25 AM: Update 26169: task mnli, batch 169 (26169): accuracy: 0.8400, mnli_loss: 0.4139
09/06 01:18:35 AM: Update 26188: task mnli, batch 188 (26188): accuracy: 0.8406, mnli_loss: 0.4110
09/06 01:18:45 AM: Update 26207: task mnli, batch 207 (26207): accuracy: 0.8402, mnli_loss: 0.4139
09/06 01:18:56 AM: Update 26225: task mnli, batch 225 (26225): accuracy: 0.8394, mnli_loss: 0.4146
09/06 01:19:06 AM: Update 26243: task mnli, batch 243 (26243): accuracy: 0.8392, mnli_loss: 0.4128
09/06 01:19:16 AM: Update 26263: task mnli, batch 263 (26263): accuracy: 0.8419, mnli_loss: 0.4080
09/06 01:19:26 AM: Update 26282: task mnli, batch 282 (26282): accuracy: 0.8416, mnli_loss: 0.4076
09/06 01:19:36 AM: Update 26302: task mnli, batch 302 (26302): accuracy: 0.8431, mnli_loss: 0.4041
09/06 01:19:46 AM: Update 26321: task mnli, batch 321 (26321): accuracy: 0.8423, mnli_loss: 0.4063
09/06 01:19:57 AM: Update 26339: task mnli, batch 339 (26339): accuracy: 0.8413, mnli_loss: 0.4068
09/06 01:20:07 AM: Update 26359: task mnli, batch 359 (26359): accuracy: 0.8431, mnli_loss: 0.4006
09/06 01:20:17 AM: Update 26377: task mnli, batch 377 (26377): accuracy: 0.8431, mnli_loss: 0.4006
09/06 01:20:28 AM: Update 26392: task mnli, batch 392 (26392): accuracy: 0.8415, mnli_loss: 0.4040
09/06 01:20:38 AM: Update 26412: task mnli, batch 412 (26412): accuracy: 0.8412, mnli_loss: 0.4053
09/06 01:20:48 AM: Update 26431: task mnli, batch 431 (26431): accuracy: 0.8419, mnli_loss: 0.4045
09/06 01:20:59 AM: Update 26451: task mnli, batch 451 (26451): accuracy: 0.8424, mnli_loss: 0.4034
09/06 01:21:09 AM: Update 26469: task mnli, batch 469 (26469): accuracy: 0.8432, mnli_loss: 0.4024
09/06 01:21:19 AM: Update 26487: task mnli, batch 487 (26487): accuracy: 0.8443, mnli_loss: 0.3991
09/06 01:21:30 AM: Update 26506: task mnli, batch 506 (26506): accuracy: 0.8448, mnli_loss: 0.3970
09/06 01:21:40 AM: Update 26525: task mnli, batch 525 (26525): accuracy: 0.8449, mnli_loss: 0.3966
09/06 01:21:50 AM: Update 26544: task mnli, batch 544 (26544): accuracy: 0.8460, mnli_loss: 0.3953
09/06 01:22:00 AM: Update 26562: task mnli, batch 562 (26562): accuracy: 0.8460, mnli_loss: 0.3946
09/06 01:22:11 AM: Update 26581: task mnli, batch 581 (26581): accuracy: 0.8468, mnli_loss: 0.3933
09/06 01:22:21 AM: Update 26600: task mnli, batch 600 (26600): accuracy: 0.8469, mnli_loss: 0.3940
09/06 01:22:31 AM: Update 26619: task mnli, batch 619 (26619): accuracy: 0.8475, mnli_loss: 0.3926
09/06 01:22:41 AM: Update 26638: task mnli, batch 638 (26638): accuracy: 0.8479, mnli_loss: 0.3931
09/06 01:22:52 AM: Update 26658: task mnli, batch 658 (26658): accuracy: 0.8483, mnli_loss: 0.3922
09/06 01:23:02 AM: Update 26678: task mnli, batch 678 (26678): accuracy: 0.8483, mnli_loss: 0.3920
09/06 01:23:12 AM: Update 26696: task mnli, batch 696 (26696): accuracy: 0.8474, mnli_loss: 0.3931
09/06 01:23:22 AM: Update 26713: task mnli, batch 713 (26713): accuracy: 0.8475, mnli_loss: 0.3935
09/06 01:23:33 AM: Update 26732: task mnli, batch 732 (26732): accuracy: 0.8477, mnli_loss: 0.3939
09/06 01:23:43 AM: Update 26753: task mnli, batch 753 (26753): accuracy: 0.8474, mnli_loss: 0.3942
09/06 01:23:54 AM: Update 26772: task mnli, batch 772 (26772): accuracy: 0.8470, mnli_loss: 0.3947
09/06 01:24:04 AM: Update 26790: task mnli, batch 790 (26790): accuracy: 0.8468, mnli_loss: 0.3951
09/06 01:24:14 AM: Update 26802: task mnli, batch 802 (26802): accuracy: 0.8467, mnli_loss: 0.3951
09/06 01:24:24 AM: Update 26821: task mnli, batch 821 (26821): accuracy: 0.8467, mnli_loss: 0.3957
09/06 01:24:35 AM: Update 26839: task mnli, batch 839 (26839): accuracy: 0.8470, mnli_loss: 0.3945
09/06 01:24:45 AM: Update 26857: task mnli, batch 857 (26857): accuracy: 0.8464, mnli_loss: 0.3952
09/06 01:24:55 AM: Update 26875: task mnli, batch 875 (26875): accuracy: 0.8465, mnli_loss: 0.3958
09/06 01:25:05 AM: Update 26894: task mnli, batch 894 (26894): accuracy: 0.8466, mnli_loss: 0.3958
09/06 01:25:15 AM: Update 26913: task mnli, batch 913 (26913): accuracy: 0.8475, mnli_loss: 0.3945
09/06 01:25:26 AM: Update 26932: task mnli, batch 932 (26932): accuracy: 0.8477, mnli_loss: 0.3939
09/06 01:25:36 AM: Update 26951: task mnli, batch 951 (26951): accuracy: 0.8471, mnli_loss: 0.3951
09/06 01:25:47 AM: Update 26971: task mnli, batch 971 (26971): accuracy: 0.8464, mnli_loss: 0.3960
09/06 01:25:57 AM: Update 26991: task mnli, batch 991 (26991): accuracy: 0.8465, mnli_loss: 0.3955
09/06 01:26:01 AM: ***** Step 27000 / Validation 27 *****
09/06 01:26:01 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:26:01 AM: Validating...
09/06 01:26:07 AM: Evaluate: task mnli, batch 28 (209): accuracy: 0.8214, mnli_loss: 0.4752
09/06 01:26:17 AM: Evaluate: task mnli, batch 78 (209): accuracy: 0.8226, mnli_loss: 0.4708
09/06 01:26:27 AM: Evaluate: task mnli, batch 128 (209): accuracy: 0.8151, mnli_loss: 0.4901
09/06 01:26:38 AM: Evaluate: task mnli, batch 178 (209): accuracy: 0.8184, mnli_loss: 0.4899
09/06 01:26:44 AM: Updating LR scheduler:
09/06 01:26:44 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:26:44 AM: 	# validation passes without improvement: 4
09/06 01:26:44 AM: mnli_loss: training: 0.395973 validation: 0.502420
09/06 01:26:44 AM: macro_avg: validation: 0.814200
09/06 01:26:44 AM: micro_avg: validation: 0.814200
09/06 01:26:44 AM: mnli_accuracy: training: 0.846273 validation: 0.814200
09/06 01:26:44 AM: Global learning rate: 1e-05
09/06 01:26:44 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:26:48 AM: Update 27006: task mnli, batch 6 (27006): accuracy: 0.8264, mnli_loss: 0.3932
09/06 01:26:58 AM: Update 27024: task mnli, batch 24 (27024): accuracy: 0.8403, mnli_loss: 0.3859
09/06 01:27:08 AM: Update 27043: task mnli, batch 43 (27043): accuracy: 0.8547, mnli_loss: 0.3736
09/06 01:27:19 AM: Update 27061: task mnli, batch 61 (27061): accuracy: 0.8566, mnli_loss: 0.3704
09/06 01:27:29 AM: Update 27078: task mnli, batch 78 (27078): accuracy: 0.8526, mnli_loss: 0.3758
09/06 01:27:39 AM: Update 27098: task mnli, batch 98 (27098): accuracy: 0.8542, mnli_loss: 0.3801
09/06 01:27:49 AM: Update 27118: task mnli, batch 118 (27118): accuracy: 0.8524, mnli_loss: 0.3877
09/06 01:28:00 AM: Update 27138: task mnli, batch 138 (27138): accuracy: 0.8533, mnli_loss: 0.3831
09/06 01:28:10 AM: Update 27156: task mnli, batch 156 (27156): accuracy: 0.8523, mnli_loss: 0.3869
09/06 01:28:20 AM: Update 27176: task mnli, batch 176 (27176): accuracy: 0.8516, mnli_loss: 0.3892
09/06 01:28:31 AM: Update 27195: task mnli, batch 195 (27195): accuracy: 0.8536, mnli_loss: 0.3886
09/06 01:28:41 AM: Update 27214: task mnli, batch 214 (27214): accuracy: 0.8538, mnli_loss: 0.3863
09/06 01:28:52 AM: Update 27230: task mnli, batch 230 (27230): accuracy: 0.8514, mnli_loss: 0.3903
09/06 01:29:02 AM: Update 27248: task mnli, batch 248 (27248): accuracy: 0.8493, mnli_loss: 0.3951
09/06 01:29:12 AM: Update 27266: task mnli, batch 266 (27266): accuracy: 0.8465, mnli_loss: 0.4000
09/06 01:29:22 AM: Update 27284: task mnli, batch 284 (27284): accuracy: 0.8472, mnli_loss: 0.3987
09/06 01:29:32 AM: Update 27304: task mnli, batch 304 (27304): accuracy: 0.8488, mnli_loss: 0.3975
09/06 01:29:43 AM: Update 27324: task mnli, batch 324 (27324): accuracy: 0.8500, mnli_loss: 0.3948
09/06 01:29:53 AM: Update 27343: task mnli, batch 343 (27343): accuracy: 0.8492, mnli_loss: 0.3966
09/06 01:30:03 AM: Update 27361: task mnli, batch 361 (27361): accuracy: 0.8481, mnli_loss: 0.3970
09/06 01:30:13 AM: Update 27378: task mnli, batch 378 (27378): accuracy: 0.8482, mnli_loss: 0.3977
09/06 01:30:23 AM: Update 27396: task mnli, batch 396 (27396): accuracy: 0.8495, mnli_loss: 0.3941
09/06 01:30:34 AM: Update 27415: task mnli, batch 415 (27415): accuracy: 0.8498, mnli_loss: 0.3932
09/06 01:30:44 AM: Update 27433: task mnli, batch 433 (27433): accuracy: 0.8494, mnli_loss: 0.3916
09/06 01:30:54 AM: Update 27452: task mnli, batch 452 (27452): accuracy: 0.8505, mnli_loss: 0.3894
09/06 01:31:04 AM: Update 27471: task mnli, batch 471 (27471): accuracy: 0.8502, mnli_loss: 0.3892
09/06 01:31:15 AM: Update 27490: task mnli, batch 490 (27490): accuracy: 0.8502, mnli_loss: 0.3895
09/06 01:31:25 AM: Update 27508: task mnli, batch 508 (27508): accuracy: 0.8496, mnli_loss: 0.3902
09/06 01:31:35 AM: Update 27527: task mnli, batch 527 (27527): accuracy: 0.8496, mnli_loss: 0.3911
09/06 01:31:46 AM: Update 27545: task mnli, batch 545 (27545): accuracy: 0.8492, mnli_loss: 0.3915
09/06 01:31:56 AM: Update 27565: task mnli, batch 565 (27565): accuracy: 0.8494, mnli_loss: 0.3921
09/06 01:32:06 AM: Update 27585: task mnli, batch 585 (27585): accuracy: 0.8487, mnli_loss: 0.3927
09/06 01:32:17 AM: Update 27606: task mnli, batch 606 (27606): accuracy: 0.8486, mnli_loss: 0.3921
09/06 01:32:27 AM: Update 27624: task mnli, batch 624 (27624): accuracy: 0.8489, mnli_loss: 0.3910
09/06 01:32:37 AM: Update 27639: task mnli, batch 639 (27639): accuracy: 0.8483, mnli_loss: 0.3919
09/06 01:32:48 AM: Update 27660: task mnli, batch 660 (27660): accuracy: 0.8483, mnli_loss: 0.3921
09/06 01:32:58 AM: Update 27679: task mnli, batch 679 (27679): accuracy: 0.8490, mnli_loss: 0.3916
09/06 01:33:08 AM: Update 27697: task mnli, batch 697 (27697): accuracy: 0.8491, mnli_loss: 0.3914
09/06 01:33:19 AM: Update 27716: task mnli, batch 716 (27716): accuracy: 0.8488, mnli_loss: 0.3924
09/06 01:33:29 AM: Update 27735: task mnli, batch 735 (27735): accuracy: 0.8481, mnli_loss: 0.3942
09/06 01:33:39 AM: Update 27754: task mnli, batch 754 (27754): accuracy: 0.8484, mnli_loss: 0.3933
09/06 01:33:50 AM: Update 27774: task mnli, batch 774 (27774): accuracy: 0.8483, mnli_loss: 0.3939
09/06 01:34:00 AM: Update 27793: task mnli, batch 793 (27793): accuracy: 0.8480, mnli_loss: 0.3948
09/06 01:34:10 AM: Update 27811: task mnli, batch 811 (27811): accuracy: 0.8474, mnli_loss: 0.3957
09/06 01:34:21 AM: Update 27830: task mnli, batch 830 (27830): accuracy: 0.8476, mnli_loss: 0.3953
09/06 01:34:31 AM: Update 27849: task mnli, batch 849 (27849): accuracy: 0.8479, mnli_loss: 0.3939
09/06 01:34:42 AM: Update 27868: task mnli, batch 868 (27868): accuracy: 0.8484, mnli_loss: 0.3935
09/06 01:34:52 AM: Update 27888: task mnli, batch 888 (27888): accuracy: 0.8493, mnli_loss: 0.3916
09/06 01:35:02 AM: Update 27908: task mnli, batch 908 (27908): accuracy: 0.8493, mnli_loss: 0.3918
09/06 01:35:12 AM: Update 27926: task mnli, batch 926 (27926): accuracy: 0.8493, mnli_loss: 0.3923
09/06 01:35:23 AM: Update 27945: task mnli, batch 945 (27945): accuracy: 0.8490, mnli_loss: 0.3927
09/06 01:35:34 AM: Update 27964: task mnli, batch 964 (27964): accuracy: 0.8490, mnli_loss: 0.3931
09/06 01:35:44 AM: Update 27984: task mnli, batch 984 (27984): accuracy: 0.8492, mnli_loss: 0.3928
09/06 01:35:52 AM: ***** Step 28000 / Validation 28 *****
09/06 01:35:52 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:35:52 AM: Validating...
09/06 01:35:54 AM: Evaluate: task mnli, batch 9 (209): accuracy: 0.8009, mnli_loss: 0.4707
09/06 01:36:04 AM: Evaluate: task mnli, batch 59 (209): accuracy: 0.8150, mnli_loss: 0.4819
09/06 01:36:14 AM: Evaluate: task mnli, batch 109 (209): accuracy: 0.8146, mnli_loss: 0.4819
09/06 01:36:24 AM: Evaluate: task mnli, batch 159 (209): accuracy: 0.8147, mnli_loss: 0.4823
09/06 01:36:34 AM: Evaluate: task mnli, batch 208 (209): accuracy: 0.8133, mnli_loss: 0.4955
09/06 01:36:34 AM: Updating LR scheduler:
09/06 01:36:34 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:36:34 AM: 	# validation passes without improvement: 0
09/06 01:36:34 AM: mnli_loss: training: 0.392866 validation: 0.497311
09/06 01:36:34 AM: macro_avg: validation: 0.813000
09/06 01:36:34 AM: micro_avg: validation: 0.813000
09/06 01:36:34 AM: mnli_accuracy: training: 0.848899 validation: 0.813000
09/06 01:36:34 AM: Global learning rate: 5e-06
09/06 01:36:34 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:36:45 AM: Update 28017: task mnli, batch 17 (28017): accuracy: 0.8431, mnli_loss: 0.4078
09/06 01:36:55 AM: Update 28035: task mnli, batch 35 (28035): accuracy: 0.8452, mnli_loss: 0.4098
09/06 01:37:07 AM: Update 28053: task mnli, batch 53 (28053): accuracy: 0.8489, mnli_loss: 0.4054
09/06 01:37:17 AM: Update 28072: task mnli, batch 72 (28072): accuracy: 0.8483, mnli_loss: 0.4094
09/06 01:37:28 AM: Update 28092: task mnli, batch 92 (28092): accuracy: 0.8477, mnli_loss: 0.4084
09/06 01:37:38 AM: Update 28111: task mnli, batch 111 (28111): accuracy: 0.8453, mnli_loss: 0.4134
09/06 01:37:49 AM: Update 28132: task mnli, batch 132 (28132): accuracy: 0.8481, mnli_loss: 0.4033
09/06 01:37:59 AM: Update 28151: task mnli, batch 151 (28151): accuracy: 0.8493, mnli_loss: 0.4038
09/06 01:38:09 AM: Update 28169: task mnli, batch 169 (28169): accuracy: 0.8463, mnli_loss: 0.4077
09/06 01:38:19 AM: Update 28187: task mnli, batch 187 (28187): accuracy: 0.8464, mnli_loss: 0.4093
09/06 01:38:30 AM: Update 28206: task mnli, batch 206 (28206): accuracy: 0.8497, mnli_loss: 0.4034
09/06 01:38:40 AM: Update 28224: task mnli, batch 224 (28224): accuracy: 0.8495, mnli_loss: 0.4060
09/06 01:38:50 AM: Update 28244: task mnli, batch 244 (28244): accuracy: 0.8502, mnli_loss: 0.4031
09/06 01:39:01 AM: Update 28263: task mnli, batch 263 (28263): accuracy: 0.8487, mnli_loss: 0.4048
09/06 01:39:11 AM: Update 28283: task mnli, batch 283 (28283): accuracy: 0.8489, mnli_loss: 0.4024
09/06 01:39:21 AM: Update 28302: task mnli, batch 302 (28302): accuracy: 0.8496, mnli_loss: 0.3997
09/06 01:39:32 AM: Update 28321: task mnli, batch 321 (28321): accuracy: 0.8491, mnli_loss: 0.4000
09/06 01:39:42 AM: Update 28340: task mnli, batch 340 (28340): accuracy: 0.8489, mnli_loss: 0.3998
09/06 01:39:52 AM: Update 28356: task mnli, batch 356 (28356): accuracy: 0.8489, mnli_loss: 0.4005
09/06 01:40:02 AM: Update 28376: task mnli, batch 376 (28376): accuracy: 0.8498, mnli_loss: 0.3977
09/06 01:40:13 AM: Update 28395: task mnli, batch 395 (28395): accuracy: 0.8491, mnli_loss: 0.3992
09/06 01:40:23 AM: Update 28414: task mnli, batch 414 (28414): accuracy: 0.8491, mnli_loss: 0.3985
09/06 01:40:34 AM: Update 28434: task mnli, batch 434 (28434): accuracy: 0.8479, mnli_loss: 0.4002
09/06 01:40:44 AM: Update 28452: task mnli, batch 452 (28452): accuracy: 0.8482, mnli_loss: 0.3994
09/06 01:40:57 AM: Update 28470: task mnli, batch 470 (28470): accuracy: 0.8480, mnli_loss: 0.3996
09/06 01:41:07 AM: Update 28488: task mnli, batch 488 (28488): accuracy: 0.8483, mnli_loss: 0.3982
09/06 01:41:18 AM: Update 28508: task mnli, batch 508 (28508): accuracy: 0.8482, mnli_loss: 0.3988
09/06 01:41:28 AM: Update 28526: task mnli, batch 526 (28526): accuracy: 0.8484, mnli_loss: 0.3988
09/06 01:41:39 AM: Update 28545: task mnli, batch 545 (28545): accuracy: 0.8485, mnli_loss: 0.3980
09/06 01:41:49 AM: Update 28565: task mnli, batch 565 (28565): accuracy: 0.8497, mnli_loss: 0.3950
09/06 01:41:59 AM: Update 28585: task mnli, batch 585 (28585): accuracy: 0.8495, mnli_loss: 0.3953
09/06 01:42:09 AM: Update 28602: task mnli, batch 602 (28602): accuracy: 0.8493, mnli_loss: 0.3956
09/06 01:42:20 AM: Update 28620: task mnli, batch 620 (28620): accuracy: 0.8494, mnli_loss: 0.3952
09/06 01:42:30 AM: Update 28638: task mnli, batch 638 (28638): accuracy: 0.8494, mnli_loss: 0.3956
09/06 01:42:40 AM: Update 28657: task mnli, batch 657 (28657): accuracy: 0.8496, mnli_loss: 0.3948
09/06 01:42:51 AM: Update 28676: task mnli, batch 676 (28676): accuracy: 0.8490, mnli_loss: 0.3956
09/06 01:43:01 AM: Update 28695: task mnli, batch 695 (28695): accuracy: 0.8489, mnli_loss: 0.3958
09/06 01:43:11 AM: Update 28714: task mnli, batch 714 (28714): accuracy: 0.8488, mnli_loss: 0.3957
09/06 01:43:21 AM: Update 28733: task mnli, batch 733 (28733): accuracy: 0.8480, mnli_loss: 0.3973
09/06 01:43:31 AM: Update 28752: task mnli, batch 752 (28752): accuracy: 0.8484, mnli_loss: 0.3966
09/06 01:43:42 AM: Update 28771: task mnli, batch 771 (28771): accuracy: 0.8480, mnli_loss: 0.3974
09/06 01:43:52 AM: Update 28790: task mnli, batch 790 (28790): accuracy: 0.8479, mnli_loss: 0.3971
09/06 01:44:02 AM: Update 28809: task mnli, batch 809 (28809): accuracy: 0.8485, mnli_loss: 0.3960
09/06 01:44:12 AM: Update 28828: task mnli, batch 828 (28828): accuracy: 0.8485, mnli_loss: 0.3959
09/06 01:44:22 AM: Update 28847: task mnli, batch 847 (28847): accuracy: 0.8490, mnli_loss: 0.3946
09/06 01:44:33 AM: Update 28867: task mnli, batch 867 (28867): accuracy: 0.8494, mnli_loss: 0.3937
09/06 01:44:43 AM: Update 28886: task mnli, batch 886 (28886): accuracy: 0.8494, mnli_loss: 0.3943
09/06 01:44:53 AM: Update 28899: task mnli, batch 899 (28899): accuracy: 0.8494, mnli_loss: 0.3942
09/06 01:45:04 AM: Update 28919: task mnli, batch 919 (28919): accuracy: 0.8498, mnli_loss: 0.3928
09/06 01:45:14 AM: Update 28939: task mnli, batch 939 (28939): accuracy: 0.8495, mnli_loss: 0.3934
09/06 01:45:24 AM: Update 28957: task mnli, batch 957 (28957): accuracy: 0.8501, mnli_loss: 0.3921
09/06 01:45:35 AM: Update 28978: task mnli, batch 978 (28978): accuracy: 0.8499, mnli_loss: 0.3926
09/06 01:45:45 AM: Update 28997: task mnli, batch 997 (28997): accuracy: 0.8501, mnli_loss: 0.3917
09/06 01:45:47 AM: ***** Step 29000 / Validation 29 *****
09/06 01:45:47 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:45:47 AM: Validating...
09/06 01:45:55 AM: Evaluate: task mnli, batch 41 (209): accuracy: 0.8181, mnli_loss: 0.4776
09/06 01:46:05 AM: Evaluate: task mnli, batch 91 (209): accuracy: 0.8205, mnli_loss: 0.4751
09/06 01:46:15 AM: Evaluate: task mnli, batch 141 (209): accuracy: 0.8135, mnli_loss: 0.4935
09/06 01:46:25 AM: Evaluate: task mnli, batch 190 (209): accuracy: 0.8160, mnli_loss: 0.4958
09/06 01:46:29 AM: Updating LR scheduler:
09/06 01:46:29 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:46:29 AM: 	# validation passes without improvement: 1
09/06 01:46:29 AM: mnli_loss: training: 0.391770 validation: 0.502541
09/06 01:46:29 AM: macro_avg: validation: 0.814000
09/06 01:46:29 AM: micro_avg: validation: 0.814000
09/06 01:46:29 AM: mnli_accuracy: training: 0.850058 validation: 0.814000
09/06 01:46:29 AM: Global learning rate: 5e-06
09/06 01:46:29 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:46:36 AM: Update 29011: task mnli, batch 11 (29011): accuracy: 0.8371, mnli_loss: 0.4465
09/06 01:46:46 AM: Update 29030: task mnli, batch 30 (29030): accuracy: 0.8431, mnli_loss: 0.4351
09/06 01:46:56 AM: Update 29049: task mnli, batch 49 (29049): accuracy: 0.8393, mnli_loss: 0.4187
09/06 01:47:07 AM: Update 29069: task mnli, batch 69 (29069): accuracy: 0.8466, mnli_loss: 0.4001
09/06 01:47:17 AM: Update 29088: task mnli, batch 88 (29088): accuracy: 0.8499, mnli_loss: 0.3917
09/06 01:47:27 AM: Update 29107: task mnli, batch 107 (29107): accuracy: 0.8493, mnli_loss: 0.3937
09/06 01:47:37 AM: Update 29126: task mnli, batch 126 (29126): accuracy: 0.8535, mnli_loss: 0.3900
09/06 01:47:48 AM: Update 29145: task mnli, batch 145 (29145): accuracy: 0.8532, mnli_loss: 0.3913
09/06 01:47:58 AM: Update 29163: task mnli, batch 163 (29163): accuracy: 0.8540, mnli_loss: 0.3875
09/06 01:48:08 AM: Update 29181: task mnli, batch 181 (29181): accuracy: 0.8490, mnli_loss: 0.3936
09/06 01:48:18 AM: Update 29199: task mnli, batch 199 (29199): accuracy: 0.8499, mnli_loss: 0.3899
09/06 01:48:29 AM: Update 29217: task mnli, batch 217 (29217): accuracy: 0.8491, mnli_loss: 0.3912
09/06 01:48:39 AM: Update 29235: task mnli, batch 235 (29235): accuracy: 0.8509, mnli_loss: 0.3865
09/06 01:48:49 AM: Update 29253: task mnli, batch 253 (29253): accuracy: 0.8508, mnli_loss: 0.3867
09/06 01:49:00 AM: Update 29271: task mnli, batch 271 (29271): accuracy: 0.8519, mnli_loss: 0.3880
09/06 01:49:10 AM: Update 29290: task mnli, batch 290 (29290): accuracy: 0.8533, mnli_loss: 0.3840
09/06 01:49:20 AM: Update 29305: task mnli, batch 305 (29305): accuracy: 0.8537, mnli_loss: 0.3822
09/06 01:49:31 AM: Update 29323: task mnli, batch 323 (29323): accuracy: 0.8527, mnli_loss: 0.3872
09/06 01:49:41 AM: Update 29340: task mnli, batch 340 (29340): accuracy: 0.8523, mnli_loss: 0.3881
09/06 01:49:51 AM: Update 29359: task mnli, batch 359 (29359): accuracy: 0.8507, mnli_loss: 0.3918
09/06 01:50:01 AM: Update 29379: task mnli, batch 379 (29379): accuracy: 0.8513, mnli_loss: 0.3894
09/06 01:50:11 AM: Update 29397: task mnli, batch 397 (29397): accuracy: 0.8520, mnli_loss: 0.3882
09/06 01:50:21 AM: Update 29416: task mnli, batch 416 (29416): accuracy: 0.8522, mnli_loss: 0.3871
09/06 01:50:32 AM: Update 29435: task mnli, batch 435 (29435): accuracy: 0.8516, mnli_loss: 0.3883
09/06 01:50:42 AM: Update 29454: task mnli, batch 454 (29454): accuracy: 0.8510, mnli_loss: 0.3898
09/06 01:50:52 AM: Update 29472: task mnli, batch 472 (29472): accuracy: 0.8491, mnli_loss: 0.3919
09/06 01:51:03 AM: Update 29492: task mnli, batch 492 (29492): accuracy: 0.8492, mnli_loss: 0.3902
09/06 01:51:13 AM: Update 29510: task mnli, batch 510 (29510): accuracy: 0.8480, mnli_loss: 0.3929
09/06 01:51:23 AM: Update 29529: task mnli, batch 529 (29529): accuracy: 0.8476, mnli_loss: 0.3940
09/06 01:51:34 AM: Update 29549: task mnli, batch 549 (29549): accuracy: 0.8472, mnli_loss: 0.3947
09/06 01:51:44 AM: Update 29568: task mnli, batch 568 (29568): accuracy: 0.8471, mnli_loss: 0.3950
09/06 01:51:54 AM: Update 29586: task mnli, batch 586 (29586): accuracy: 0.8478, mnli_loss: 0.3944
09/06 01:52:04 AM: Update 29606: task mnli, batch 606 (29606): accuracy: 0.8483, mnli_loss: 0.3930
09/06 01:52:15 AM: Update 29625: task mnli, batch 625 (29625): accuracy: 0.8473, mnli_loss: 0.3949
09/06 01:52:25 AM: Update 29644: task mnli, batch 644 (29644): accuracy: 0.8477, mnli_loss: 0.3947
09/06 01:52:35 AM: Update 29664: task mnli, batch 664 (29664): accuracy: 0.8467, mnli_loss: 0.3965
09/06 01:52:46 AM: Update 29682: task mnli, batch 682 (29682): accuracy: 0.8473, mnli_loss: 0.3945
09/06 01:52:56 AM: Update 29702: task mnli, batch 702 (29702): accuracy: 0.8476, mnli_loss: 0.3943
09/06 01:53:06 AM: Update 29720: task mnli, batch 720 (29720): accuracy: 0.8478, mnli_loss: 0.3943
09/06 01:53:16 AM: Update 29734: task mnli, batch 734 (29734): accuracy: 0.8475, mnli_loss: 0.3957
09/06 01:53:27 AM: Update 29755: task mnli, batch 755 (29755): accuracy: 0.8478, mnli_loss: 0.3961
09/06 01:53:37 AM: Update 29773: task mnli, batch 773 (29773): accuracy: 0.8480, mnli_loss: 0.3962
09/06 01:53:48 AM: Update 29791: task mnli, batch 791 (29791): accuracy: 0.8483, mnli_loss: 0.3956
09/06 01:53:58 AM: Update 29809: task mnli, batch 809 (29809): accuracy: 0.8487, mnli_loss: 0.3947
09/06 01:54:08 AM: Update 29829: task mnli, batch 829 (29829): accuracy: 0.8477, mnli_loss: 0.3956
09/06 01:54:18 AM: Update 29849: task mnli, batch 849 (29849): accuracy: 0.8479, mnli_loss: 0.3948
09/06 01:54:29 AM: Update 29868: task mnli, batch 868 (29868): accuracy: 0.8483, mnli_loss: 0.3936
09/06 01:54:39 AM: Update 29888: task mnli, batch 888 (29888): accuracy: 0.8490, mnli_loss: 0.3927
09/06 01:54:49 AM: Update 29905: task mnli, batch 905 (29905): accuracy: 0.8490, mnli_loss: 0.3922
09/06 01:54:59 AM: Update 29925: task mnli, batch 925 (29925): accuracy: 0.8498, mnli_loss: 0.3903
09/06 01:55:09 AM: Update 29943: task mnli, batch 943 (29943): accuracy: 0.8500, mnli_loss: 0.3901
09/06 01:55:19 AM: Update 29962: task mnli, batch 962 (29962): accuracy: 0.8502, mnli_loss: 0.3901
09/06 01:55:29 AM: Update 29980: task mnli, batch 980 (29980): accuracy: 0.8501, mnli_loss: 0.3903
09/06 01:55:40 AM: Update 29998: task mnli, batch 998 (29998): accuracy: 0.8504, mnli_loss: 0.3907
09/06 01:55:41 AM: ***** Step 30000 / Validation 30 *****
09/06 01:55:41 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 01:55:41 AM: Validating...
09/06 01:55:50 AM: Evaluate: task mnli, batch 44 (209): accuracy: 0.8106, mnli_loss: 0.4840
09/06 01:56:00 AM: Evaluate: task mnli, batch 94 (209): accuracy: 0.8156, mnli_loss: 0.4848
09/06 01:56:10 AM: Evaluate: task mnli, batch 144 (209): accuracy: 0.8128, mnli_loss: 0.4961
09/06 01:56:20 AM: Evaluate: task mnli, batch 194 (209): accuracy: 0.8142, mnli_loss: 0.4964
09/06 01:56:23 AM: Updating LR scheduler:
09/06 01:56:23 AM: 	Best result seen so far for macro_avg: 0.814
09/06 01:56:23 AM: 	# validation passes without improvement: 2
09/06 01:56:23 AM: mnli_loss: training: 0.390810 validation: 0.505887
09/06 01:56:23 AM: macro_avg: validation: 0.811200
09/06 01:56:23 AM: micro_avg: validation: 0.811200
09/06 01:56:23 AM: mnli_accuracy: training: 0.850275 validation: 0.811200
09/06 01:56:23 AM: Global learning rate: 5e-06
09/06 01:56:23 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 01:56:31 AM: Update 30011: task mnli, batch 11 (30011): accuracy: 0.8371, mnli_loss: 0.4275
09/06 01:56:41 AM: Update 30031: task mnli, batch 31 (30031): accuracy: 0.8481, mnli_loss: 0.3893
09/06 01:56:51 AM: Update 30049: task mnli, batch 49 (30049): accuracy: 0.8469, mnli_loss: 0.3867
09/06 01:57:02 AM: Update 30067: task mnli, batch 67 (30067): accuracy: 0.8470, mnli_loss: 0.3905
09/06 01:57:13 AM: Update 30087: task mnli, batch 87 (30087): accuracy: 0.8467, mnli_loss: 0.3881
09/06 01:57:23 AM: Update 30105: task mnli, batch 105 (30105): accuracy: 0.8444, mnli_loss: 0.3890
09/06 01:57:33 AM: Update 30124: task mnli, batch 124 (30124): accuracy: 0.8448, mnli_loss: 0.3904
09/06 01:57:44 AM: Update 30140: task mnli, batch 140 (30140): accuracy: 0.8467, mnli_loss: 0.3927
09/06 01:57:54 AM: Update 30160: task mnli, batch 160 (30160): accuracy: 0.8455, mnli_loss: 0.3983
09/06 01:58:04 AM: Update 30178: task mnli, batch 178 (30178): accuracy: 0.8455, mnli_loss: 0.3984
09/06 01:58:14 AM: Update 30196: task mnli, batch 196 (30196): accuracy: 0.8441, mnli_loss: 0.3979
09/06 01:58:24 AM: Update 30215: task mnli, batch 215 (30215): accuracy: 0.8445, mnli_loss: 0.3983
09/06 01:58:35 AM: Update 30235: task mnli, batch 235 (30235): accuracy: 0.8434, mnli_loss: 0.3968
09/06 01:58:46 AM: Update 30255: task mnli, batch 255 (30255): accuracy: 0.8464, mnli_loss: 0.3937
09/06 01:58:56 AM: Update 30273: task mnli, batch 273 (30273): accuracy: 0.8476, mnli_loss: 0.3925
09/06 01:59:06 AM: Update 30292: task mnli, batch 292 (30292): accuracy: 0.8461, mnli_loss: 0.3958
09/06 01:59:17 AM: Update 30311: task mnli, batch 311 (30311): accuracy: 0.8452, mnli_loss: 0.3986
09/06 01:59:27 AM: Update 30330: task mnli, batch 330 (30330): accuracy: 0.8454, mnli_loss: 0.3978
09/06 01:59:37 AM: Update 30349: task mnli, batch 349 (30349): accuracy: 0.8460, mnli_loss: 0.3968
09/06 01:59:47 AM: Update 30367: task mnli, batch 367 (30367): accuracy: 0.8459, mnli_loss: 0.3967
09/06 01:59:57 AM: Update 30385: task mnli, batch 385 (30385): accuracy: 0.8466, mnli_loss: 0.3965
09/06 02:00:07 AM: Update 30403: task mnli, batch 403 (30403): accuracy: 0.8470, mnli_loss: 0.3969
09/06 02:00:18 AM: Update 30422: task mnli, batch 422 (30422): accuracy: 0.8465, mnli_loss: 0.3979
09/06 02:00:28 AM: Update 30441: task mnli, batch 441 (30441): accuracy: 0.8463, mnli_loss: 0.3993
09/06 02:00:38 AM: Update 30459: task mnli, batch 459 (30459): accuracy: 0.8457, mnli_loss: 0.4008
09/06 02:00:49 AM: Update 30477: task mnli, batch 477 (30477): accuracy: 0.8457, mnli_loss: 0.3999
09/06 02:00:59 AM: Update 30496: task mnli, batch 496 (30496): accuracy: 0.8451, mnli_loss: 0.4016
09/06 02:01:10 AM: Update 30518: task mnli, batch 518 (30518): accuracy: 0.8450, mnli_loss: 0.4024
09/06 02:01:20 AM: Update 30537: task mnli, batch 537 (30537): accuracy: 0.8450, mnli_loss: 0.4033
09/06 02:01:33 AM: Update 30555: task mnli, batch 555 (30555): accuracy: 0.8445, mnli_loss: 0.4035
09/06 02:01:44 AM: Update 30572: task mnli, batch 572 (30572): accuracy: 0.8450, mnli_loss: 0.4030
09/06 02:01:54 AM: Update 30591: task mnli, batch 591 (30591): accuracy: 0.8452, mnli_loss: 0.4021
09/06 02:02:04 AM: Update 30611: task mnli, batch 611 (30611): accuracy: 0.8454, mnli_loss: 0.4009
09/06 02:02:14 AM: Update 30631: task mnli, batch 631 (30631): accuracy: 0.8452, mnli_loss: 0.4005
09/06 02:02:25 AM: Update 30651: task mnli, batch 651 (30651): accuracy: 0.8465, mnli_loss: 0.3978
09/06 02:02:35 AM: Update 30672: task mnli, batch 672 (30672): accuracy: 0.8474, mnli_loss: 0.3964
09/06 02:02:46 AM: Update 30691: task mnli, batch 691 (30691): accuracy: 0.8465, mnli_loss: 0.3983
09/06 02:02:56 AM: Update 30710: task mnli, batch 710 (30710): accuracy: 0.8467, mnli_loss: 0.3982
09/06 02:03:07 AM: Update 30728: task mnli, batch 728 (30728): accuracy: 0.8470, mnli_loss: 0.3978
09/06 02:03:17 AM: Update 30748: task mnli, batch 748 (30748): accuracy: 0.8477, mnli_loss: 0.3949
09/06 02:03:27 AM: Update 30769: task mnli, batch 769 (30769): accuracy: 0.8477, mnli_loss: 0.3946
09/06 02:03:38 AM: Update 30786: task mnli, batch 786 (30786): accuracy: 0.8474, mnli_loss: 0.3944
09/06 02:03:48 AM: Update 30804: task mnli, batch 804 (30804): accuracy: 0.8467, mnli_loss: 0.3946
09/06 02:03:58 AM: Update 30824: task mnli, batch 824 (30824): accuracy: 0.8472, mnli_loss: 0.3933
09/06 02:04:08 AM: Update 30842: task mnli, batch 842 (30842): accuracy: 0.8470, mnli_loss: 0.3936
09/06 02:04:18 AM: Update 30860: task mnli, batch 860 (30860): accuracy: 0.8471, mnli_loss: 0.3928
09/06 02:04:29 AM: Update 30878: task mnli, batch 878 (30878): accuracy: 0.8466, mnli_loss: 0.3948
09/06 02:04:39 AM: Update 30897: task mnli, batch 897 (30897): accuracy: 0.8462, mnli_loss: 0.3957
09/06 02:04:50 AM: Update 30915: task mnli, batch 915 (30915): accuracy: 0.8457, mnli_loss: 0.3963
09/06 02:05:00 AM: Update 30933: task mnli, batch 933 (30933): accuracy: 0.8455, mnli_loss: 0.3966
09/06 02:05:10 AM: Update 30952: task mnli, batch 952 (30952): accuracy: 0.8453, mnli_loss: 0.3965
09/06 02:05:21 AM: Update 30971: task mnli, batch 971 (30971): accuracy: 0.8452, mnli_loss: 0.3964
09/06 02:05:31 AM: Update 30986: task mnli, batch 986 (30986): accuracy: 0.8455, mnli_loss: 0.3959
09/06 02:05:39 AM: ***** Step 31000 / Validation 31 *****
09/06 02:05:39 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:05:39 AM: Validating...
09/06 02:05:42 AM: Evaluate: task mnli, batch 12 (209): accuracy: 0.8264, mnli_loss: 0.4368
09/06 02:05:52 AM: Evaluate: task mnli, batch 62 (209): accuracy: 0.8145, mnli_loss: 0.4882
09/06 02:06:02 AM: Evaluate: task mnli, batch 111 (209): accuracy: 0.8101, mnli_loss: 0.5000
09/06 02:06:12 AM: Evaluate: task mnli, batch 161 (209): accuracy: 0.8142, mnli_loss: 0.4956
09/06 02:06:21 AM: Updating LR scheduler:
09/06 02:06:21 AM: 	Best result seen so far for macro_avg: 0.814
09/06 02:06:21 AM: 	# validation passes without improvement: 3
09/06 02:06:21 AM: mnli_loss: training: 0.396146 validation: 0.508951
09/06 02:06:21 AM: macro_avg: validation: 0.810200
09/06 02:06:21 AM: micro_avg: validation: 0.810200
09/06 02:06:21 AM: mnli_accuracy: training: 0.845387 validation: 0.810200
09/06 02:06:21 AM: Global learning rate: 5e-06
09/06 02:06:21 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:06:23 AM: Update 31001: task mnli, batch 1 (31001): accuracy: 0.9167, mnli_loss: 0.3229
09/06 02:06:33 AM: Update 31020: task mnli, batch 20 (31020): accuracy: 0.8562, mnli_loss: 0.3563
09/06 02:06:44 AM: Update 31038: task mnli, batch 38 (31038): accuracy: 0.8476, mnli_loss: 0.3669
09/06 02:06:54 AM: Update 31057: task mnli, batch 57 (31057): accuracy: 0.8567, mnli_loss: 0.3715
09/06 02:07:05 AM: Update 31076: task mnli, batch 76 (31076): accuracy: 0.8591, mnli_loss: 0.3671
09/06 02:07:15 AM: Update 31094: task mnli, batch 94 (31094): accuracy: 0.8595, mnli_loss: 0.3647
09/06 02:07:25 AM: Update 31114: task mnli, batch 114 (31114): accuracy: 0.8578, mnli_loss: 0.3729
09/06 02:07:35 AM: Update 31132: task mnli, batch 132 (31132): accuracy: 0.8586, mnli_loss: 0.3709
09/06 02:07:46 AM: Update 31151: task mnli, batch 151 (31151): accuracy: 0.8584, mnli_loss: 0.3733
09/06 02:07:56 AM: Update 31171: task mnli, batch 171 (31171): accuracy: 0.8553, mnli_loss: 0.3749
09/06 02:08:07 AM: Update 31190: task mnli, batch 190 (31190): accuracy: 0.8553, mnli_loss: 0.3763
09/06 02:08:17 AM: Update 31208: task mnli, batch 208 (31208): accuracy: 0.8506, mnli_loss: 0.3855
09/06 02:08:27 AM: Update 31227: task mnli, batch 227 (31227): accuracy: 0.8488, mnli_loss: 0.3893
09/06 02:08:37 AM: Update 31246: task mnli, batch 246 (31246): accuracy: 0.8501, mnli_loss: 0.3854
09/06 02:08:47 AM: Update 31264: task mnli, batch 264 (31264): accuracy: 0.8516, mnli_loss: 0.3827
09/06 02:08:58 AM: Update 31282: task mnli, batch 282 (31282): accuracy: 0.8500, mnli_loss: 0.3851
09/06 02:09:08 AM: Update 31302: task mnli, batch 302 (31302): accuracy: 0.8489, mnli_loss: 0.3875
09/06 02:09:19 AM: Update 31322: task mnli, batch 322 (31322): accuracy: 0.8476, mnli_loss: 0.3889
09/06 02:09:29 AM: Update 31340: task mnli, batch 340 (31340): accuracy: 0.8484, mnli_loss: 0.3883
09/06 02:09:39 AM: Update 31359: task mnli, batch 359 (31359): accuracy: 0.8477, mnli_loss: 0.3889
09/06 02:09:49 AM: Update 31379: task mnli, batch 379 (31379): accuracy: 0.8473, mnli_loss: 0.3905
09/06 02:10:00 AM: Update 31393: task mnli, batch 393 (31393): accuracy: 0.8459, mnli_loss: 0.3935
09/06 02:10:10 AM: Update 31412: task mnli, batch 412 (31412): accuracy: 0.8449, mnli_loss: 0.3943
09/06 02:10:20 AM: Update 31431: task mnli, batch 431 (31431): accuracy: 0.8449, mnli_loss: 0.3936
09/06 02:10:30 AM: Update 31450: task mnli, batch 450 (31450): accuracy: 0.8439, mnli_loss: 0.3958
09/06 02:10:40 AM: Update 31469: task mnli, batch 469 (31469): accuracy: 0.8449, mnli_loss: 0.3951
09/06 02:10:50 AM: Update 31487: task mnli, batch 487 (31487): accuracy: 0.8448, mnli_loss: 0.3960
09/06 02:11:00 AM: Update 31506: task mnli, batch 506 (31506): accuracy: 0.8453, mnli_loss: 0.3955
09/06 02:11:11 AM: Update 31524: task mnli, batch 524 (31524): accuracy: 0.8464, mnli_loss: 0.3935
09/06 02:11:21 AM: Update 31542: task mnli, batch 542 (31542): accuracy: 0.8464, mnli_loss: 0.3930
09/06 02:11:31 AM: Update 31560: task mnli, batch 560 (31560): accuracy: 0.8463, mnli_loss: 0.3929
09/06 02:11:41 AM: Update 31579: task mnli, batch 579 (31579): accuracy: 0.8459, mnli_loss: 0.3945
09/06 02:11:51 AM: Update 31598: task mnli, batch 598 (31598): accuracy: 0.8466, mnli_loss: 0.3938
09/06 02:12:02 AM: Update 31616: task mnli, batch 616 (31616): accuracy: 0.8466, mnli_loss: 0.3929
09/06 02:12:12 AM: Update 31635: task mnli, batch 635 (31635): accuracy: 0.8470, mnli_loss: 0.3917
09/06 02:12:22 AM: Update 31654: task mnli, batch 654 (31654): accuracy: 0.8463, mnli_loss: 0.3925
09/06 02:12:32 AM: Update 31672: task mnli, batch 672 (31672): accuracy: 0.8464, mnli_loss: 0.3919
09/06 02:12:43 AM: Update 31691: task mnli, batch 691 (31691): accuracy: 0.8459, mnli_loss: 0.3929
09/06 02:12:53 AM: Update 31710: task mnli, batch 710 (31710): accuracy: 0.8458, mnli_loss: 0.3927
09/06 02:13:03 AM: Update 31730: task mnli, batch 730 (31730): accuracy: 0.8463, mnli_loss: 0.3918
09/06 02:13:13 AM: Update 31749: task mnli, batch 749 (31749): accuracy: 0.8461, mnli_loss: 0.3927
09/06 02:13:24 AM: Update 31769: task mnli, batch 769 (31769): accuracy: 0.8464, mnli_loss: 0.3917
09/06 02:13:34 AM: Update 31786: task mnli, batch 786 (31786): accuracy: 0.8464, mnli_loss: 0.3915
09/06 02:13:44 AM: Update 31805: task mnli, batch 805 (31805): accuracy: 0.8464, mnli_loss: 0.3915
09/06 02:13:54 AM: Update 31818: task mnli, batch 818 (31818): accuracy: 0.8457, mnli_loss: 0.3934
09/06 02:14:05 AM: Update 31837: task mnli, batch 837 (31837): accuracy: 0.8452, mnli_loss: 0.3947
09/06 02:14:15 AM: Update 31855: task mnli, batch 855 (31855): accuracy: 0.8457, mnli_loss: 0.3935
09/06 02:14:25 AM: Update 31874: task mnli, batch 874 (31874): accuracy: 0.8451, mnli_loss: 0.3941
09/06 02:14:35 AM: Update 31892: task mnli, batch 892 (31892): accuracy: 0.8449, mnli_loss: 0.3949
09/06 02:14:45 AM: Update 31910: task mnli, batch 910 (31910): accuracy: 0.8455, mnli_loss: 0.3945
09/06 02:14:56 AM: Update 31928: task mnli, batch 928 (31928): accuracy: 0.8460, mnli_loss: 0.3941
09/06 02:15:06 AM: Update 31948: task mnli, batch 948 (31948): accuracy: 0.8458, mnli_loss: 0.3935
09/06 02:15:16 AM: Update 31967: task mnli, batch 967 (31967): accuracy: 0.8459, mnli_loss: 0.3937
09/06 02:15:27 AM: Update 31986: task mnli, batch 986 (31986): accuracy: 0.8464, mnli_loss: 0.3929
09/06 02:15:34 AM: ***** Step 32000 / Validation 32 *****
09/06 02:15:34 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:15:34 AM: Validating...
09/06 02:15:37 AM: Evaluate: task mnli, batch 15 (209): accuracy: 0.8222, mnli_loss: 0.4694
09/06 02:15:47 AM: Evaluate: task mnli, batch 65 (209): accuracy: 0.8199, mnli_loss: 0.4754
09/06 02:15:57 AM: Evaluate: task mnli, batch 115 (209): accuracy: 0.8138, mnli_loss: 0.4907
09/06 02:16:07 AM: Evaluate: task mnli, batch 165 (209): accuracy: 0.8199, mnli_loss: 0.4844
09/06 02:16:16 AM: Best result seen so far for mnli.
09/06 02:16:16 AM: Best result seen so far for micro.
09/06 02:16:16 AM: Best result seen so far for macro.
09/06 02:16:16 AM: Updating LR scheduler:
09/06 02:16:16 AM: 	Best result seen so far for macro_avg: 0.815
09/06 02:16:16 AM: 	# validation passes without improvement: 0
09/06 02:16:16 AM: mnli_loss: training: 0.392602 validation: 0.495729
09/06 02:16:16 AM: macro_avg: validation: 0.815200
09/06 02:16:16 AM: micro_avg: validation: 0.815200
09/06 02:16:16 AM: mnli_accuracy: training: 0.846606 validation: 0.815200
09/06 02:16:16 AM: Global learning rate: 5e-06
09/06 02:16:16 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:16:17 AM: Update 32001: task mnli, batch 1 (32001): accuracy: 0.9167, mnli_loss: 0.2766
09/06 02:16:27 AM: Update 32019: task mnli, batch 19 (32019): accuracy: 0.8662, mnli_loss: 0.3660
09/06 02:16:38 AM: Update 32038: task mnli, batch 38 (32038): accuracy: 0.8586, mnli_loss: 0.3703
09/06 02:16:48 AM: Update 32057: task mnli, batch 57 (32057): accuracy: 0.8501, mnli_loss: 0.3772
09/06 02:16:58 AM: Update 32075: task mnli, batch 75 (32075): accuracy: 0.8489, mnli_loss: 0.3853
09/06 02:17:08 AM: Update 32094: task mnli, batch 94 (32094): accuracy: 0.8555, mnli_loss: 0.3713
09/06 02:17:19 AM: Update 32112: task mnli, batch 112 (32112): accuracy: 0.8564, mnli_loss: 0.3703
09/06 02:17:29 AM: Update 32130: task mnli, batch 130 (32130): accuracy: 0.8558, mnli_loss: 0.3704
09/06 02:17:39 AM: Update 32149: task mnli, batch 149 (32149): accuracy: 0.8605, mnli_loss: 0.3641
09/06 02:17:49 AM: Update 32169: task mnli, batch 169 (32169): accuracy: 0.8555, mnli_loss: 0.3735
09/06 02:18:00 AM: Update 32189: task mnli, batch 189 (32189): accuracy: 0.8547, mnli_loss: 0.3750
09/06 02:18:10 AM: Update 32209: task mnli, batch 209 (32209): accuracy: 0.8547, mnli_loss: 0.3768
09/06 02:18:21 AM: Update 32223: task mnli, batch 223 (32223): accuracy: 0.8540, mnli_loss: 0.3795
09/06 02:18:31 AM: Update 32241: task mnli, batch 241 (32241): accuracy: 0.8534, mnli_loss: 0.3794
09/06 02:18:41 AM: Update 32261: task mnli, batch 261 (32261): accuracy: 0.8534, mnli_loss: 0.3792
09/06 02:18:52 AM: Update 32281: task mnli, batch 281 (32281): accuracy: 0.8547, mnli_loss: 0.3788
09/06 02:19:02 AM: Update 32299: task mnli, batch 299 (32299): accuracy: 0.8553, mnli_loss: 0.3788
09/06 02:19:12 AM: Update 32318: task mnli, batch 318 (32318): accuracy: 0.8547, mnli_loss: 0.3820
09/06 02:19:22 AM: Update 32336: task mnli, batch 336 (32336): accuracy: 0.8541, mnli_loss: 0.3831
09/06 02:19:32 AM: Update 32356: task mnli, batch 356 (32356): accuracy: 0.8532, mnli_loss: 0.3843
09/06 02:19:43 AM: Update 32375: task mnli, batch 375 (32375): accuracy: 0.8532, mnli_loss: 0.3839
09/06 02:19:53 AM: Update 32394: task mnli, batch 394 (32394): accuracy: 0.8523, mnli_loss: 0.3843
09/06 02:20:03 AM: Update 32414: task mnli, batch 414 (32414): accuracy: 0.8539, mnli_loss: 0.3840
09/06 02:20:14 AM: Update 32433: task mnli, batch 433 (32433): accuracy: 0.8533, mnli_loss: 0.3831
09/06 02:20:24 AM: Update 32452: task mnli, batch 452 (32452): accuracy: 0.8531, mnli_loss: 0.3839
09/06 02:20:34 AM: Update 32471: task mnli, batch 471 (32471): accuracy: 0.8523, mnli_loss: 0.3842
09/06 02:20:44 AM: Update 32491: task mnli, batch 491 (32491): accuracy: 0.8515, mnli_loss: 0.3862
09/06 02:20:54 AM: Update 32509: task mnli, batch 509 (32509): accuracy: 0.8518, mnli_loss: 0.3866
09/06 02:21:04 AM: Update 32526: task mnli, batch 526 (32526): accuracy: 0.8515, mnli_loss: 0.3866
09/06 02:21:15 AM: Update 32545: task mnli, batch 545 (32545): accuracy: 0.8515, mnli_loss: 0.3884
09/06 02:21:25 AM: Update 32562: task mnli, batch 562 (32562): accuracy: 0.8513, mnli_loss: 0.3875
09/06 02:21:36 AM: Update 32582: task mnli, batch 582 (32582): accuracy: 0.8515, mnli_loss: 0.3863
09/06 02:21:46 AM: Update 32600: task mnli, batch 600 (32600): accuracy: 0.8512, mnli_loss: 0.3861
09/06 02:21:56 AM: Update 32618: task mnli, batch 618 (32618): accuracy: 0.8507, mnli_loss: 0.3880
09/06 02:22:06 AM: Update 32636: task mnli, batch 636 (32636): accuracy: 0.8505, mnli_loss: 0.3887
09/06 02:22:17 AM: Update 32653: task mnli, batch 653 (32653): accuracy: 0.8503, mnli_loss: 0.3893
09/06 02:22:27 AM: Update 32672: task mnli, batch 672 (32672): accuracy: 0.8505, mnli_loss: 0.3882
09/06 02:22:37 AM: Update 32692: task mnli, batch 692 (32692): accuracy: 0.8497, mnli_loss: 0.3892
09/06 02:22:48 AM: Update 32710: task mnli, batch 710 (32710): accuracy: 0.8495, mnli_loss: 0.3897
09/06 02:22:58 AM: Update 32730: task mnli, batch 730 (32730): accuracy: 0.8499, mnli_loss: 0.3895
09/06 02:23:08 AM: Update 32748: task mnli, batch 748 (32748): accuracy: 0.8498, mnli_loss: 0.3888
09/06 02:23:18 AM: Update 32762: task mnli, batch 762 (32762): accuracy: 0.8497, mnli_loss: 0.3888
09/06 02:23:29 AM: Update 32782: task mnli, batch 782 (32782): accuracy: 0.8506, mnli_loss: 0.3871
09/06 02:23:40 AM: Update 32802: task mnli, batch 802 (32802): accuracy: 0.8508, mnli_loss: 0.3860
09/06 02:23:50 AM: Update 32821: task mnli, batch 821 (32821): accuracy: 0.8505, mnli_loss: 0.3866
09/06 02:24:00 AM: Update 32840: task mnli, batch 840 (32840): accuracy: 0.8508, mnli_loss: 0.3863
09/06 02:24:11 AM: Update 32860: task mnli, batch 860 (32860): accuracy: 0.8510, mnli_loss: 0.3858
09/06 02:24:21 AM: Update 32879: task mnli, batch 879 (32879): accuracy: 0.8513, mnli_loss: 0.3852
09/06 02:24:31 AM: Update 32898: task mnli, batch 898 (32898): accuracy: 0.8512, mnli_loss: 0.3856
09/06 02:24:41 AM: Update 32917: task mnli, batch 917 (32917): accuracy: 0.8514, mnli_loss: 0.3847
09/06 02:24:52 AM: Update 32936: task mnli, batch 936 (32936): accuracy: 0.8517, mnli_loss: 0.3841
09/06 02:25:02 AM: Update 32955: task mnli, batch 955 (32955): accuracy: 0.8521, mnli_loss: 0.3829
09/06 02:25:12 AM: Update 32974: task mnli, batch 974 (32974): accuracy: 0.8519, mnli_loss: 0.3829
09/06 02:25:22 AM: Update 32993: task mnli, batch 993 (32993): accuracy: 0.8523, mnli_loss: 0.3815
09/06 02:25:27 AM: ***** Step 33000 / Validation 33 *****
09/06 02:25:27 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:25:27 AM: Validating...
09/06 02:25:33 AM: Evaluate: task mnli, batch 30 (209): accuracy: 0.8139, mnli_loss: 0.4733
09/06 02:25:43 AM: Evaluate: task mnli, batch 80 (209): accuracy: 0.8234, mnli_loss: 0.4689
09/06 02:25:53 AM: Evaluate: task mnli, batch 130 (209): accuracy: 0.8160, mnli_loss: 0.4858
09/06 02:26:03 AM: Evaluate: task mnli, batch 179 (209): accuracy: 0.8198, mnli_loss: 0.4873
09/06 02:26:09 AM: Best result seen so far for mnli.
09/06 02:26:09 AM: Best result seen so far for micro.
09/06 02:26:09 AM: Best result seen so far for macro.
09/06 02:26:09 AM: Updating LR scheduler:
09/06 02:26:09 AM: 	Best result seen so far for macro_avg: 0.816
09/06 02:26:09 AM: 	# validation passes without improvement: 0
09/06 02:26:09 AM: mnli_loss: training: 0.381560 validation: 0.494799
09/06 02:26:09 AM: macro_avg: validation: 0.815800
09/06 02:26:09 AM: micro_avg: validation: 0.815800
09/06 02:26:09 AM: mnli_accuracy: training: 0.852257 validation: 0.815800
09/06 02:26:09 AM: Global learning rate: 5e-06
09/06 02:26:09 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:26:13 AM: Update 33007: task mnli, batch 7 (33007): accuracy: 0.8750, mnli_loss: 0.3962
09/06 02:26:24 AM: Update 33026: task mnli, batch 26 (33026): accuracy: 0.8750, mnli_loss: 0.3462
09/06 02:26:34 AM: Update 33046: task mnli, batch 46 (33046): accuracy: 0.8668, mnli_loss: 0.3724
09/06 02:26:44 AM: Update 33065: task mnli, batch 65 (33065): accuracy: 0.8673, mnli_loss: 0.3653
09/06 02:26:54 AM: Update 33083: task mnli, batch 83 (33083): accuracy: 0.8604, mnli_loss: 0.3738
09/06 02:27:04 AM: Update 33100: task mnli, batch 100 (33100): accuracy: 0.8538, mnli_loss: 0.3916
09/06 02:27:15 AM: Update 33118: task mnli, batch 118 (33118): accuracy: 0.8531, mnli_loss: 0.3904
09/06 02:27:26 AM: Update 33136: task mnli, batch 136 (33136): accuracy: 0.8526, mnli_loss: 0.3894
09/06 02:27:36 AM: Update 33155: task mnli, batch 155 (33155): accuracy: 0.8556, mnli_loss: 0.3808
09/06 02:27:46 AM: Update 33171: task mnli, batch 171 (33171): accuracy: 0.8567, mnli_loss: 0.3775
09/06 02:27:57 AM: Update 33190: task mnli, batch 190 (33190): accuracy: 0.8598, mnli_loss: 0.3722
09/06 02:28:07 AM: Update 33209: task mnli, batch 209 (33209): accuracy: 0.8568, mnli_loss: 0.3767
09/06 02:28:18 AM: Update 33229: task mnli, batch 229 (33229): accuracy: 0.8579, mnli_loss: 0.3747
09/06 02:28:28 AM: Update 33247: task mnli, batch 247 (33247): accuracy: 0.8556, mnli_loss: 0.3795
09/06 02:28:38 AM: Update 33267: task mnli, batch 267 (33267): accuracy: 0.8561, mnli_loss: 0.3792
09/06 02:28:48 AM: Update 33287: task mnli, batch 287 (33287): accuracy: 0.8547, mnli_loss: 0.3808
09/06 02:28:58 AM: Update 33305: task mnli, batch 305 (33305): accuracy: 0.8554, mnli_loss: 0.3797
09/06 02:29:09 AM: Update 33324: task mnli, batch 324 (33324): accuracy: 0.8543, mnli_loss: 0.3844
09/06 02:29:19 AM: Update 33343: task mnli, batch 343 (33343): accuracy: 0.8558, mnli_loss: 0.3826
09/06 02:29:30 AM: Update 33362: task mnli, batch 362 (33362): accuracy: 0.8553, mnli_loss: 0.3838
09/06 02:29:40 AM: Update 33381: task mnli, batch 381 (33381): accuracy: 0.8554, mnli_loss: 0.3829
09/06 02:29:50 AM: Update 33399: task mnli, batch 399 (33399): accuracy: 0.8551, mnli_loss: 0.3831
09/06 02:30:00 AM: Update 33417: task mnli, batch 417 (33417): accuracy: 0.8556, mnli_loss: 0.3811
09/06 02:30:11 AM: Update 33436: task mnli, batch 436 (33436): accuracy: 0.8564, mnli_loss: 0.3794
09/06 02:30:21 AM: Update 33457: task mnli, batch 457 (33457): accuracy: 0.8578, mnli_loss: 0.3770
09/06 02:30:31 AM: Update 33477: task mnli, batch 477 (33477): accuracy: 0.8574, mnli_loss: 0.3781
09/06 02:30:41 AM: Update 33496: task mnli, batch 496 (33496): accuracy: 0.8581, mnli_loss: 0.3762
09/06 02:30:52 AM: Update 33515: task mnli, batch 515 (33515): accuracy: 0.8589, mnli_loss: 0.3751
09/06 02:31:02 AM: Update 33533: task mnli, batch 533 (33533): accuracy: 0.8587, mnli_loss: 0.3747
09/06 02:31:13 AM: Update 33553: task mnli, batch 553 (33553): accuracy: 0.8583, mnli_loss: 0.3745
09/06 02:31:23 AM: Update 33572: task mnli, batch 572 (33572): accuracy: 0.8580, mnli_loss: 0.3749
09/06 02:31:33 AM: Update 33587: task mnli, batch 587 (33587): accuracy: 0.8579, mnli_loss: 0.3738
09/06 02:31:43 AM: Update 33605: task mnli, batch 605 (33605): accuracy: 0.8579, mnli_loss: 0.3748
09/06 02:31:54 AM: Update 33623: task mnli, batch 623 (33623): accuracy: 0.8576, mnli_loss: 0.3765
09/06 02:32:04 AM: Update 33642: task mnli, batch 642 (33642): accuracy: 0.8576, mnli_loss: 0.3765
09/06 02:32:14 AM: Update 33660: task mnli, batch 660 (33660): accuracy: 0.8564, mnli_loss: 0.3792
09/06 02:32:24 AM: Update 33678: task mnli, batch 678 (33678): accuracy: 0.8557, mnli_loss: 0.3805
09/06 02:32:35 AM: Update 33697: task mnli, batch 697 (33697): accuracy: 0.8558, mnli_loss: 0.3804
09/06 02:32:45 AM: Update 33716: task mnli, batch 716 (33716): accuracy: 0.8553, mnli_loss: 0.3806
09/06 02:32:56 AM: Update 33735: task mnli, batch 735 (33735): accuracy: 0.8554, mnli_loss: 0.3800
09/06 02:33:06 AM: Update 33754: task mnli, batch 754 (33754): accuracy: 0.8556, mnli_loss: 0.3787
09/06 02:33:16 AM: Update 33773: task mnli, batch 773 (33773): accuracy: 0.8551, mnli_loss: 0.3793
09/06 02:33:27 AM: Update 33792: task mnli, batch 792 (33792): accuracy: 0.8550, mnli_loss: 0.3800
09/06 02:33:37 AM: Update 33812: task mnli, batch 812 (33812): accuracy: 0.8553, mnli_loss: 0.3789
09/06 02:33:48 AM: Update 33831: task mnli, batch 831 (33831): accuracy: 0.8552, mnli_loss: 0.3792
09/06 02:33:58 AM: Update 33849: task mnli, batch 849 (33849): accuracy: 0.8552, mnli_loss: 0.3785
09/06 02:34:08 AM: Update 33868: task mnli, batch 868 (33868): accuracy: 0.8554, mnli_loss: 0.3783
09/06 02:34:18 AM: Update 33888: task mnli, batch 888 (33888): accuracy: 0.8559, mnli_loss: 0.3777
09/06 02:34:28 AM: Update 33909: task mnli, batch 909 (33909): accuracy: 0.8557, mnli_loss: 0.3775
09/06 02:34:39 AM: Update 33928: task mnli, batch 928 (33928): accuracy: 0.8558, mnli_loss: 0.3770
09/06 02:34:49 AM: Update 33947: task mnli, batch 947 (33947): accuracy: 0.8558, mnli_loss: 0.3771
09/06 02:34:59 AM: Update 33964: task mnli, batch 964 (33964): accuracy: 0.8557, mnli_loss: 0.3766
09/06 02:35:10 AM: Update 33984: task mnli, batch 984 (33984): accuracy: 0.8559, mnli_loss: 0.3759
09/06 02:35:18 AM: ***** Step 34000 / Validation 34 *****
09/06 02:35:18 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:35:18 AM: Validating...
09/06 02:35:20 AM: Evaluate: task mnli, batch 10 (209): accuracy: 0.8042, mnli_loss: 0.4858
09/06 02:35:30 AM: Evaluate: task mnli, batch 60 (209): accuracy: 0.8181, mnli_loss: 0.4780
09/06 02:35:40 AM: Evaluate: task mnli, batch 110 (209): accuracy: 0.8136, mnli_loss: 0.4897
09/06 02:35:50 AM: Evaluate: task mnli, batch 156 (209): accuracy: 0.8154, mnli_loss: 0.4924
09/06 02:36:00 AM: Evaluate: task mnli, batch 205 (209): accuracy: 0.8157, mnli_loss: 0.4959
09/06 02:36:01 AM: Updating LR scheduler:
09/06 02:36:01 AM: 	Best result seen so far for macro_avg: 0.816
09/06 02:36:01 AM: 	# validation passes without improvement: 1
09/06 02:36:01 AM: mnli_loss: training: 0.377343 validation: 0.500613
09/06 02:36:01 AM: macro_avg: validation: 0.813800
09/06 02:36:01 AM: micro_avg: validation: 0.813800
09/06 02:36:01 AM: mnli_accuracy: training: 0.855487 validation: 0.813800
09/06 02:36:01 AM: Global learning rate: 5e-06
09/06 02:36:01 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:36:10 AM: Update 34011: task mnli, batch 11 (34011): accuracy: 0.8555, mnli_loss: 0.3740
09/06 02:36:20 AM: Update 34030: task mnli, batch 30 (34030): accuracy: 0.8525, mnli_loss: 0.3880
09/06 02:36:31 AM: Update 34049: task mnli, batch 49 (34049): accuracy: 0.8545, mnli_loss: 0.3711
09/06 02:36:41 AM: Update 34067: task mnli, batch 67 (34067): accuracy: 0.8500, mnli_loss: 0.3793
09/06 02:36:51 AM: Update 34086: task mnli, batch 86 (34086): accuracy: 0.8531, mnli_loss: 0.3745
09/06 02:37:02 AM: Update 34105: task mnli, batch 105 (34105): accuracy: 0.8515, mnli_loss: 0.3766
09/06 02:37:12 AM: Update 34124: task mnli, batch 124 (34124): accuracy: 0.8514, mnli_loss: 0.3795
09/06 02:37:23 AM: Update 34143: task mnli, batch 143 (34143): accuracy: 0.8540, mnli_loss: 0.3818
09/06 02:37:33 AM: Update 34162: task mnli, batch 162 (34162): accuracy: 0.8534, mnli_loss: 0.3830
09/06 02:37:43 AM: Update 34182: task mnli, batch 182 (34182): accuracy: 0.8539, mnli_loss: 0.3835
09/06 02:37:54 AM: Update 34200: task mnli, batch 200 (34200): accuracy: 0.8537, mnli_loss: 0.3827
09/06 02:38:04 AM: Update 34219: task mnli, batch 219 (34219): accuracy: 0.8540, mnli_loss: 0.3815
09/06 02:38:14 AM: Update 34237: task mnli, batch 237 (34237): accuracy: 0.8548, mnli_loss: 0.3796
09/06 02:38:25 AM: Update 34257: task mnli, batch 257 (34257): accuracy: 0.8554, mnli_loss: 0.3775
09/06 02:38:35 AM: Update 34276: task mnli, batch 276 (34276): accuracy: 0.8549, mnli_loss: 0.3788
09/06 02:38:45 AM: Update 34295: task mnli, batch 295 (34295): accuracy: 0.8556, mnli_loss: 0.3792
09/06 02:38:56 AM: Update 34314: task mnli, batch 314 (34314): accuracy: 0.8549, mnli_loss: 0.3793
09/06 02:39:06 AM: Update 34333: task mnli, batch 333 (34333): accuracy: 0.8552, mnli_loss: 0.3786
09/06 02:39:16 AM: Update 34353: task mnli, batch 353 (34353): accuracy: 0.8572, mnli_loss: 0.3740
09/06 02:39:27 AM: Update 34373: task mnli, batch 373 (34373): accuracy: 0.8587, mnli_loss: 0.3707
09/06 02:39:37 AM: Update 34392: task mnli, batch 392 (34392): accuracy: 0.8596, mnli_loss: 0.3695
09/06 02:39:47 AM: Update 34410: task mnli, batch 410 (34410): accuracy: 0.8592, mnli_loss: 0.3699
09/06 02:39:57 AM: Update 34425: task mnli, batch 425 (34425): accuracy: 0.8603, mnli_loss: 0.3680
09/06 02:40:08 AM: Update 34444: task mnli, batch 444 (34444): accuracy: 0.8607, mnli_loss: 0.3680
09/06 02:40:18 AM: Update 34463: task mnli, batch 463 (34463): accuracy: 0.8604, mnli_loss: 0.3689
09/06 02:40:28 AM: Update 34481: task mnli, batch 481 (34481): accuracy: 0.8594, mnli_loss: 0.3705
09/06 02:40:39 AM: Update 34501: task mnli, batch 501 (34501): accuracy: 0.8601, mnli_loss: 0.3679
09/06 02:40:49 AM: Update 34522: task mnli, batch 522 (34522): accuracy: 0.8605, mnli_loss: 0.3669
09/06 02:41:00 AM: Update 34540: task mnli, batch 540 (34540): accuracy: 0.8595, mnli_loss: 0.3682
09/06 02:41:10 AM: Update 34560: task mnli, batch 560 (34560): accuracy: 0.8576, mnli_loss: 0.3713
09/06 02:41:20 AM: Update 34579: task mnli, batch 579 (34579): accuracy: 0.8581, mnli_loss: 0.3705
09/06 02:41:30 AM: Update 34598: task mnli, batch 598 (34598): accuracy: 0.8574, mnli_loss: 0.3710
09/06 02:41:40 AM: Update 34618: task mnli, batch 618 (34618): accuracy: 0.8580, mnli_loss: 0.3689
09/06 02:41:51 AM: Update 34636: task mnli, batch 636 (34636): accuracy: 0.8574, mnli_loss: 0.3712
09/06 02:42:01 AM: Update 34655: task mnli, batch 655 (34655): accuracy: 0.8583, mnli_loss: 0.3698
09/06 02:42:11 AM: Update 34674: task mnli, batch 674 (34674): accuracy: 0.8574, mnli_loss: 0.3714
09/06 02:42:22 AM: Update 34692: task mnli, batch 692 (34692): accuracy: 0.8575, mnli_loss: 0.3721
09/06 02:42:32 AM: Update 34711: task mnli, batch 711 (34711): accuracy: 0.8570, mnli_loss: 0.3742
09/06 02:42:43 AM: Update 34731: task mnli, batch 731 (34731): accuracy: 0.8566, mnli_loss: 0.3745
09/06 02:42:53 AM: Update 34749: task mnli, batch 749 (34749): accuracy: 0.8563, mnli_loss: 0.3749
09/06 02:43:03 AM: Update 34768: task mnli, batch 768 (34768): accuracy: 0.8564, mnli_loss: 0.3750
09/06 02:43:14 AM: Update 34787: task mnli, batch 787 (34787): accuracy: 0.8562, mnli_loss: 0.3750
09/06 02:43:24 AM: Update 34806: task mnli, batch 806 (34806): accuracy: 0.8560, mnli_loss: 0.3753
09/06 02:43:34 AM: Update 34824: task mnli, batch 824 (34824): accuracy: 0.8561, mnli_loss: 0.3752
09/06 02:43:45 AM: Update 34839: task mnli, batch 839 (34839): accuracy: 0.8561, mnli_loss: 0.3751
09/06 02:43:55 AM: Update 34859: task mnli, batch 859 (34859): accuracy: 0.8561, mnli_loss: 0.3747
09/06 02:44:06 AM: Update 34877: task mnli, batch 877 (34877): accuracy: 0.8563, mnli_loss: 0.3745
09/06 02:44:16 AM: Update 34897: task mnli, batch 897 (34897): accuracy: 0.8566, mnli_loss: 0.3742
09/06 02:44:27 AM: Update 34916: task mnli, batch 916 (34916): accuracy: 0.8566, mnli_loss: 0.3730
09/06 02:44:37 AM: Update 34934: task mnli, batch 934 (34934): accuracy: 0.8568, mnli_loss: 0.3731
09/06 02:44:47 AM: Update 34954: task mnli, batch 954 (34954): accuracy: 0.8570, mnli_loss: 0.3726
09/06 02:44:58 AM: Update 34973: task mnli, batch 973 (34973): accuracy: 0.8569, mnli_loss: 0.3720
09/06 02:45:08 AM: Update 34991: task mnli, batch 991 (34991): accuracy: 0.8569, mnli_loss: 0.3717
09/06 02:45:13 AM: ***** Step 35000 / Validation 35 *****
09/06 02:45:13 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:45:13 AM: Validating...
09/06 02:45:18 AM: Evaluate: task mnli, batch 25 (209): accuracy: 0.8183, mnli_loss: 0.4497
09/06 02:45:28 AM: Evaluate: task mnli, batch 75 (209): accuracy: 0.8178, mnli_loss: 0.4753
09/06 02:45:38 AM: Evaluate: task mnli, batch 125 (209): accuracy: 0.8130, mnli_loss: 0.4848
09/06 02:45:48 AM: Evaluate: task mnli, batch 175 (209): accuracy: 0.8183, mnli_loss: 0.4817
09/06 02:45:55 AM: Updating LR scheduler:
09/06 02:45:55 AM: 	Best result seen so far for macro_avg: 0.816
09/06 02:45:55 AM: 	# validation passes without improvement: 2
09/06 02:45:55 AM: mnli_loss: training: 0.372309 validation: 0.492354
09/06 02:45:55 AM: macro_avg: validation: 0.815400
09/06 02:45:55 AM: micro_avg: validation: 0.815400
09/06 02:45:55 AM: mnli_accuracy: training: 0.856523 validation: 0.815400
09/06 02:45:55 AM: Global learning rate: 5e-06
09/06 02:45:55 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:45:59 AM: Update 35005: task mnli, batch 5 (35005): accuracy: 0.8250, mnli_loss: 0.4578
09/06 02:46:09 AM: Update 35023: task mnli, batch 23 (35023): accuracy: 0.8696, mnli_loss: 0.3830
09/06 02:46:19 AM: Update 35042: task mnli, batch 42 (35042): accuracy: 0.8671, mnli_loss: 0.3886
09/06 02:46:29 AM: Update 35061: task mnli, batch 61 (35061): accuracy: 0.8613, mnli_loss: 0.3930
09/06 02:46:39 AM: Update 35081: task mnli, batch 81 (35081): accuracy: 0.8657, mnli_loss: 0.3763
09/06 02:46:49 AM: Update 35100: task mnli, batch 100 (35100): accuracy: 0.8658, mnli_loss: 0.3731
09/06 02:47:00 AM: Update 35119: task mnli, batch 119 (35119): accuracy: 0.8627, mnli_loss: 0.3711
09/06 02:47:10 AM: Update 35139: task mnli, batch 139 (35139): accuracy: 0.8648, mnli_loss: 0.3637
09/06 02:47:21 AM: Update 35158: task mnli, batch 158 (35158): accuracy: 0.8650, mnli_loss: 0.3654
09/06 02:47:31 AM: Update 35177: task mnli, batch 177 (35177): accuracy: 0.8628, mnli_loss: 0.3690
09/06 02:47:41 AM: Update 35195: task mnli, batch 195 (35195): accuracy: 0.8588, mnli_loss: 0.3745
09/06 02:47:51 AM: Update 35214: task mnli, batch 214 (35214): accuracy: 0.8586, mnli_loss: 0.3760
09/06 02:48:01 AM: Update 35233: task mnli, batch 233 (35233): accuracy: 0.8603, mnli_loss: 0.3707
09/06 02:48:11 AM: Update 35253: task mnli, batch 253 (35253): accuracy: 0.8638, mnli_loss: 0.3631
09/06 02:48:21 AM: Update 35266: task mnli, batch 266 (35266): accuracy: 0.8610, mnli_loss: 0.3679
09/06 02:48:32 AM: Update 35286: task mnli, batch 286 (35286): accuracy: 0.8609, mnli_loss: 0.3693
09/06 02:48:42 AM: Update 35308: task mnli, batch 308 (35308): accuracy: 0.8609, mnli_loss: 0.3679
09/06 02:48:53 AM: Update 35326: task mnli, batch 326 (35326): accuracy: 0.8621, mnli_loss: 0.3649
09/06 02:49:03 AM: Update 35346: task mnli, batch 346 (35346): accuracy: 0.8626, mnli_loss: 0.3637
09/06 02:49:13 AM: Update 35363: task mnli, batch 363 (35363): accuracy: 0.8620, mnli_loss: 0.3644
09/06 02:49:23 AM: Update 35381: task mnli, batch 381 (35381): accuracy: 0.8609, mnli_loss: 0.3683
09/06 02:49:34 AM: Update 35400: task mnli, batch 400 (35400): accuracy: 0.8616, mnli_loss: 0.3669
09/06 02:49:44 AM: Update 35419: task mnli, batch 419 (35419): accuracy: 0.8604, mnli_loss: 0.3673
09/06 02:49:54 AM: Update 35439: task mnli, batch 439 (35439): accuracy: 0.8594, mnli_loss: 0.3684
09/06 02:50:04 AM: Update 35458: task mnli, batch 458 (35458): accuracy: 0.8610, mnli_loss: 0.3648
09/06 02:50:15 AM: Update 35476: task mnli, batch 476 (35476): accuracy: 0.8611, mnli_loss: 0.3630
09/06 02:50:25 AM: Update 35495: task mnli, batch 495 (35495): accuracy: 0.8599, mnli_loss: 0.3643
09/06 02:50:36 AM: Update 35515: task mnli, batch 515 (35515): accuracy: 0.8602, mnli_loss: 0.3638
09/06 02:50:46 AM: Update 35532: task mnli, batch 532 (35532): accuracy: 0.8599, mnli_loss: 0.3640
09/06 02:50:56 AM: Update 35550: task mnli, batch 550 (35550): accuracy: 0.8592, mnli_loss: 0.3657
09/06 02:51:06 AM: Update 35569: task mnli, batch 569 (35569): accuracy: 0.8591, mnli_loss: 0.3655
09/06 02:51:16 AM: Update 35588: task mnli, batch 588 (35588): accuracy: 0.8598, mnli_loss: 0.3639
09/06 02:51:26 AM: Update 35605: task mnli, batch 605 (35605): accuracy: 0.8597, mnli_loss: 0.3638
09/06 02:51:37 AM: Update 35624: task mnli, batch 624 (35624): accuracy: 0.8606, mnli_loss: 0.3630
09/06 02:51:47 AM: Update 35644: task mnli, batch 644 (35644): accuracy: 0.8610, mnli_loss: 0.3617
09/06 02:51:57 AM: Update 35663: task mnli, batch 663 (35663): accuracy: 0.8612, mnli_loss: 0.3613
09/06 02:52:07 AM: Update 35675: task mnli, batch 675 (35675): accuracy: 0.8603, mnli_loss: 0.3632
09/06 02:52:17 AM: Update 35693: task mnli, batch 693 (35693): accuracy: 0.8607, mnli_loss: 0.3624
09/06 02:52:28 AM: Update 35711: task mnli, batch 711 (35711): accuracy: 0.8611, mnli_loss: 0.3612
09/06 02:52:38 AM: Update 35729: task mnli, batch 729 (35729): accuracy: 0.8601, mnli_loss: 0.3632
09/06 02:52:48 AM: Update 35746: task mnli, batch 746 (35746): accuracy: 0.8600, mnli_loss: 0.3634
09/06 02:52:58 AM: Update 35764: task mnli, batch 764 (35764): accuracy: 0.8600, mnli_loss: 0.3636
09/06 02:53:08 AM: Update 35782: task mnli, batch 782 (35782): accuracy: 0.8600, mnli_loss: 0.3643
09/06 02:53:18 AM: Update 35801: task mnli, batch 801 (35801): accuracy: 0.8603, mnli_loss: 0.3643
09/06 02:53:29 AM: Update 35819: task mnli, batch 819 (35819): accuracy: 0.8607, mnli_loss: 0.3634
09/06 02:53:39 AM: Update 35838: task mnli, batch 838 (35838): accuracy: 0.8609, mnli_loss: 0.3631
09/06 02:53:49 AM: Update 35858: task mnli, batch 858 (35858): accuracy: 0.8616, mnli_loss: 0.3617
09/06 02:53:59 AM: Update 35877: task mnli, batch 877 (35877): accuracy: 0.8616, mnli_loss: 0.3616
09/06 02:54:10 AM: Update 35897: task mnli, batch 897 (35897): accuracy: 0.8622, mnli_loss: 0.3607
09/06 02:54:20 AM: Update 35916: task mnli, batch 916 (35916): accuracy: 0.8621, mnli_loss: 0.3608
09/06 02:54:31 AM: Update 35936: task mnli, batch 936 (35936): accuracy: 0.8624, mnli_loss: 0.3601
09/06 02:54:41 AM: Update 35956: task mnli, batch 956 (35956): accuracy: 0.8625, mnli_loss: 0.3592
09/06 02:54:51 AM: Update 35976: task mnli, batch 976 (35976): accuracy: 0.8633, mnli_loss: 0.3579
09/06 02:55:01 AM: Update 35996: task mnli, batch 996 (35996): accuracy: 0.8635, mnli_loss: 0.3568
09/06 02:55:03 AM: ***** Step 36000 / Validation 36 *****
09/06 02:55:03 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 02:55:03 AM: Validating...
09/06 02:55:11 AM: Evaluate: task mnli, batch 39 (209): accuracy: 0.8184, mnli_loss: 0.4903
09/06 02:55:21 AM: Evaluate: task mnli, batch 89 (209): accuracy: 0.8235, mnli_loss: 0.4828
09/06 02:55:31 AM: Evaluate: task mnli, batch 139 (209): accuracy: 0.8192, mnli_loss: 0.4981
09/06 02:55:41 AM: Evaluate: task mnli, batch 189 (209): accuracy: 0.8219, mnli_loss: 0.5000
09/06 02:55:45 AM: Best result seen so far for mnli.
09/06 02:55:45 AM: Best result seen so far for micro.
09/06 02:55:45 AM: Best result seen so far for macro.
09/06 02:55:45 AM: Updating LR scheduler:
09/06 02:55:45 AM: 	Best result seen so far for macro_avg: 0.819
09/06 02:55:45 AM: 	# validation passes without improvement: 0
09/06 02:55:45 AM: mnli_loss: training: 0.357145 validation: 0.506322
09/06 02:55:45 AM: macro_avg: validation: 0.819400
09/06 02:55:45 AM: micro_avg: validation: 0.819400
09/06 02:55:45 AM: mnli_accuracy: training: 0.863367 validation: 0.819400
09/06 02:55:45 AM: Global learning rate: 5e-06
09/06 02:55:45 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 02:55:52 AM: Update 36011: task mnli, batch 11 (36011): accuracy: 0.8674, mnli_loss: 0.3191
09/06 02:56:02 AM: Update 36031: task mnli, batch 31 (36031): accuracy: 0.8696, mnli_loss: 0.3310
09/06 02:56:13 AM: Update 36050: task mnli, batch 50 (36050): accuracy: 0.8575, mnli_loss: 0.3602
09/06 02:56:23 AM: Update 36068: task mnli, batch 68 (36068): accuracy: 0.8609, mnli_loss: 0.3596
09/06 02:56:33 AM: Update 36086: task mnli, batch 86 (36086): accuracy: 0.8551, mnli_loss: 0.3669
09/06 02:56:44 AM: Update 36100: task mnli, batch 100 (36100): accuracy: 0.8545, mnli_loss: 0.3672
09/06 02:56:54 AM: Update 36120: task mnli, batch 120 (36120): accuracy: 0.8569, mnli_loss: 0.3704
09/06 02:57:04 AM: Update 36139: task mnli, batch 139 (36139): accuracy: 0.8552, mnli_loss: 0.3666
09/06 02:57:15 AM: Update 36158: task mnli, batch 158 (36158): accuracy: 0.8586, mnli_loss: 0.3595
09/06 02:57:25 AM: Update 36176: task mnli, batch 176 (36176): accuracy: 0.8579, mnli_loss: 0.3607
09/06 02:57:35 AM: Update 36194: task mnli, batch 194 (36194): accuracy: 0.8589, mnli_loss: 0.3574
09/06 02:57:46 AM: Update 36214: task mnli, batch 214 (36214): accuracy: 0.8598, mnli_loss: 0.3576
09/06 02:57:56 AM: Update 36233: task mnli, batch 233 (36233): accuracy: 0.8601, mnli_loss: 0.3603
09/06 02:58:07 AM: Update 36254: task mnli, batch 254 (36254): accuracy: 0.8578, mnli_loss: 0.3662
09/06 02:58:17 AM: Update 36273: task mnli, batch 273 (36273): accuracy: 0.8580, mnli_loss: 0.3665
09/06 02:58:27 AM: Update 36292: task mnli, batch 292 (36292): accuracy: 0.8601, mnli_loss: 0.3631
09/06 02:58:38 AM: Update 36311: task mnli, batch 311 (36311): accuracy: 0.8600, mnli_loss: 0.3641
09/06 02:58:48 AM: Update 36330: task mnli, batch 330 (36330): accuracy: 0.8600, mnli_loss: 0.3628
09/06 02:58:58 AM: Update 36347: task mnli, batch 347 (36347): accuracy: 0.8591, mnli_loss: 0.3644
09/06 02:59:08 AM: Update 36367: task mnli, batch 367 (36367): accuracy: 0.8589, mnli_loss: 0.3668
09/06 02:59:19 AM: Update 36385: task mnli, batch 385 (36385): accuracy: 0.8586, mnli_loss: 0.3661
09/06 02:59:29 AM: Update 36404: task mnli, batch 404 (36404): accuracy: 0.8587, mnli_loss: 0.3652
09/06 02:59:39 AM: Update 36422: task mnli, batch 422 (36422): accuracy: 0.8584, mnli_loss: 0.3652
09/06 02:59:49 AM: Update 36442: task mnli, batch 442 (36442): accuracy: 0.8589, mnli_loss: 0.3641
09/06 03:00:00 AM: Update 36462: task mnli, batch 462 (36462): accuracy: 0.8591, mnli_loss: 0.3644
09/06 03:00:10 AM: Update 36481: task mnli, batch 481 (36481): accuracy: 0.8576, mnli_loss: 0.3671
09/06 03:00:20 AM: Update 36500: task mnli, batch 500 (36500): accuracy: 0.8571, mnli_loss: 0.3690
09/06 03:00:31 AM: Update 36515: task mnli, batch 515 (36515): accuracy: 0.8574, mnli_loss: 0.3680
09/06 03:00:41 AM: Update 36534: task mnli, batch 534 (36534): accuracy: 0.8580, mnli_loss: 0.3664
09/06 03:00:51 AM: Update 36554: task mnli, batch 554 (36554): accuracy: 0.8591, mnli_loss: 0.3643
09/06 03:01:02 AM: Update 36573: task mnli, batch 573 (36573): accuracy: 0.8592, mnli_loss: 0.3639
09/06 03:01:12 AM: Update 36589: task mnli, batch 589 (36589): accuracy: 0.8593, mnli_loss: 0.3636
09/06 03:01:22 AM: Update 36607: task mnli, batch 607 (36607): accuracy: 0.8580, mnli_loss: 0.3655
09/06 03:01:32 AM: Update 36627: task mnli, batch 627 (36627): accuracy: 0.8587, mnli_loss: 0.3631
09/06 03:01:42 AM: Update 36646: task mnli, batch 646 (36646): accuracy: 0.8584, mnli_loss: 0.3627
09/06 03:01:52 AM: Update 36665: task mnli, batch 665 (36665): accuracy: 0.8586, mnli_loss: 0.3621
09/06 03:02:03 AM: Update 36684: task mnli, batch 684 (36684): accuracy: 0.8591, mnli_loss: 0.3615
09/06 03:02:13 AM: Update 36703: task mnli, batch 703 (36703): accuracy: 0.8599, mnli_loss: 0.3597
09/06 03:02:23 AM: Update 36721: task mnli, batch 721 (36721): accuracy: 0.8604, mnli_loss: 0.3585
09/06 03:02:33 AM: Update 36741: task mnli, batch 741 (36741): accuracy: 0.8605, mnli_loss: 0.3596
09/06 03:02:43 AM: Update 36759: task mnli, batch 759 (36759): accuracy: 0.8603, mnli_loss: 0.3593
09/06 03:02:54 AM: Update 36777: task mnli, batch 777 (36777): accuracy: 0.8599, mnli_loss: 0.3600
09/06 03:03:04 AM: Update 36796: task mnli, batch 796 (36796): accuracy: 0.8604, mnli_loss: 0.3588
09/06 03:03:14 AM: Update 36816: task mnli, batch 816 (36816): accuracy: 0.8602, mnli_loss: 0.3593
09/06 03:03:24 AM: Update 36834: task mnli, batch 834 (36834): accuracy: 0.8604, mnli_loss: 0.3593
09/06 03:03:35 AM: Update 36853: task mnli, batch 853 (36853): accuracy: 0.8611, mnli_loss: 0.3586
09/06 03:03:46 AM: Update 36874: task mnli, batch 874 (36874): accuracy: 0.8617, mnli_loss: 0.3565
09/06 03:03:56 AM: Update 36893: task mnli, batch 893 (36893): accuracy: 0.8621, mnli_loss: 0.3555
09/06 03:04:06 AM: Update 36911: task mnli, batch 911 (36911): accuracy: 0.8621, mnli_loss: 0.3558
09/06 03:04:16 AM: Update 36925: task mnli, batch 925 (36925): accuracy: 0.8621, mnli_loss: 0.3559
09/06 03:04:27 AM: Update 36943: task mnli, batch 943 (36943): accuracy: 0.8620, mnli_loss: 0.3562
09/06 03:04:37 AM: Update 36962: task mnli, batch 962 (36962): accuracy: 0.8622, mnli_loss: 0.3560
09/06 03:04:48 AM: Update 36982: task mnli, batch 982 (36982): accuracy: 0.8626, mnli_loss: 0.3546
09/06 03:04:58 AM: ***** Step 37000 / Validation 37 *****
09/06 03:04:58 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:04:58 AM: Validating...
09/06 03:04:58 AM: Evaluate: task mnli, batch 1 (209): accuracy: 0.8750, mnli_loss: 0.2832
09/06 03:05:08 AM: Evaluate: task mnli, batch 52 (209): accuracy: 0.8213, mnli_loss: 0.4727
09/06 03:05:18 AM: Evaluate: task mnli, batch 102 (209): accuracy: 0.8203, mnli_loss: 0.4790
09/06 03:05:29 AM: Evaluate: task mnli, batch 152 (209): accuracy: 0.8191, mnli_loss: 0.4964
09/06 03:05:39 AM: Evaluate: task mnli, batch 202 (209): accuracy: 0.8201, mnli_loss: 0.4933
09/06 03:05:40 AM: Updating LR scheduler:
09/06 03:05:40 AM: 	Best result seen so far for macro_avg: 0.819
09/06 03:05:40 AM: 	# validation passes without improvement: 1
09/06 03:05:40 AM: mnli_loss: training: 0.353679 validation: 0.501690
09/06 03:05:40 AM: macro_avg: validation: 0.817400
09/06 03:05:40 AM: micro_avg: validation: 0.817400
09/06 03:05:40 AM: mnli_accuracy: training: 0.863030 validation: 0.817400
09/06 03:05:40 AM: Global learning rate: 5e-06
09/06 03:05:40 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:05:49 AM: Update 37014: task mnli, batch 14 (37014): accuracy: 0.8750, mnli_loss: 0.3127
09/06 03:05:59 AM: Update 37033: task mnli, batch 33 (37033): accuracy: 0.8902, mnli_loss: 0.2899
09/06 03:06:10 AM: Update 37053: task mnli, batch 53 (37053): accuracy: 0.8829, mnli_loss: 0.3076
09/06 03:06:21 AM: Update 37072: task mnli, batch 72 (37072): accuracy: 0.8872, mnli_loss: 0.2997
09/06 03:06:31 AM: Update 37091: task mnli, batch 91 (37091): accuracy: 0.8855, mnli_loss: 0.3082
09/06 03:06:41 AM: Update 37109: task mnli, batch 109 (37109): accuracy: 0.8804, mnli_loss: 0.3208
09/06 03:06:52 AM: Update 37128: task mnli, batch 128 (37128): accuracy: 0.8789, mnli_loss: 0.3248
09/06 03:07:02 AM: Update 37147: task mnli, batch 147 (37147): accuracy: 0.8756, mnli_loss: 0.3314
09/06 03:07:12 AM: Update 37165: task mnli, batch 165 (37165): accuracy: 0.8758, mnli_loss: 0.3349
09/06 03:07:23 AM: Update 37183: task mnli, batch 183 (37183): accuracy: 0.8723, mnli_loss: 0.3409
09/06 03:07:33 AM: Update 37202: task mnli, batch 202 (37202): accuracy: 0.8725, mnli_loss: 0.3400
09/06 03:07:43 AM: Update 37221: task mnli, batch 221 (37221): accuracy: 0.8710, mnli_loss: 0.3426
09/06 03:07:53 AM: Update 37241: task mnli, batch 241 (37241): accuracy: 0.8726, mnli_loss: 0.3378
09/06 03:08:03 AM: Update 37260: task mnli, batch 260 (37260): accuracy: 0.8734, mnli_loss: 0.3362
09/06 03:08:14 AM: Update 37282: task mnli, batch 282 (37282): accuracy: 0.8749, mnli_loss: 0.3362
09/06 03:08:24 AM: Update 37301: task mnli, batch 301 (37301): accuracy: 0.8761, mnli_loss: 0.3341
09/06 03:08:34 AM: Update 37320: task mnli, batch 320 (37320): accuracy: 0.8762, mnli_loss: 0.3363
09/06 03:08:44 AM: Update 37338: task mnli, batch 338 (37338): accuracy: 0.8766, mnli_loss: 0.3359
09/06 03:08:55 AM: Update 37351: task mnli, batch 351 (37351): accuracy: 0.8760, mnli_loss: 0.3365
09/06 03:09:05 AM: Update 37369: task mnli, batch 369 (37369): accuracy: 0.8752, mnli_loss: 0.3388
09/06 03:09:15 AM: Update 37388: task mnli, batch 388 (37388): accuracy: 0.8758, mnli_loss: 0.3386
09/06 03:09:25 AM: Update 37406: task mnli, batch 406 (37406): accuracy: 0.8759, mnli_loss: 0.3400
09/06 03:09:35 AM: Update 37425: task mnli, batch 425 (37425): accuracy: 0.8754, mnli_loss: 0.3404
09/06 03:09:46 AM: Update 37444: task mnli, batch 444 (37444): accuracy: 0.8748, mnli_loss: 0.3401
09/06 03:09:56 AM: Update 37461: task mnli, batch 461 (37461): accuracy: 0.8747, mnli_loss: 0.3401
09/06 03:10:07 AM: Update 37480: task mnli, batch 480 (37480): accuracy: 0.8733, mnli_loss: 0.3427
09/06 03:10:17 AM: Update 37500: task mnli, batch 500 (37500): accuracy: 0.8739, mnli_loss: 0.3410
09/06 03:10:27 AM: Update 37520: task mnli, batch 520 (37520): accuracy: 0.8743, mnli_loss: 0.3391
09/06 03:10:38 AM: Update 37540: task mnli, batch 540 (37540): accuracy: 0.8745, mnli_loss: 0.3374
09/06 03:10:48 AM: Update 37559: task mnli, batch 559 (37559): accuracy: 0.8746, mnli_loss: 0.3382
09/06 03:10:58 AM: Update 37577: task mnli, batch 577 (37577): accuracy: 0.8738, mnli_loss: 0.3388
09/06 03:11:08 AM: Update 37596: task mnli, batch 596 (37596): accuracy: 0.8727, mnli_loss: 0.3419
09/06 03:11:19 AM: Update 37614: task mnli, batch 614 (37614): accuracy: 0.8728, mnli_loss: 0.3421
09/06 03:11:29 AM: Update 37632: task mnli, batch 632 (37632): accuracy: 0.8722, mnli_loss: 0.3431
09/06 03:11:39 AM: Update 37649: task mnli, batch 649 (37649): accuracy: 0.8714, mnli_loss: 0.3435
09/06 03:11:49 AM: Update 37668: task mnli, batch 668 (37668): accuracy: 0.8711, mnli_loss: 0.3434
09/06 03:12:00 AM: Update 37690: task mnli, batch 690 (37690): accuracy: 0.8713, mnli_loss: 0.3435
09/06 03:12:10 AM: Update 37709: task mnli, batch 709 (37709): accuracy: 0.8714, mnli_loss: 0.3430
09/06 03:12:20 AM: Update 37727: task mnli, batch 727 (37727): accuracy: 0.8718, mnli_loss: 0.3414
09/06 03:12:30 AM: Update 37748: task mnli, batch 748 (37748): accuracy: 0.8717, mnli_loss: 0.3405
09/06 03:12:41 AM: Update 37762: task mnli, batch 762 (37762): accuracy: 0.8716, mnli_loss: 0.3400
09/06 03:12:51 AM: Update 37782: task mnli, batch 782 (37782): accuracy: 0.8722, mnli_loss: 0.3389
09/06 03:13:02 AM: Update 37801: task mnli, batch 801 (37801): accuracy: 0.8721, mnli_loss: 0.3393
09/06 03:13:12 AM: Update 37819: task mnli, batch 819 (37819): accuracy: 0.8719, mnli_loss: 0.3396
09/06 03:13:22 AM: Update 37837: task mnli, batch 837 (37837): accuracy: 0.8721, mnli_loss: 0.3394
09/06 03:13:32 AM: Update 37856: task mnli, batch 856 (37856): accuracy: 0.8720, mnli_loss: 0.3402
09/06 03:13:43 AM: Update 37876: task mnli, batch 876 (37876): accuracy: 0.8716, mnli_loss: 0.3407
09/06 03:13:53 AM: Update 37893: task mnli, batch 893 (37893): accuracy: 0.8710, mnli_loss: 0.3426
09/06 03:14:04 AM: Update 37913: task mnli, batch 913 (37913): accuracy: 0.8713, mnli_loss: 0.3420
09/06 03:14:14 AM: Update 37932: task mnli, batch 932 (37932): accuracy: 0.8720, mnli_loss: 0.3404
09/06 03:14:24 AM: Update 37952: task mnli, batch 952 (37952): accuracy: 0.8718, mnli_loss: 0.3409
09/06 03:14:34 AM: Update 37973: task mnli, batch 973 (37973): accuracy: 0.8723, mnli_loss: 0.3394
09/06 03:14:45 AM: Update 37992: task mnli, batch 992 (37992): accuracy: 0.8728, mnli_loss: 0.3384
09/06 03:14:49 AM: ***** Step 38000 / Validation 38 *****
09/06 03:14:49 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:14:49 AM: Validating...
09/06 03:14:55 AM: Evaluate: task mnli, batch 28 (209): accuracy: 0.8259, mnli_loss: 0.4790
09/06 03:15:05 AM: Evaluate: task mnli, batch 78 (209): accuracy: 0.8237, mnli_loss: 0.4783
09/06 03:15:15 AM: Evaluate: task mnli, batch 128 (209): accuracy: 0.8180, mnli_loss: 0.4933
09/06 03:15:25 AM: Evaluate: task mnli, batch 178 (209): accuracy: 0.8230, mnli_loss: 0.4912
09/06 03:15:31 AM: Updating LR scheduler:
09/06 03:15:31 AM: 	Best result seen so far for macro_avg: 0.819
09/06 03:15:31 AM: 	# validation passes without improvement: 2
09/06 03:15:31 AM: mnli_loss: training: 0.338856 validation: 0.502690
09/06 03:15:31 AM: macro_avg: validation: 0.818000
09/06 03:15:31 AM: micro_avg: validation: 0.818000
09/06 03:15:31 AM: mnli_accuracy: training: 0.872582 validation: 0.818000
09/06 03:15:31 AM: Global learning rate: 5e-06
09/06 03:15:31 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:15:36 AM: Update 38006: task mnli, batch 6 (38006): accuracy: 0.9028, mnli_loss: 0.3360
09/06 03:15:46 AM: Update 38026: task mnli, batch 26 (38026): accuracy: 0.8814, mnli_loss: 0.3357
09/06 03:15:56 AM: Update 38045: task mnli, batch 45 (38045): accuracy: 0.8917, mnli_loss: 0.3047
09/06 03:16:06 AM: Update 38064: task mnli, batch 64 (38064): accuracy: 0.8874, mnli_loss: 0.3064
09/06 03:16:16 AM: Update 38082: task mnli, batch 82 (38082): accuracy: 0.8918, mnli_loss: 0.2935
09/06 03:16:26 AM: Update 38101: task mnli, batch 101 (38101): accuracy: 0.8824, mnli_loss: 0.3157
09/06 03:16:37 AM: Update 38120: task mnli, batch 120 (38120): accuracy: 0.8781, mnli_loss: 0.3240
09/06 03:16:47 AM: Update 38138: task mnli, batch 138 (38138): accuracy: 0.8801, mnli_loss: 0.3208
09/06 03:16:58 AM: Update 38156: task mnli, batch 156 (38156): accuracy: 0.8777, mnli_loss: 0.3248
09/06 03:17:11 AM: Update 38174: task mnli, batch 174 (38174): accuracy: 0.8779, mnli_loss: 0.3264
09/06 03:17:21 AM: Update 38192: task mnli, batch 192 (38192): accuracy: 0.8778, mnli_loss: 0.3285
09/06 03:17:31 AM: Update 38211: task mnli, batch 211 (38211): accuracy: 0.8778, mnli_loss: 0.3265
09/06 03:17:41 AM: Update 38229: task mnli, batch 229 (38229): accuracy: 0.8794, mnli_loss: 0.3233
09/06 03:17:51 AM: Update 38248: task mnli, batch 248 (38248): accuracy: 0.8784, mnli_loss: 0.3246
09/06 03:18:01 AM: Update 38266: task mnli, batch 266 (38266): accuracy: 0.8780, mnli_loss: 0.3249
09/06 03:18:12 AM: Update 38286: task mnli, batch 286 (38286): accuracy: 0.8786, mnli_loss: 0.3244
09/06 03:18:22 AM: Update 38306: task mnli, batch 306 (38306): accuracy: 0.8791, mnli_loss: 0.3233
09/06 03:18:32 AM: Update 38325: task mnli, batch 325 (38325): accuracy: 0.8777, mnli_loss: 0.3259
09/06 03:18:42 AM: Update 38344: task mnli, batch 344 (38344): accuracy: 0.8777, mnli_loss: 0.3245
09/06 03:18:53 AM: Update 38363: task mnli, batch 363 (38363): accuracy: 0.8775, mnli_loss: 0.3257
09/06 03:19:03 AM: Update 38382: task mnli, batch 382 (38382): accuracy: 0.8773, mnli_loss: 0.3254
09/06 03:19:13 AM: Update 38400: task mnli, batch 400 (38400): accuracy: 0.8768, mnli_loss: 0.3260
09/06 03:19:24 AM: Update 38420: task mnli, batch 420 (38420): accuracy: 0.8782, mnli_loss: 0.3240
09/06 03:19:34 AM: Update 38440: task mnli, batch 440 (38440): accuracy: 0.8783, mnli_loss: 0.3236
09/06 03:19:44 AM: Update 38460: task mnli, batch 460 (38460): accuracy: 0.8788, mnli_loss: 0.3217
09/06 03:19:54 AM: Update 38479: task mnli, batch 479 (38479): accuracy: 0.8799, mnli_loss: 0.3205
09/06 03:20:05 AM: Update 38498: task mnli, batch 498 (38498): accuracy: 0.8801, mnli_loss: 0.3197
09/06 03:20:15 AM: Update 38515: task mnli, batch 515 (38515): accuracy: 0.8801, mnli_loss: 0.3207
09/06 03:20:25 AM: Update 38534: task mnli, batch 534 (38534): accuracy: 0.8799, mnli_loss: 0.3199
09/06 03:20:35 AM: Update 38551: task mnli, batch 551 (38551): accuracy: 0.8795, mnli_loss: 0.3200
09/06 03:20:46 AM: Update 38570: task mnli, batch 570 (38570): accuracy: 0.8800, mnli_loss: 0.3189
09/06 03:20:56 AM: Update 38588: task mnli, batch 588 (38588): accuracy: 0.8805, mnli_loss: 0.3190
09/06 03:21:07 AM: Update 38602: task mnli, batch 602 (38602): accuracy: 0.8805, mnli_loss: 0.3190
09/06 03:21:17 AM: Update 38621: task mnli, batch 621 (38621): accuracy: 0.8806, mnli_loss: 0.3184
09/06 03:21:28 AM: Update 38640: task mnli, batch 640 (38640): accuracy: 0.8801, mnli_loss: 0.3194
09/06 03:21:38 AM: Update 38659: task mnli, batch 659 (38659): accuracy: 0.8809, mnli_loss: 0.3189
09/06 03:21:48 AM: Update 38678: task mnli, batch 678 (38678): accuracy: 0.8807, mnli_loss: 0.3195
09/06 03:21:58 AM: Update 38696: task mnli, batch 696 (38696): accuracy: 0.8812, mnli_loss: 0.3197
09/06 03:22:08 AM: Update 38714: task mnli, batch 714 (38714): accuracy: 0.8807, mnli_loss: 0.3195
09/06 03:22:18 AM: Update 38733: task mnli, batch 733 (38733): accuracy: 0.8803, mnli_loss: 0.3192
09/06 03:22:29 AM: Update 38753: task mnli, batch 753 (38753): accuracy: 0.8806, mnli_loss: 0.3189
09/06 03:22:40 AM: Update 38772: task mnli, batch 772 (38772): accuracy: 0.8806, mnli_loss: 0.3196
09/06 03:22:50 AM: Update 38793: task mnli, batch 793 (38793): accuracy: 0.8813, mnli_loss: 0.3182
09/06 03:23:00 AM: Update 38812: task mnli, batch 812 (38812): accuracy: 0.8815, mnli_loss: 0.3179
09/06 03:23:10 AM: Update 38831: task mnli, batch 831 (38831): accuracy: 0.8811, mnli_loss: 0.3187
09/06 03:23:21 AM: Update 38850: task mnli, batch 850 (38850): accuracy: 0.8812, mnli_loss: 0.3182
09/06 03:23:31 AM: Update 38870: task mnli, batch 870 (38870): accuracy: 0.8819, mnli_loss: 0.3168
09/06 03:23:42 AM: Update 38890: task mnli, batch 890 (38890): accuracy: 0.8824, mnli_loss: 0.3161
09/06 03:23:52 AM: Update 38909: task mnli, batch 909 (38909): accuracy: 0.8826, mnli_loss: 0.3152
09/06 03:24:02 AM: Update 38928: task mnli, batch 928 (38928): accuracy: 0.8826, mnli_loss: 0.3156
09/06 03:24:12 AM: Update 38947: task mnli, batch 947 (38947): accuracy: 0.8824, mnli_loss: 0.3161
09/06 03:24:23 AM: Update 38966: task mnli, batch 966 (38966): accuracy: 0.8825, mnli_loss: 0.3158
09/06 03:24:33 AM: Update 38985: task mnli, batch 985 (38985): accuracy: 0.8825, mnli_loss: 0.3157
09/06 03:24:41 AM: ***** Step 39000 / Validation 39 *****
09/06 03:24:41 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:24:41 AM: Validating...
09/06 03:24:43 AM: Evaluate: task mnli, batch 9 (209): accuracy: 0.8194, mnli_loss: 0.5301
09/06 03:24:53 AM: Evaluate: task mnli, batch 59 (209): accuracy: 0.8150, mnli_loss: 0.5061
09/06 03:25:03 AM: Evaluate: task mnli, batch 109 (209): accuracy: 0.8169, mnli_loss: 0.5052
09/06 03:25:13 AM: Evaluate: task mnli, batch 159 (209): accuracy: 0.8184, mnli_loss: 0.5086
09/06 03:25:23 AM: Evaluate: task mnli, batch 209 (209): accuracy: 0.8146, mnli_loss: 0.5245
09/06 03:25:23 AM: Updating LR scheduler:
09/06 03:25:23 AM: 	Best result seen so far for macro_avg: 0.819
09/06 03:25:23 AM: 	# validation passes without improvement: 3
09/06 03:25:23 AM: mnli_loss: training: 0.315401 validation: 0.524509
09/06 03:25:23 AM: macro_avg: validation: 0.814600
09/06 03:25:23 AM: micro_avg: validation: 0.814600
09/06 03:25:23 AM: mnli_accuracy: training: 0.882713 validation: 0.814600
09/06 03:25:23 AM: Global learning rate: 5e-06
09/06 03:25:23 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:25:34 AM: Update 39012: task mnli, batch 12 (39012): accuracy: 0.9000, mnli_loss: 0.3171
09/06 03:25:44 AM: Update 39030: task mnli, batch 30 (39030): accuracy: 0.8834, mnli_loss: 0.3478
09/06 03:25:54 AM: Update 39049: task mnli, batch 49 (39049): accuracy: 0.8844, mnli_loss: 0.3350
09/06 03:26:05 AM: Update 39068: task mnli, batch 68 (39068): accuracy: 0.8812, mnli_loss: 0.3358
09/06 03:26:15 AM: Update 39085: task mnli, batch 85 (39085): accuracy: 0.8819, mnli_loss: 0.3273
09/06 03:26:25 AM: Update 39103: task mnli, batch 103 (39103): accuracy: 0.8803, mnli_loss: 0.3283
09/06 03:26:36 AM: Update 39122: task mnli, batch 122 (39122): accuracy: 0.8829, mnli_loss: 0.3230
09/06 03:26:46 AM: Update 39140: task mnli, batch 140 (39140): accuracy: 0.8828, mnli_loss: 0.3252
09/06 03:26:56 AM: Update 39159: task mnli, batch 159 (39159): accuracy: 0.8808, mnli_loss: 0.3280
09/06 03:27:07 AM: Update 39178: task mnli, batch 178 (39178): accuracy: 0.8790, mnli_loss: 0.3337
09/06 03:27:17 AM: Update 39197: task mnli, batch 197 (39197): accuracy: 0.8803, mnli_loss: 0.3320
09/06 03:27:27 AM: Update 39215: task mnli, batch 215 (39215): accuracy: 0.8802, mnli_loss: 0.3306
09/06 03:27:38 AM: Update 39235: task mnli, batch 235 (39235): accuracy: 0.8789, mnli_loss: 0.3318
09/06 03:27:48 AM: Update 39255: task mnli, batch 255 (39255): accuracy: 0.8806, mnli_loss: 0.3324
09/06 03:27:58 AM: Update 39273: task mnli, batch 273 (39273): accuracy: 0.8814, mnli_loss: 0.3288
09/06 03:28:09 AM: Update 39291: task mnli, batch 291 (39291): accuracy: 0.8823, mnli_loss: 0.3281
09/06 03:28:19 AM: Update 39312: task mnli, batch 312 (39312): accuracy: 0.8838, mnli_loss: 0.3257
09/06 03:28:30 AM: Update 39332: task mnli, batch 332 (39332): accuracy: 0.8843, mnli_loss: 0.3257
09/06 03:28:40 AM: Update 39352: task mnli, batch 352 (39352): accuracy: 0.8836, mnli_loss: 0.3261
09/06 03:28:50 AM: Update 39371: task mnli, batch 371 (39371): accuracy: 0.8830, mnli_loss: 0.3271
09/06 03:29:00 AM: Update 39390: task mnli, batch 390 (39390): accuracy: 0.8824, mnli_loss: 0.3286
09/06 03:29:11 AM: Update 39409: task mnli, batch 409 (39409): accuracy: 0.8820, mnli_loss: 0.3300
09/06 03:29:22 AM: Update 39425: task mnli, batch 425 (39425): accuracy: 0.8823, mnli_loss: 0.3306
09/06 03:29:32 AM: Update 39442: task mnli, batch 442 (39442): accuracy: 0.8799, mnli_loss: 0.3361
09/06 03:29:43 AM: Update 39462: task mnli, batch 462 (39462): accuracy: 0.8805, mnli_loss: 0.3329
09/06 03:29:53 AM: Update 39481: task mnli, batch 481 (39481): accuracy: 0.8807, mnli_loss: 0.3317
09/06 03:30:03 AM: Update 39499: task mnli, batch 499 (39499): accuracy: 0.8811, mnli_loss: 0.3309
09/06 03:30:14 AM: Update 39517: task mnli, batch 517 (39517): accuracy: 0.8815, mnli_loss: 0.3301
09/06 03:30:24 AM: Update 39535: task mnli, batch 535 (39535): accuracy: 0.8810, mnli_loss: 0.3295
09/06 03:30:34 AM: Update 39554: task mnli, batch 554 (39554): accuracy: 0.8813, mnli_loss: 0.3278
09/06 03:30:45 AM: Update 39572: task mnli, batch 572 (39572): accuracy: 0.8808, mnli_loss: 0.3289
09/06 03:30:55 AM: Update 39590: task mnli, batch 590 (39590): accuracy: 0.8809, mnli_loss: 0.3283
09/06 03:31:05 AM: Update 39610: task mnli, batch 610 (39610): accuracy: 0.8801, mnli_loss: 0.3282
09/06 03:31:15 AM: Update 39630: task mnli, batch 630 (39630): accuracy: 0.8811, mnli_loss: 0.3264
09/06 03:31:26 AM: Update 39648: task mnli, batch 648 (39648): accuracy: 0.8811, mnli_loss: 0.3256
09/06 03:31:36 AM: Update 39667: task mnli, batch 667 (39667): accuracy: 0.8807, mnli_loss: 0.3254
09/06 03:31:46 AM: Update 39686: task mnli, batch 686 (39686): accuracy: 0.8807, mnli_loss: 0.3243
09/06 03:31:56 AM: Update 39705: task mnli, batch 705 (39705): accuracy: 0.8814, mnli_loss: 0.3225
09/06 03:32:07 AM: Update 39724: task mnli, batch 724 (39724): accuracy: 0.8820, mnli_loss: 0.3211
09/06 03:32:17 AM: Update 39743: task mnli, batch 743 (39743): accuracy: 0.8820, mnli_loss: 0.3210
09/06 03:32:27 AM: Update 39762: task mnli, batch 762 (39762): accuracy: 0.8827, mnli_loss: 0.3193
09/06 03:32:37 AM: Update 39781: task mnli, batch 781 (39781): accuracy: 0.8831, mnli_loss: 0.3188
09/06 03:32:47 AM: Update 39800: task mnli, batch 800 (39800): accuracy: 0.8835, mnli_loss: 0.3175
09/06 03:32:58 AM: Update 39819: task mnli, batch 819 (39819): accuracy: 0.8832, mnli_loss: 0.3184
09/06 03:33:08 AM: Update 39839: task mnli, batch 839 (39839): accuracy: 0.8828, mnli_loss: 0.3187
09/06 03:33:18 AM: Update 39853: task mnli, batch 853 (39853): accuracy: 0.8829, mnli_loss: 0.3184
09/06 03:33:29 AM: Update 39871: task mnli, batch 871 (39871): accuracy: 0.8829, mnli_loss: 0.3188
09/06 03:33:39 AM: Update 39890: task mnli, batch 890 (39890): accuracy: 0.8831, mnli_loss: 0.3186
09/06 03:33:50 AM: Update 39909: task mnli, batch 909 (39909): accuracy: 0.8834, mnli_loss: 0.3173
09/06 03:34:00 AM: Update 39929: task mnli, batch 929 (39929): accuracy: 0.8834, mnli_loss: 0.3172
09/06 03:34:10 AM: Update 39948: task mnli, batch 948 (39948): accuracy: 0.8837, mnli_loss: 0.3168
09/06 03:34:20 AM: Update 39966: task mnli, batch 966 (39966): accuracy: 0.8837, mnli_loss: 0.3166
09/06 03:34:31 AM: Update 39984: task mnli, batch 984 (39984): accuracy: 0.8839, mnli_loss: 0.3172
09/06 03:34:40 AM: ***** Step 40000 / Validation 40 *****
09/06 03:34:40 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:34:40 AM: Validating...
09/06 03:34:41 AM: Evaluate: task mnli, batch 6 (209): accuracy: 0.8125, mnli_loss: 0.5068
09/06 03:34:51 AM: Evaluate: task mnli, batch 57 (209): accuracy: 0.8246, mnli_loss: 0.5112
09/06 03:35:01 AM: Evaluate: task mnli, batch 107 (209): accuracy: 0.8217, mnli_loss: 0.5193
09/06 03:35:11 AM: Evaluate: task mnli, batch 157 (209): accuracy: 0.8225, mnli_loss: 0.5240
09/06 03:35:21 AM: Evaluate: task mnli, batch 207 (209): accuracy: 0.8184, mnli_loss: 0.5327
09/06 03:35:22 AM: Updating LR scheduler:
09/06 03:35:22 AM: 	Best result seen so far for macro_avg: 0.819
09/06 03:35:22 AM: 	# validation passes without improvement: 4
09/06 03:35:22 AM: mnli_loss: training: 0.316605 validation: 0.537919
09/06 03:35:22 AM: macro_avg: validation: 0.817800
09/06 03:35:22 AM: micro_avg: validation: 0.817800
09/06 03:35:22 AM: mnli_accuracy: training: 0.884134 validation: 0.817800
09/06 03:35:22 AM: Global learning rate: 5e-06
09/06 03:35:22 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:35:32 AM: Update 40016: task mnli, batch 16 (40016): accuracy: 0.8698, mnli_loss: 0.3807
09/06 03:35:42 AM: Update 40034: task mnli, batch 34 (40034): accuracy: 0.8676, mnli_loss: 0.3885
09/06 03:35:52 AM: Update 40054: task mnli, batch 54 (40054): accuracy: 0.8866, mnli_loss: 0.3341
09/06 03:36:02 AM: Update 40072: task mnli, batch 72 (40072): accuracy: 0.8814, mnli_loss: 0.3376
09/06 03:36:12 AM: Update 40091: task mnli, batch 91 (40091): accuracy: 0.8823, mnli_loss: 0.3264
09/06 03:36:22 AM: Update 40110: task mnli, batch 110 (40110): accuracy: 0.8871, mnli_loss: 0.3184
09/06 03:36:33 AM: Update 40128: task mnli, batch 128 (40128): accuracy: 0.8890, mnli_loss: 0.3125
09/06 03:36:43 AM: Update 40147: task mnli, batch 147 (40147): accuracy: 0.8883, mnli_loss: 0.3111
09/06 03:36:53 AM: Update 40166: task mnli, batch 166 (40166): accuracy: 0.8873, mnli_loss: 0.3100
09/06 03:37:03 AM: Update 40185: task mnli, batch 185 (40185): accuracy: 0.8863, mnli_loss: 0.3110
09/06 03:37:13 AM: Update 40204: task mnli, batch 204 (40204): accuracy: 0.8846, mnli_loss: 0.3157
09/06 03:37:23 AM: Update 40224: task mnli, batch 224 (40224): accuracy: 0.8834, mnli_loss: 0.3147
09/06 03:37:34 AM: Update 40243: task mnli, batch 243 (40243): accuracy: 0.8822, mnli_loss: 0.3172
09/06 03:37:44 AM: Update 40259: task mnli, batch 259 (40259): accuracy: 0.8811, mnli_loss: 0.3187
09/06 03:37:55 AM: Update 40277: task mnli, batch 277 (40277): accuracy: 0.8804, mnli_loss: 0.3178
09/06 03:38:05 AM: Update 40295: task mnli, batch 295 (40295): accuracy: 0.8815, mnli_loss: 0.3179
09/06 03:38:15 AM: Update 40314: task mnli, batch 314 (40314): accuracy: 0.8804, mnli_loss: 0.3178
09/06 03:38:26 AM: Update 40333: task mnli, batch 333 (40333): accuracy: 0.8816, mnli_loss: 0.3145
09/06 03:38:36 AM: Update 40352: task mnli, batch 352 (40352): accuracy: 0.8819, mnli_loss: 0.3141
09/06 03:38:47 AM: Update 40370: task mnli, batch 370 (40370): accuracy: 0.8810, mnli_loss: 0.3145
09/06 03:38:57 AM: Update 40391: task mnli, batch 391 (40391): accuracy: 0.8811, mnli_loss: 0.3141
09/06 03:39:08 AM: Update 40410: task mnli, batch 410 (40410): accuracy: 0.8815, mnli_loss: 0.3144
09/06 03:39:18 AM: Update 40428: task mnli, batch 428 (40428): accuracy: 0.8818, mnli_loss: 0.3144
09/06 03:39:28 AM: Update 40447: task mnli, batch 447 (40447): accuracy: 0.8827, mnli_loss: 0.3137
09/06 03:39:39 AM: Update 40467: task mnli, batch 467 (40467): accuracy: 0.8831, mnli_loss: 0.3132
09/06 03:39:49 AM: Update 40487: task mnli, batch 487 (40487): accuracy: 0.8837, mnli_loss: 0.3122
09/06 03:39:59 AM: Update 40506: task mnli, batch 506 (40506): accuracy: 0.8838, mnli_loss: 0.3111
09/06 03:40:09 AM: Update 40525: task mnli, batch 525 (40525): accuracy: 0.8838, mnli_loss: 0.3105
09/06 03:40:19 AM: Update 40543: task mnli, batch 543 (40543): accuracy: 0.8837, mnli_loss: 0.3109
09/06 03:40:30 AM: Update 40562: task mnli, batch 562 (40562): accuracy: 0.8837, mnli_loss: 0.3121
09/06 03:40:40 AM: Update 40581: task mnli, batch 581 (40581): accuracy: 0.8838, mnli_loss: 0.3119
09/06 03:40:51 AM: Update 40600: task mnli, batch 600 (40600): accuracy: 0.8839, mnli_loss: 0.3113
09/06 03:41:01 AM: Update 40620: task mnli, batch 620 (40620): accuracy: 0.8838, mnli_loss: 0.3117
09/06 03:41:11 AM: Update 40640: task mnli, batch 640 (40640): accuracy: 0.8846, mnli_loss: 0.3096
09/06 03:41:21 AM: Update 40659: task mnli, batch 659 (40659): accuracy: 0.8844, mnli_loss: 0.3104
09/06 03:41:33 AM: Update 40676: task mnli, batch 676 (40676): accuracy: 0.8839, mnli_loss: 0.3113
09/06 03:41:43 AM: Update 40695: task mnli, batch 695 (40695): accuracy: 0.8836, mnli_loss: 0.3118
09/06 03:41:53 AM: Update 40713: task mnli, batch 713 (40713): accuracy: 0.8836, mnli_loss: 0.3125
09/06 03:42:04 AM: Update 40734: task mnli, batch 734 (40734): accuracy: 0.8835, mnli_loss: 0.3130
09/06 03:42:14 AM: Update 40754: task mnli, batch 754 (40754): accuracy: 0.8834, mnli_loss: 0.3136
09/06 03:42:24 AM: Update 40772: task mnli, batch 772 (40772): accuracy: 0.8827, mnli_loss: 0.3152
09/06 03:42:34 AM: Update 40790: task mnli, batch 790 (40790): accuracy: 0.8825, mnli_loss: 0.3153
09/06 03:42:45 AM: Update 40809: task mnli, batch 809 (40809): accuracy: 0.8820, mnli_loss: 0.3167
09/06 03:42:55 AM: Update 40828: task mnli, batch 828 (40828): accuracy: 0.8814, mnli_loss: 0.3183
09/06 03:43:05 AM: Update 40847: task mnli, batch 847 (40847): accuracy: 0.8815, mnli_loss: 0.3174
09/06 03:43:16 AM: Update 40865: task mnli, batch 865 (40865): accuracy: 0.8810, mnli_loss: 0.3175
09/06 03:43:26 AM: Update 40883: task mnli, batch 883 (40883): accuracy: 0.8810, mnli_loss: 0.3172
09/06 03:43:36 AM: Update 40902: task mnli, batch 902 (40902): accuracy: 0.8814, mnli_loss: 0.3168
09/06 03:43:46 AM: Update 40920: task mnli, batch 920 (40920): accuracy: 0.8815, mnli_loss: 0.3167
09/06 03:43:56 AM: Update 40940: task mnli, batch 940 (40940): accuracy: 0.8817, mnli_loss: 0.3166
09/06 03:44:06 AM: Update 40958: task mnli, batch 958 (40958): accuracy: 0.8818, mnli_loss: 0.3171
09/06 03:44:17 AM: Update 40977: task mnli, batch 977 (40977): accuracy: 0.8820, mnli_loss: 0.3170
09/06 03:44:27 AM: Update 40996: task mnli, batch 996 (40996): accuracy: 0.8821, mnli_loss: 0.3171
09/06 03:44:29 AM: ***** Step 41000 / Validation 41 *****
09/06 03:44:29 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:44:29 AM: Validating...
09/06 03:44:37 AM: Evaluate: task mnli, batch 39 (209): accuracy: 0.8280, mnli_loss: 0.4973
09/06 03:44:47 AM: Evaluate: task mnli, batch 89 (209): accuracy: 0.8254, mnli_loss: 0.4970
09/06 03:44:57 AM: Evaluate: task mnli, batch 139 (209): accuracy: 0.8225, mnli_loss: 0.5094
09/06 03:45:07 AM: Evaluate: task mnli, batch 189 (209): accuracy: 0.8236, mnli_loss: 0.5140
09/06 03:45:11 AM: Best result seen so far for mnli.
09/06 03:45:11 AM: Best result seen so far for micro.
09/06 03:45:11 AM: Best result seen so far for macro.
09/06 03:45:11 AM: Updating LR scheduler:
09/06 03:45:11 AM: 	Best result seen so far for macro_avg: 0.820
09/06 03:45:11 AM: 	# validation passes without improvement: 0
09/06 03:45:11 AM: mnli_loss: training: 0.316877 validation: 0.523548
09/06 03:45:11 AM: macro_avg: validation: 0.820400
09/06 03:45:11 AM: micro_avg: validation: 0.820400
09/06 03:45:11 AM: mnli_accuracy: training: 0.882130 validation: 0.820400
09/06 03:45:11 AM: Global learning rate: 5e-06
09/06 03:45:11 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:45:17 AM: Update 41010: task mnli, batch 10 (41010): accuracy: 0.9000, mnli_loss: 0.2652
09/06 03:45:28 AM: Update 41029: task mnli, batch 29 (41029): accuracy: 0.8836, mnli_loss: 0.2945
09/06 03:45:38 AM: Update 41047: task mnli, batch 47 (41047): accuracy: 0.8945, mnli_loss: 0.2835
09/06 03:45:49 AM: Update 41068: task mnli, batch 68 (41068): accuracy: 0.8848, mnli_loss: 0.3053
09/06 03:45:59 AM: Update 41087: task mnli, batch 87 (41087): accuracy: 0.8870, mnli_loss: 0.3009
09/06 03:46:10 AM: Update 41100: task mnli, batch 100 (41100): accuracy: 0.8846, mnli_loss: 0.3048
09/06 03:46:20 AM: Update 41120: task mnli, batch 120 (41120): accuracy: 0.8847, mnli_loss: 0.3074
09/06 03:46:30 AM: Update 41139: task mnli, batch 139 (41139): accuracy: 0.8876, mnli_loss: 0.3015
09/06 03:46:41 AM: Update 41158: task mnli, batch 158 (41158): accuracy: 0.8877, mnli_loss: 0.3016
09/06 03:46:51 AM: Update 41176: task mnli, batch 176 (41176): accuracy: 0.8852, mnli_loss: 0.3078
09/06 03:47:01 AM: Update 41195: task mnli, batch 195 (41195): accuracy: 0.8818, mnli_loss: 0.3114
09/06 03:47:11 AM: Update 41214: task mnli, batch 214 (41214): accuracy: 0.8826, mnli_loss: 0.3100
09/06 03:47:22 AM: Update 41234: task mnli, batch 234 (41234): accuracy: 0.8823, mnli_loss: 0.3113
09/06 03:47:32 AM: Update 41253: task mnli, batch 253 (41253): accuracy: 0.8811, mnli_loss: 0.3164
09/06 03:47:42 AM: Update 41271: task mnli, batch 271 (41271): accuracy: 0.8804, mnli_loss: 0.3169
09/06 03:47:52 AM: Update 41291: task mnli, batch 291 (41291): accuracy: 0.8809, mnli_loss: 0.3174
09/06 03:48:03 AM: Update 41311: task mnli, batch 311 (41311): accuracy: 0.8813, mnli_loss: 0.3148
09/06 03:48:13 AM: Update 41331: task mnli, batch 331 (41331): accuracy: 0.8822, mnli_loss: 0.3114
09/06 03:48:23 AM: Update 41349: task mnli, batch 349 (41349): accuracy: 0.8806, mnli_loss: 0.3143
09/06 03:48:34 AM: Update 41368: task mnli, batch 368 (41368): accuracy: 0.8811, mnli_loss: 0.3132
09/06 03:48:44 AM: Update 41386: task mnli, batch 386 (41386): accuracy: 0.8822, mnli_loss: 0.3106
09/06 03:48:55 AM: Update 41404: task mnli, batch 404 (41404): accuracy: 0.8816, mnli_loss: 0.3131
09/06 03:49:05 AM: Update 41423: task mnli, batch 423 (41423): accuracy: 0.8824, mnli_loss: 0.3117
09/06 03:49:15 AM: Update 41442: task mnli, batch 442 (41442): accuracy: 0.8829, mnli_loss: 0.3120
09/06 03:49:25 AM: Update 41461: task mnli, batch 461 (41461): accuracy: 0.8830, mnli_loss: 0.3121
09/06 03:49:36 AM: Update 41480: task mnli, batch 480 (41480): accuracy: 0.8838, mnli_loss: 0.3107
09/06 03:49:46 AM: Update 41500: task mnli, batch 500 (41500): accuracy: 0.8846, mnli_loss: 0.3100
09/06 03:49:57 AM: Update 41512: task mnli, batch 512 (41512): accuracy: 0.8841, mnli_loss: 0.3107
09/06 03:50:07 AM: Update 41531: task mnli, batch 531 (41531): accuracy: 0.8836, mnli_loss: 0.3115
09/06 03:50:17 AM: Update 41548: task mnli, batch 548 (41548): accuracy: 0.8835, mnli_loss: 0.3112
09/06 03:50:28 AM: Update 41570: task mnli, batch 570 (41570): accuracy: 0.8836, mnli_loss: 0.3110
09/06 03:50:38 AM: Update 41589: task mnli, batch 589 (41589): accuracy: 0.8831, mnli_loss: 0.3115
09/06 03:50:49 AM: Update 41609: task mnli, batch 609 (41609): accuracy: 0.8832, mnli_loss: 0.3114
09/06 03:50:59 AM: Update 41628: task mnli, batch 628 (41628): accuracy: 0.8832, mnli_loss: 0.3117
09/06 03:51:09 AM: Update 41647: task mnli, batch 647 (41647): accuracy: 0.8829, mnli_loss: 0.3129
09/06 03:51:20 AM: Update 41667: task mnli, batch 667 (41667): accuracy: 0.8829, mnli_loss: 0.3131
09/06 03:51:30 AM: Update 41686: task mnli, batch 686 (41686): accuracy: 0.8834, mnli_loss: 0.3125
09/06 03:51:40 AM: Update 41705: task mnli, batch 705 (41705): accuracy: 0.8828, mnli_loss: 0.3138
09/06 03:51:50 AM: Update 41723: task mnli, batch 723 (41723): accuracy: 0.8826, mnli_loss: 0.3142
09/06 03:52:00 AM: Update 41742: task mnli, batch 742 (41742): accuracy: 0.8829, mnli_loss: 0.3134
09/06 03:52:10 AM: Update 41761: task mnli, batch 761 (41761): accuracy: 0.8831, mnli_loss: 0.3130
09/06 03:52:21 AM: Update 41779: task mnli, batch 779 (41779): accuracy: 0.8826, mnli_loss: 0.3138
09/06 03:52:31 AM: Update 41798: task mnli, batch 798 (41798): accuracy: 0.8826, mnli_loss: 0.3136
09/06 03:52:41 AM: Update 41817: task mnli, batch 817 (41817): accuracy: 0.8821, mnli_loss: 0.3142
09/06 03:52:52 AM: Update 41837: task mnli, batch 837 (41837): accuracy: 0.8823, mnli_loss: 0.3142
09/06 03:53:02 AM: Update 41855: task mnli, batch 855 (41855): accuracy: 0.8821, mnli_loss: 0.3146
09/06 03:53:12 AM: Update 41874: task mnli, batch 874 (41874): accuracy: 0.8823, mnli_loss: 0.3150
09/06 03:53:23 AM: Update 41893: task mnli, batch 893 (41893): accuracy: 0.8828, mnli_loss: 0.3141
09/06 03:53:33 AM: Update 41912: task mnli, batch 912 (41912): accuracy: 0.8829, mnli_loss: 0.3133
09/06 03:53:44 AM: Update 41927: task mnli, batch 927 (41927): accuracy: 0.8824, mnli_loss: 0.3139
09/06 03:53:54 AM: Update 41946: task mnli, batch 946 (41946): accuracy: 0.8826, mnli_loss: 0.3134
09/06 03:54:05 AM: Update 41964: task mnli, batch 964 (41964): accuracy: 0.8817, mnli_loss: 0.3147
09/06 03:54:15 AM: Update 41982: task mnli, batch 982 (41982): accuracy: 0.8818, mnli_loss: 0.3146
09/06 03:54:24 AM: ***** Step 42000 / Validation 42 *****
09/06 03:54:24 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 03:54:24 AM: Validating...
09/06 03:54:25 AM: Evaluate: task mnli, batch 3 (209): accuracy: 0.7639, mnli_loss: 0.5441
09/06 03:54:35 AM: Evaluate: task mnli, batch 54 (209): accuracy: 0.8225, mnli_loss: 0.4988
09/06 03:54:45 AM: Evaluate: task mnli, batch 104 (209): accuracy: 0.8229, mnli_loss: 0.5057
09/06 03:54:55 AM: Evaluate: task mnli, batch 154 (209): accuracy: 0.8233, mnli_loss: 0.5152
09/06 03:55:06 AM: Evaluate: task mnli, batch 204 (209): accuracy: 0.8217, mnli_loss: 0.5190
09/06 03:55:06 AM: Updating LR scheduler:
09/06 03:55:06 AM: 	Best result seen so far for macro_avg: 0.820
09/06 03:55:06 AM: 	# validation passes without improvement: 1
09/06 03:55:06 AM: mnli_loss: training: 0.314700 validation: 0.526653
09/06 03:55:06 AM: macro_avg: validation: 0.819400
09/06 03:55:06 AM: micro_avg: validation: 0.819400
09/06 03:55:06 AM: mnli_accuracy: training: 0.881757 validation: 0.819400
09/06 03:55:06 AM: Global learning rate: 5e-06
09/06 03:55:06 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 03:55:16 AM: Update 42016: task mnli, batch 16 (42016): accuracy: 0.8802, mnli_loss: 0.3183
09/06 03:55:26 AM: Update 42036: task mnli, batch 36 (42036): accuracy: 0.8808, mnli_loss: 0.3430
09/06 03:55:36 AM: Update 42055: task mnli, batch 55 (42055): accuracy: 0.8924, mnli_loss: 0.3129
09/06 03:55:46 AM: Update 42073: task mnli, batch 73 (42073): accuracy: 0.8927, mnli_loss: 0.3068
09/06 03:55:57 AM: Update 42092: task mnli, batch 92 (42092): accuracy: 0.8954, mnli_loss: 0.3050
09/06 03:56:07 AM: Update 42110: task mnli, batch 110 (42110): accuracy: 0.8867, mnli_loss: 0.3216
09/06 03:56:17 AM: Update 42129: task mnli, batch 129 (42129): accuracy: 0.8831, mnli_loss: 0.3315
09/06 03:56:27 AM: Update 42147: task mnli, batch 147 (42147): accuracy: 0.8844, mnli_loss: 0.3269
09/06 03:56:38 AM: Update 42168: task mnli, batch 168 (42168): accuracy: 0.8879, mnli_loss: 0.3188
09/06 03:56:48 AM: Update 42187: task mnli, batch 187 (42187): accuracy: 0.8881, mnli_loss: 0.3164
09/06 03:56:58 AM: Update 42205: task mnli, batch 205 (42205): accuracy: 0.8872, mnli_loss: 0.3191
09/06 03:57:08 AM: Update 42224: task mnli, batch 224 (42224): accuracy: 0.8871, mnli_loss: 0.3173
09/06 03:57:19 AM: Update 42243: task mnli, batch 243 (42243): accuracy: 0.8870, mnli_loss: 0.3159
09/06 03:57:29 AM: Update 42261: task mnli, batch 261 (42261): accuracy: 0.8873, mnli_loss: 0.3160
09/06 03:57:39 AM: Update 42279: task mnli, batch 279 (42279): accuracy: 0.8856, mnli_loss: 0.3192
09/06 03:57:49 AM: Update 42297: task mnli, batch 297 (42297): accuracy: 0.8858, mnli_loss: 0.3177
09/06 03:58:00 AM: Update 42316: task mnli, batch 316 (42316): accuracy: 0.8848, mnli_loss: 0.3194
09/06 03:58:10 AM: Update 42335: task mnli, batch 335 (42335): accuracy: 0.8862, mnli_loss: 0.3176
09/06 03:58:20 AM: Update 42350: task mnli, batch 350 (42350): accuracy: 0.8862, mnli_loss: 0.3174
09/06 03:58:31 AM: Update 42371: task mnli, batch 371 (42371): accuracy: 0.8855, mnli_loss: 0.3198
09/06 03:58:41 AM: Update 42389: task mnli, batch 389 (42389): accuracy: 0.8840, mnli_loss: 0.3214
09/06 03:58:52 AM: Update 42407: task mnli, batch 407 (42407): accuracy: 0.8827, mnli_loss: 0.3243
09/06 03:59:02 AM: Update 42425: task mnli, batch 425 (42425): accuracy: 0.8836, mnli_loss: 0.3218
09/06 03:59:12 AM: Update 42446: task mnli, batch 446 (42446): accuracy: 0.8840, mnli_loss: 0.3213
09/06 03:59:22 AM: Update 42466: task mnli, batch 466 (42466): accuracy: 0.8845, mnli_loss: 0.3205
09/06 03:59:33 AM: Update 42484: task mnli, batch 484 (42484): accuracy: 0.8840, mnli_loss: 0.3198
09/06 03:59:43 AM: Update 42502: task mnli, batch 502 (42502): accuracy: 0.8843, mnli_loss: 0.3187
09/06 03:59:53 AM: Update 42521: task mnli, batch 521 (42521): accuracy: 0.8846, mnli_loss: 0.3172
09/06 04:00:04 AM: Update 42541: task mnli, batch 541 (42541): accuracy: 0.8841, mnli_loss: 0.3179
09/06 04:00:14 AM: Update 42560: task mnli, batch 560 (42560): accuracy: 0.8842, mnli_loss: 0.3172
09/06 04:00:24 AM: Update 42579: task mnli, batch 579 (42579): accuracy: 0.8843, mnli_loss: 0.3161
09/06 04:00:34 AM: Update 42597: task mnli, batch 597 (42597): accuracy: 0.8844, mnli_loss: 0.3162
09/06 04:00:44 AM: Update 42617: task mnli, batch 617 (42617): accuracy: 0.8851, mnli_loss: 0.3141
09/06 04:00:55 AM: Update 42635: task mnli, batch 635 (42635): accuracy: 0.8841, mnli_loss: 0.3166
09/06 04:01:05 AM: Update 42654: task mnli, batch 654 (42654): accuracy: 0.8849, mnli_loss: 0.3153
09/06 04:01:16 AM: Update 42672: task mnli, batch 672 (42672): accuracy: 0.8846, mnli_loss: 0.3155
09/06 04:01:26 AM: Update 42691: task mnli, batch 691 (42691): accuracy: 0.8849, mnli_loss: 0.3147
09/06 04:01:37 AM: Update 42711: task mnli, batch 711 (42711): accuracy: 0.8847, mnli_loss: 0.3147
09/06 04:01:47 AM: Update 42731: task mnli, batch 731 (42731): accuracy: 0.8849, mnli_loss: 0.3145
09/06 04:01:57 AM: Update 42749: task mnli, batch 749 (42749): accuracy: 0.8847, mnli_loss: 0.3149
09/06 04:02:08 AM: Update 42764: task mnli, batch 764 (42764): accuracy: 0.8846, mnli_loss: 0.3156
09/06 04:02:18 AM: Update 42784: task mnli, batch 784 (42784): accuracy: 0.8847, mnli_loss: 0.3148
09/06 04:02:29 AM: Update 42802: task mnli, batch 802 (42802): accuracy: 0.8848, mnli_loss: 0.3145
09/06 04:02:39 AM: Update 42819: task mnli, batch 819 (42819): accuracy: 0.8845, mnli_loss: 0.3148
09/06 04:02:49 AM: Update 42838: task mnli, batch 838 (42838): accuracy: 0.8851, mnli_loss: 0.3133
09/06 04:03:00 AM: Update 42858: task mnli, batch 858 (42858): accuracy: 0.8850, mnli_loss: 0.3129
09/06 04:03:10 AM: Update 42878: task mnli, batch 878 (42878): accuracy: 0.8854, mnli_loss: 0.3117
09/06 04:03:20 AM: Update 42897: task mnli, batch 897 (42897): accuracy: 0.8862, mnli_loss: 0.3097
09/06 04:03:31 AM: Update 42916: task mnli, batch 916 (42916): accuracy: 0.8860, mnli_loss: 0.3096
09/06 04:03:42 AM: Update 42935: task mnli, batch 935 (42935): accuracy: 0.8857, mnli_loss: 0.3104
09/06 04:03:52 AM: Update 42954: task mnli, batch 954 (42954): accuracy: 0.8858, mnli_loss: 0.3100
09/06 04:04:02 AM: Update 42973: task mnli, batch 973 (42973): accuracy: 0.8857, mnli_loss: 0.3103
09/06 04:04:13 AM: Update 42992: task mnli, batch 992 (42992): accuracy: 0.8859, mnli_loss: 0.3101
09/06 04:04:17 AM: ***** Step 43000 / Validation 43 *****
09/06 04:04:17 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:04:17 AM: Validating...
09/06 04:04:23 AM: Evaluate: task mnli, batch 29 (209): accuracy: 0.8233, mnli_loss: 0.5047
09/06 04:04:33 AM: Evaluate: task mnli, batch 79 (209): accuracy: 0.8212, mnli_loss: 0.5066
09/06 04:04:43 AM: Evaluate: task mnli, batch 129 (209): accuracy: 0.8185, mnli_loss: 0.5200
09/06 04:04:53 AM: Evaluate: task mnli, batch 179 (209): accuracy: 0.8229, mnli_loss: 0.5234
09/06 04:04:59 AM: Updating LR scheduler:
09/06 04:04:59 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:04:59 AM: 	# validation passes without improvement: 2
09/06 04:04:59 AM: mnli_loss: training: 0.310362 validation: 0.535462
09/06 04:04:59 AM: macro_avg: validation: 0.817800
09/06 04:04:59 AM: micro_avg: validation: 0.817800
09/06 04:04:59 AM: mnli_accuracy: training: 0.885674 validation: 0.817800
09/06 04:04:59 AM: Global learning rate: 5e-06
09/06 04:04:59 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:05:03 AM: Update 43006: task mnli, batch 6 (43006): accuracy: 0.9167, mnli_loss: 0.2151
09/06 04:05:13 AM: Update 43025: task mnli, batch 25 (43025): accuracy: 0.8883, mnli_loss: 0.2937
09/06 04:05:24 AM: Update 43044: task mnli, batch 44 (43044): accuracy: 0.8911, mnli_loss: 0.2986
09/06 04:05:34 AM: Update 43063: task mnli, batch 63 (43063): accuracy: 0.8882, mnli_loss: 0.3062
09/06 04:05:44 AM: Update 43082: task mnli, batch 82 (43082): accuracy: 0.8908, mnli_loss: 0.3030
09/06 04:05:55 AM: Update 43101: task mnli, batch 101 (43101): accuracy: 0.8882, mnli_loss: 0.3094
09/06 04:06:05 AM: Update 43121: task mnli, batch 121 (43121): accuracy: 0.8905, mnli_loss: 0.3013
09/06 04:06:15 AM: Update 43139: task mnli, batch 139 (43139): accuracy: 0.8909, mnli_loss: 0.2991
09/06 04:06:25 AM: Update 43157: task mnli, batch 157 (43157): accuracy: 0.8875, mnli_loss: 0.3058
09/06 04:06:36 AM: Update 43177: task mnli, batch 177 (43177): accuracy: 0.8863, mnli_loss: 0.3107
09/06 04:06:46 AM: Update 43190: task mnli, batch 190 (43190): accuracy: 0.8877, mnli_loss: 0.3080
09/06 04:06:57 AM: Update 43209: task mnli, batch 209 (43209): accuracy: 0.8914, mnli_loss: 0.3001
09/06 04:07:07 AM: Update 43229: task mnli, batch 229 (43229): accuracy: 0.8905, mnli_loss: 0.3000
09/06 04:07:17 AM: Update 43249: task mnli, batch 249 (43249): accuracy: 0.8913, mnli_loss: 0.2972
09/06 04:07:28 AM: Update 43269: task mnli, batch 269 (43269): accuracy: 0.8914, mnli_loss: 0.2975
09/06 04:07:38 AM: Update 43287: task mnli, batch 287 (43287): accuracy: 0.8929, mnli_loss: 0.2950
09/06 04:07:48 AM: Update 43305: task mnli, batch 305 (43305): accuracy: 0.8935, mnli_loss: 0.2936
09/06 04:07:58 AM: Update 43325: task mnli, batch 325 (43325): accuracy: 0.8930, mnli_loss: 0.2933
09/06 04:08:09 AM: Update 43343: task mnli, batch 343 (43343): accuracy: 0.8920, mnli_loss: 0.2959
09/06 04:08:19 AM: Update 43361: task mnli, batch 361 (43361): accuracy: 0.8920, mnli_loss: 0.2965
09/06 04:08:29 AM: Update 43378: task mnli, batch 378 (43378): accuracy: 0.8902, mnli_loss: 0.2976
09/06 04:08:40 AM: Update 43397: task mnli, batch 397 (43397): accuracy: 0.8900, mnli_loss: 0.2986
09/06 04:08:50 AM: Update 43415: task mnli, batch 415 (43415): accuracy: 0.8894, mnli_loss: 0.3001
09/06 04:09:00 AM: Update 43433: task mnli, batch 433 (43433): accuracy: 0.8902, mnli_loss: 0.2975
09/06 04:09:10 AM: Update 43453: task mnli, batch 453 (43453): accuracy: 0.8903, mnli_loss: 0.2979
09/06 04:09:20 AM: Update 43475: task mnli, batch 475 (43475): accuracy: 0.8902, mnli_loss: 0.2981
09/06 04:09:31 AM: Update 43493: task mnli, batch 493 (43493): accuracy: 0.8906, mnli_loss: 0.2963
09/06 04:09:41 AM: Update 43511: task mnli, batch 511 (43511): accuracy: 0.8900, mnli_loss: 0.2973
09/06 04:09:51 AM: Update 43531: task mnli, batch 531 (43531): accuracy: 0.8902, mnli_loss: 0.2967
09/06 04:10:01 AM: Update 43550: task mnli, batch 550 (43550): accuracy: 0.8904, mnli_loss: 0.2964
09/06 04:10:12 AM: Update 43569: task mnli, batch 569 (43569): accuracy: 0.8902, mnli_loss: 0.2962
09/06 04:10:22 AM: Update 43587: task mnli, batch 587 (43587): accuracy: 0.8889, mnli_loss: 0.2990
09/06 04:10:32 AM: Update 43603: task mnli, batch 603 (43603): accuracy: 0.8895, mnli_loss: 0.2988
09/06 04:10:43 AM: Update 43622: task mnli, batch 622 (43622): accuracy: 0.8879, mnli_loss: 0.3013
09/06 04:10:53 AM: Update 43641: task mnli, batch 641 (43641): accuracy: 0.8883, mnli_loss: 0.3004
09/06 04:11:03 AM: Update 43660: task mnli, batch 660 (43660): accuracy: 0.8886, mnli_loss: 0.2998
09/06 04:11:14 AM: Update 43677: task mnli, batch 677 (43677): accuracy: 0.8876, mnli_loss: 0.3017
09/06 04:11:24 AM: Update 43696: task mnli, batch 696 (43696): accuracy: 0.8873, mnli_loss: 0.3024
09/06 04:11:34 AM: Update 43715: task mnli, batch 715 (43715): accuracy: 0.8881, mnli_loss: 0.3015
09/06 04:11:44 AM: Update 43733: task mnli, batch 733 (43733): accuracy: 0.8874, mnli_loss: 0.3025
09/06 04:11:55 AM: Update 43752: task mnli, batch 752 (43752): accuracy: 0.8879, mnli_loss: 0.3011
09/06 04:12:05 AM: Update 43772: task mnli, batch 772 (43772): accuracy: 0.8876, mnli_loss: 0.3004
09/06 04:12:15 AM: Update 43792: task mnli, batch 792 (43792): accuracy: 0.8881, mnli_loss: 0.2990
09/06 04:12:26 AM: Update 43810: task mnli, batch 810 (43810): accuracy: 0.8875, mnli_loss: 0.3001
09/06 04:12:36 AM: Update 43828: task mnli, batch 828 (43828): accuracy: 0.8873, mnli_loss: 0.3014
09/06 04:12:46 AM: Update 43847: task mnli, batch 847 (43847): accuracy: 0.8868, mnli_loss: 0.3018
09/06 04:12:56 AM: Update 43865: task mnli, batch 865 (43865): accuracy: 0.8861, mnli_loss: 0.3035
09/06 04:13:07 AM: Update 43883: task mnli, batch 883 (43883): accuracy: 0.8858, mnli_loss: 0.3039
09/06 04:13:17 AM: Update 43903: task mnli, batch 903 (43903): accuracy: 0.8860, mnli_loss: 0.3034
09/06 04:13:27 AM: Update 43923: task mnli, batch 923 (43923): accuracy: 0.8861, mnli_loss: 0.3040
09/06 04:13:37 AM: Update 43942: task mnli, batch 942 (43942): accuracy: 0.8862, mnli_loss: 0.3032
09/06 04:13:48 AM: Update 43962: task mnli, batch 962 (43962): accuracy: 0.8863, mnli_loss: 0.3030
09/06 04:13:58 AM: Update 43980: task mnli, batch 980 (43980): accuracy: 0.8865, mnli_loss: 0.3030
09/06 04:14:08 AM: Update 43998: task mnli, batch 998 (43998): accuracy: 0.8868, mnli_loss: 0.3024
09/06 04:14:09 AM: ***** Step 44000 / Validation 44 *****
09/06 04:14:09 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:14:09 AM: Validating...
09/06 04:14:18 AM: Evaluate: task mnli, batch 44 (209): accuracy: 0.8239, mnli_loss: 0.5123
09/06 04:14:28 AM: Evaluate: task mnli, batch 94 (209): accuracy: 0.8236, mnli_loss: 0.5124
09/06 04:14:38 AM: Evaluate: task mnli, batch 144 (209): accuracy: 0.8212, mnli_loss: 0.5260
09/06 04:14:49 AM: Evaluate: task mnli, batch 194 (209): accuracy: 0.8232, mnli_loss: 0.5237
09/06 04:14:52 AM: Updating LR scheduler:
09/06 04:14:52 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:14:52 AM: 	# validation passes without improvement: 3
09/06 04:14:52 AM: mnli_loss: training: 0.302358 validation: 0.533594
09/06 04:14:52 AM: macro_avg: validation: 0.819600
09/06 04:14:52 AM: micro_avg: validation: 0.819600
09/06 04:14:52 AM: mnli_accuracy: training: 0.886841 validation: 0.819600
09/06 04:14:52 AM: Global learning rate: 5e-06
09/06 04:14:52 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:15:01 AM: Update 44012: task mnli, batch 12 (44012): accuracy: 0.9036, mnli_loss: 0.2459
09/06 04:15:11 AM: Update 44029: task mnli, batch 29 (44029): accuracy: 0.8692, mnli_loss: 0.3264
09/06 04:15:22 AM: Update 44048: task mnli, batch 48 (44048): accuracy: 0.8829, mnli_loss: 0.2991
09/06 04:15:32 AM: Update 44067: task mnli, batch 67 (44067): accuracy: 0.8800, mnli_loss: 0.3057
09/06 04:15:42 AM: Update 44085: task mnli, batch 85 (44085): accuracy: 0.8780, mnli_loss: 0.3128
09/06 04:15:52 AM: Update 44104: task mnli, batch 104 (44104): accuracy: 0.8806, mnli_loss: 0.3072
09/06 04:16:02 AM: Update 44123: task mnli, batch 123 (44123): accuracy: 0.8784, mnli_loss: 0.3133
09/06 04:16:13 AM: Update 44142: task mnli, batch 142 (44142): accuracy: 0.8782, mnli_loss: 0.3125
09/06 04:16:23 AM: Update 44160: task mnli, batch 160 (44160): accuracy: 0.8779, mnli_loss: 0.3162
09/06 04:16:34 AM: Update 44179: task mnli, batch 179 (44179): accuracy: 0.8792, mnli_loss: 0.3137
09/06 04:16:44 AM: Update 44199: task mnli, batch 199 (44199): accuracy: 0.8805, mnli_loss: 0.3103
09/06 04:16:54 AM: Update 44219: task mnli, batch 219 (44219): accuracy: 0.8819, mnli_loss: 0.3059
09/06 04:17:05 AM: Update 44239: task mnli, batch 239 (44239): accuracy: 0.8844, mnli_loss: 0.3010
09/06 04:17:15 AM: Update 44258: task mnli, batch 258 (44258): accuracy: 0.8847, mnli_loss: 0.3037
09/06 04:17:25 AM: Update 44277: task mnli, batch 277 (44277): accuracy: 0.8822, mnli_loss: 0.3083
09/06 04:17:36 AM: Update 44297: task mnli, batch 297 (44297): accuracy: 0.8831, mnli_loss: 0.3088
09/06 04:17:46 AM: Update 44315: task mnli, batch 315 (44315): accuracy: 0.8832, mnli_loss: 0.3110
09/06 04:17:57 AM: Update 44334: task mnli, batch 334 (44334): accuracy: 0.8824, mnli_loss: 0.3117
09/06 04:18:07 AM: Update 44353: task mnli, batch 353 (44353): accuracy: 0.8819, mnli_loss: 0.3128
09/06 04:18:17 AM: Update 44372: task mnli, batch 372 (44372): accuracy: 0.8824, mnli_loss: 0.3124
09/06 04:18:27 AM: Update 44392: task mnli, batch 392 (44392): accuracy: 0.8837, mnli_loss: 0.3084
09/06 04:18:37 AM: Update 44411: task mnli, batch 411 (44411): accuracy: 0.8834, mnli_loss: 0.3087
09/06 04:18:50 AM: Update 44429: task mnli, batch 429 (44429): accuracy: 0.8819, mnli_loss: 0.3139
09/06 04:19:00 AM: Update 44447: task mnli, batch 447 (44447): accuracy: 0.8813, mnli_loss: 0.3163
09/06 04:19:10 AM: Update 44468: task mnli, batch 468 (44468): accuracy: 0.8810, mnli_loss: 0.3182
09/06 04:19:20 AM: Update 44487: task mnli, batch 487 (44487): accuracy: 0.8811, mnli_loss: 0.3213
09/06 04:19:31 AM: Update 44506: task mnli, batch 506 (44506): accuracy: 0.8796, mnli_loss: 0.3240
09/06 04:19:41 AM: Update 44525: task mnli, batch 525 (44525): accuracy: 0.8798, mnli_loss: 0.3245
09/06 04:19:52 AM: Update 44544: task mnli, batch 544 (44544): accuracy: 0.8798, mnli_loss: 0.3252
09/06 04:20:02 AM: Update 44563: task mnli, batch 563 (44563): accuracy: 0.8790, mnli_loss: 0.3265
09/06 04:20:13 AM: Update 44582: task mnli, batch 582 (44582): accuracy: 0.8789, mnli_loss: 0.3278
09/06 04:20:23 AM: Update 44600: task mnli, batch 600 (44600): accuracy: 0.8789, mnli_loss: 0.3275
09/06 04:20:33 AM: Update 44618: task mnli, batch 618 (44618): accuracy: 0.8781, mnli_loss: 0.3278
09/06 04:20:43 AM: Update 44638: task mnli, batch 638 (44638): accuracy: 0.8789, mnli_loss: 0.3266
09/06 04:20:54 AM: Update 44657: task mnli, batch 657 (44657): accuracy: 0.8786, mnli_loss: 0.3270
09/06 04:21:04 AM: Update 44677: task mnli, batch 677 (44677): accuracy: 0.8793, mnli_loss: 0.3263
09/06 04:21:14 AM: Update 44694: task mnli, batch 694 (44694): accuracy: 0.8784, mnli_loss: 0.3272
09/06 04:21:24 AM: Update 44713: task mnli, batch 713 (44713): accuracy: 0.8779, mnli_loss: 0.3286
09/06 04:21:35 AM: Update 44732: task mnli, batch 732 (44732): accuracy: 0.8767, mnli_loss: 0.3308
09/06 04:21:45 AM: Update 44751: task mnli, batch 751 (44751): accuracy: 0.8765, mnli_loss: 0.3309
09/06 04:21:56 AM: Update 44770: task mnli, batch 770 (44770): accuracy: 0.8759, mnli_loss: 0.3328
09/06 04:22:06 AM: Update 44788: task mnli, batch 788 (44788): accuracy: 0.8756, mnli_loss: 0.3332
09/06 04:22:16 AM: Update 44808: task mnli, batch 808 (44808): accuracy: 0.8759, mnli_loss: 0.3325
09/06 04:22:27 AM: Update 44827: task mnli, batch 827 (44827): accuracy: 0.8759, mnli_loss: 0.3329
09/06 04:22:37 AM: Update 44845: task mnli, batch 845 (44845): accuracy: 0.8757, mnli_loss: 0.3330
09/06 04:22:47 AM: Update 44860: task mnli, batch 860 (44860): accuracy: 0.8758, mnli_loss: 0.3332
09/06 04:22:57 AM: Update 44879: task mnli, batch 879 (44879): accuracy: 0.8759, mnli_loss: 0.3329
09/06 04:23:08 AM: Update 44897: task mnli, batch 897 (44897): accuracy: 0.8758, mnli_loss: 0.3322
09/06 04:23:18 AM: Update 44917: task mnli, batch 917 (44917): accuracy: 0.8763, mnli_loss: 0.3309
09/06 04:23:28 AM: Update 44936: task mnli, batch 936 (44936): accuracy: 0.8761, mnli_loss: 0.3312
09/06 04:23:39 AM: Update 44954: task mnli, batch 954 (44954): accuracy: 0.8753, mnli_loss: 0.3336
09/06 04:23:49 AM: Update 44972: task mnli, batch 972 (44972): accuracy: 0.8751, mnli_loss: 0.3344
09/06 04:23:59 AM: Update 44992: task mnli, batch 992 (44992): accuracy: 0.8748, mnli_loss: 0.3346
09/06 04:24:03 AM: ***** Step 45000 / Validation 45 *****
09/06 04:24:03 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:24:03 AM: Validating...
09/06 04:24:10 AM: Evaluate: task mnli, batch 31 (209): accuracy: 0.8185, mnli_loss: 0.5007
09/06 04:24:20 AM: Evaluate: task mnli, batch 81 (209): accuracy: 0.8236, mnli_loss: 0.4962
09/06 04:24:31 AM: Evaluate: task mnli, batch 131 (209): accuracy: 0.8203, mnli_loss: 0.5094
09/06 04:24:41 AM: Evaluate: task mnli, batch 181 (209): accuracy: 0.8237, mnli_loss: 0.5091
09/06 04:24:46 AM: Updating LR scheduler:
09/06 04:24:46 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:24:46 AM: 	# validation passes without improvement: 4
09/06 04:24:46 AM: mnli_loss: training: 0.334533 validation: 0.522864
09/06 04:24:46 AM: macro_avg: validation: 0.817600
09/06 04:24:46 AM: micro_avg: validation: 0.817600
09/06 04:24:46 AM: mnli_accuracy: training: 0.874833 validation: 0.817600
09/06 04:24:46 AM: Global learning rate: 5e-06
09/06 04:24:46 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:24:51 AM: Update 45007: task mnli, batch 7 (45007): accuracy: 0.8750, mnli_loss: 0.2952
09/06 04:25:01 AM: Update 45027: task mnli, batch 27 (45027): accuracy: 0.8673, mnli_loss: 0.3127
09/06 04:25:11 AM: Update 45045: task mnli, batch 45 (45045): accuracy: 0.8685, mnli_loss: 0.3535
09/06 04:25:22 AM: Update 45064: task mnli, batch 64 (45064): accuracy: 0.8724, mnli_loss: 0.3469
09/06 04:25:32 AM: Update 45083: task mnli, batch 83 (45083): accuracy: 0.8720, mnli_loss: 0.3498
09/06 04:25:43 AM: Update 45102: task mnli, batch 102 (45102): accuracy: 0.8725, mnli_loss: 0.3438
09/06 04:25:53 AM: Update 45120: task mnli, batch 120 (45120): accuracy: 0.8750, mnli_loss: 0.3376
09/06 04:26:03 AM: Update 45139: task mnli, batch 139 (45139): accuracy: 0.8750, mnli_loss: 0.3365
09/06 04:26:14 AM: Update 45158: task mnli, batch 158 (45158): accuracy: 0.8729, mnli_loss: 0.3397
09/06 04:26:24 AM: Update 45177: task mnli, batch 177 (45177): accuracy: 0.8734, mnli_loss: 0.3376
09/06 04:26:34 AM: Update 45196: task mnli, batch 196 (45196): accuracy: 0.8729, mnli_loss: 0.3413
09/06 04:26:44 AM: Update 45214: task mnli, batch 214 (45214): accuracy: 0.8729, mnli_loss: 0.3439
09/06 04:26:55 AM: Update 45234: task mnli, batch 234 (45234): accuracy: 0.8736, mnli_loss: 0.3394
09/06 04:27:05 AM: Update 45253: task mnli, batch 253 (45253): accuracy: 0.8724, mnli_loss: 0.3445
09/06 04:27:16 AM: Update 45268: task mnli, batch 268 (45268): accuracy: 0.8719, mnli_loss: 0.3436
09/06 04:27:26 AM: Update 45288: task mnli, batch 288 (45288): accuracy: 0.8728, mnli_loss: 0.3427
09/06 04:27:36 AM: Update 45306: task mnli, batch 306 (45306): accuracy: 0.8702, mnli_loss: 0.3469
09/06 04:27:47 AM: Update 45326: task mnli, batch 326 (45326): accuracy: 0.8708, mnli_loss: 0.3453
09/06 04:27:57 AM: Update 45344: task mnli, batch 344 (45344): accuracy: 0.8718, mnli_loss: 0.3450
09/06 04:28:07 AM: Update 45364: task mnli, batch 364 (45364): accuracy: 0.8717, mnli_loss: 0.3429
09/06 04:28:18 AM: Update 45384: task mnli, batch 384 (45384): accuracy: 0.8734, mnli_loss: 0.3384
09/06 04:28:28 AM: Update 45402: task mnli, batch 402 (45402): accuracy: 0.8742, mnli_loss: 0.3373
09/06 04:28:39 AM: Update 45421: task mnli, batch 421 (45421): accuracy: 0.8740, mnli_loss: 0.3375
09/06 04:28:49 AM: Update 45440: task mnli, batch 440 (45440): accuracy: 0.8742, mnli_loss: 0.3382
09/06 04:28:59 AM: Update 45461: task mnli, batch 461 (45461): accuracy: 0.8751, mnli_loss: 0.3366
09/06 04:29:09 AM: Update 45479: task mnli, batch 479 (45479): accuracy: 0.8753, mnli_loss: 0.3362
09/06 04:29:19 AM: Update 45498: task mnli, batch 498 (45498): accuracy: 0.8751, mnli_loss: 0.3372
09/06 04:29:30 AM: Update 45518: task mnli, batch 518 (45518): accuracy: 0.8748, mnli_loss: 0.3390
09/06 04:29:40 AM: Update 45535: task mnli, batch 535 (45535): accuracy: 0.8738, mnli_loss: 0.3408
09/06 04:29:51 AM: Update 45553: task mnli, batch 553 (45553): accuracy: 0.8733, mnli_loss: 0.3421
09/06 04:30:01 AM: Update 45573: task mnli, batch 573 (45573): accuracy: 0.8738, mnli_loss: 0.3406
09/06 04:30:11 AM: Update 45591: task mnli, batch 591 (45591): accuracy: 0.8735, mnli_loss: 0.3404
09/06 04:30:21 AM: Update 45609: task mnli, batch 609 (45609): accuracy: 0.8727, mnli_loss: 0.3417
09/06 04:30:31 AM: Update 45627: task mnli, batch 627 (45627): accuracy: 0.8725, mnli_loss: 0.3415
09/06 04:30:42 AM: Update 45647: task mnli, batch 647 (45647): accuracy: 0.8728, mnli_loss: 0.3398
09/06 04:30:52 AM: Update 45665: task mnli, batch 665 (45665): accuracy: 0.8732, mnli_loss: 0.3388
09/06 04:31:03 AM: Update 45680: task mnli, batch 680 (45680): accuracy: 0.8734, mnli_loss: 0.3380
09/06 04:31:13 AM: Update 45700: task mnli, batch 700 (45700): accuracy: 0.8719, mnli_loss: 0.3416
09/06 04:31:23 AM: Update 45719: task mnli, batch 719 (45719): accuracy: 0.8715, mnli_loss: 0.3421
09/06 04:31:33 AM: Update 45737: task mnli, batch 737 (45737): accuracy: 0.8712, mnli_loss: 0.3433
09/06 04:31:44 AM: Update 45756: task mnli, batch 756 (45756): accuracy: 0.8716, mnli_loss: 0.3423
09/06 04:31:54 AM: Update 45774: task mnli, batch 774 (45774): accuracy: 0.8713, mnli_loss: 0.3422
09/06 04:32:04 AM: Update 45792: task mnli, batch 792 (45792): accuracy: 0.8712, mnli_loss: 0.3421
09/06 04:32:14 AM: Update 45812: task mnli, batch 812 (45812): accuracy: 0.8705, mnli_loss: 0.3426
09/06 04:32:25 AM: Update 45830: task mnli, batch 830 (45830): accuracy: 0.8698, mnli_loss: 0.3439
09/06 04:32:35 AM: Update 45850: task mnli, batch 850 (45850): accuracy: 0.8691, mnli_loss: 0.3444
09/06 04:32:46 AM: Update 45868: task mnli, batch 868 (45868): accuracy: 0.8685, mnli_loss: 0.3454
09/06 04:32:56 AM: Update 45888: task mnli, batch 888 (45888): accuracy: 0.8690, mnli_loss: 0.3451
09/06 04:33:06 AM: Update 45906: task mnli, batch 906 (45906): accuracy: 0.8692, mnli_loss: 0.3448
09/06 04:33:17 AM: Update 45923: task mnli, batch 923 (45923): accuracy: 0.8689, mnli_loss: 0.3456
09/06 04:33:27 AM: Update 45941: task mnli, batch 941 (45941): accuracy: 0.8684, mnli_loss: 0.3462
09/06 04:33:37 AM: Update 45959: task mnli, batch 959 (45959): accuracy: 0.8683, mnli_loss: 0.3467
09/06 04:33:47 AM: Update 45979: task mnli, batch 979 (45979): accuracy: 0.8681, mnli_loss: 0.3476
09/06 04:33:58 AM: Update 45999: task mnli, batch 999 (45999): accuracy: 0.8679, mnli_loss: 0.3486
09/06 04:33:58 AM: ***** Step 46000 / Validation 46 *****
09/06 04:33:58 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:33:58 AM: Validating...
09/06 04:34:08 AM: Evaluate: task mnli, batch 47 (209): accuracy: 0.8165, mnli_loss: 0.4936
09/06 04:34:18 AM: Evaluate: task mnli, batch 97 (209): accuracy: 0.8170, mnli_loss: 0.4994
09/06 04:34:28 AM: Evaluate: task mnli, batch 146 (209): accuracy: 0.8191, mnli_loss: 0.5076
09/06 04:34:38 AM: Evaluate: task mnli, batch 196 (209): accuracy: 0.8195, mnli_loss: 0.5071
09/06 04:34:40 AM: Updating LR scheduler:
09/06 04:34:40 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:34:40 AM: 	# validation passes without improvement: 0
09/06 04:34:40 AM: mnli_loss: training: 0.348473 validation: 0.517013
09/06 04:34:40 AM: macro_avg: validation: 0.816400
09/06 04:34:40 AM: micro_avg: validation: 0.816400
09/06 04:34:40 AM: mnli_accuracy: training: 0.867870 validation: 0.816400
09/06 04:34:40 AM: Global learning rate: 2.5e-06
09/06 04:34:40 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:34:48 AM: Update 46012: task mnli, batch 12 (46012): accuracy: 0.8924, mnli_loss: 0.3157
09/06 04:34:58 AM: Update 46032: task mnli, batch 32 (46032): accuracy: 0.8841, mnli_loss: 0.3324
09/06 04:35:08 AM: Update 46050: task mnli, batch 50 (46050): accuracy: 0.8808, mnli_loss: 0.3347
09/06 04:35:19 AM: Update 46070: task mnli, batch 70 (46070): accuracy: 0.8744, mnli_loss: 0.3514
09/06 04:35:29 AM: Update 46089: task mnli, batch 89 (46089): accuracy: 0.8769, mnli_loss: 0.3504
09/06 04:35:39 AM: Update 46101: task mnli, batch 101 (46101): accuracy: 0.8754, mnli_loss: 0.3481
09/06 04:35:49 AM: Update 46120: task mnli, batch 120 (46120): accuracy: 0.8743, mnli_loss: 0.3526
09/06 04:36:00 AM: Update 46139: task mnli, batch 139 (46139): accuracy: 0.8720, mnli_loss: 0.3493
09/06 04:36:10 AM: Update 46160: task mnli, batch 160 (46160): accuracy: 0.8768, mnli_loss: 0.3413
09/06 04:36:21 AM: Update 46179: task mnli, batch 179 (46179): accuracy: 0.8748, mnli_loss: 0.3442
09/06 04:36:31 AM: Update 46198: task mnli, batch 198 (46198): accuracy: 0.8754, mnli_loss: 0.3419
09/06 04:36:42 AM: Update 46218: task mnli, batch 218 (46218): accuracy: 0.8756, mnli_loss: 0.3374
09/06 04:36:52 AM: Update 46237: task mnli, batch 237 (46237): accuracy: 0.8771, mnli_loss: 0.3330
09/06 04:37:03 AM: Update 46255: task mnli, batch 255 (46255): accuracy: 0.8760, mnli_loss: 0.3356
09/06 04:37:13 AM: Update 46273: task mnli, batch 273 (46273): accuracy: 0.8730, mnli_loss: 0.3402
09/06 04:37:23 AM: Update 46292: task mnli, batch 292 (46292): accuracy: 0.8729, mnli_loss: 0.3404
09/06 04:37:33 AM: Update 46309: task mnli, batch 309 (46309): accuracy: 0.8732, mnli_loss: 0.3394
09/06 04:37:44 AM: Update 46327: task mnli, batch 327 (46327): accuracy: 0.8724, mnli_loss: 0.3408
09/06 04:37:54 AM: Update 46347: task mnli, batch 347 (46347): accuracy: 0.8716, mnli_loss: 0.3421
09/06 04:38:04 AM: Update 46366: task mnli, batch 366 (46366): accuracy: 0.8716, mnli_loss: 0.3411
09/06 04:38:14 AM: Update 46385: task mnli, batch 385 (46385): accuracy: 0.8718, mnli_loss: 0.3390
09/06 04:38:25 AM: Update 46405: task mnli, batch 405 (46405): accuracy: 0.8717, mnli_loss: 0.3372
09/06 04:38:35 AM: Update 46426: task mnli, batch 426 (46426): accuracy: 0.8711, mnli_loss: 0.3381
09/06 04:38:45 AM: Update 46445: task mnli, batch 445 (46445): accuracy: 0.8713, mnli_loss: 0.3385
09/06 04:38:56 AM: Update 46464: task mnli, batch 464 (46464): accuracy: 0.8709, mnli_loss: 0.3393
09/06 04:39:06 AM: Update 46484: task mnli, batch 484 (46484): accuracy: 0.8702, mnli_loss: 0.3399
09/06 04:39:17 AM: Update 46502: task mnli, batch 502 (46502): accuracy: 0.8708, mnli_loss: 0.3380
09/06 04:39:27 AM: Update 46515: task mnli, batch 515 (46515): accuracy: 0.8703, mnli_loss: 0.3401
09/06 04:39:37 AM: Update 46534: task mnli, batch 534 (46534): accuracy: 0.8716, mnli_loss: 0.3375
09/06 04:39:47 AM: Update 46554: task mnli, batch 554 (46554): accuracy: 0.8712, mnli_loss: 0.3384
09/06 04:39:58 AM: Update 46573: task mnli, batch 573 (46573): accuracy: 0.8709, mnli_loss: 0.3391
09/06 04:40:08 AM: Update 46592: task mnli, batch 592 (46592): accuracy: 0.8708, mnli_loss: 0.3394
09/06 04:40:19 AM: Update 46610: task mnli, batch 610 (46610): accuracy: 0.8701, mnli_loss: 0.3404
09/06 04:40:29 AM: Update 46630: task mnli, batch 630 (46630): accuracy: 0.8694, mnli_loss: 0.3418
09/06 04:40:39 AM: Update 46647: task mnli, batch 647 (46647): accuracy: 0.8694, mnli_loss: 0.3412
09/06 04:40:50 AM: Update 46665: task mnli, batch 665 (46665): accuracy: 0.8700, mnli_loss: 0.3406
09/06 04:41:00 AM: Update 46685: task mnli, batch 685 (46685): accuracy: 0.8697, mnli_loss: 0.3416
09/06 04:41:10 AM: Update 46702: task mnli, batch 702 (46702): accuracy: 0.8691, mnli_loss: 0.3432
09/06 04:41:20 AM: Update 46721: task mnli, batch 721 (46721): accuracy: 0.8689, mnli_loss: 0.3427
09/06 04:41:31 AM: Update 46742: task mnli, batch 742 (46742): accuracy: 0.8681, mnli_loss: 0.3444
09/06 04:41:41 AM: Update 46761: task mnli, batch 761 (46761): accuracy: 0.8677, mnli_loss: 0.3469
09/06 04:41:51 AM: Update 46781: task mnli, batch 781 (46781): accuracy: 0.8677, mnli_loss: 0.3467
09/06 04:42:02 AM: Update 46801: task mnli, batch 801 (46801): accuracy: 0.8681, mnli_loss: 0.3461
09/06 04:42:12 AM: Update 46820: task mnli, batch 820 (46820): accuracy: 0.8676, mnli_loss: 0.3469
09/06 04:42:22 AM: Update 46839: task mnli, batch 839 (46839): accuracy: 0.8679, mnli_loss: 0.3465
09/06 04:42:33 AM: Update 46856: task mnli, batch 856 (46856): accuracy: 0.8674, mnli_loss: 0.3472
09/06 04:42:43 AM: Update 46875: task mnli, batch 875 (46875): accuracy: 0.8670, mnli_loss: 0.3475
09/06 04:42:53 AM: Update 46894: task mnli, batch 894 (46894): accuracy: 0.8669, mnli_loss: 0.3480
09/06 04:43:04 AM: Update 46913: task mnli, batch 913 (46913): accuracy: 0.8661, mnli_loss: 0.3495
09/06 04:43:16 AM: Update 46931: task mnli, batch 931 (46931): accuracy: 0.8661, mnli_loss: 0.3501
09/06 04:43:26 AM: Update 46948: task mnli, batch 948 (46948): accuracy: 0.8662, mnli_loss: 0.3502
09/06 04:43:36 AM: Update 46967: task mnli, batch 967 (46967): accuracy: 0.8664, mnli_loss: 0.3502
09/06 04:43:46 AM: Update 46987: task mnli, batch 987 (46987): accuracy: 0.8660, mnli_loss: 0.3508
09/06 04:43:53 AM: ***** Step 47000 / Validation 47 *****
09/06 04:43:53 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:43:53 AM: Validating...
09/06 04:43:57 AM: Evaluate: task mnli, batch 17 (209): accuracy: 0.8039, mnli_loss: 0.4940
09/06 04:44:07 AM: Evaluate: task mnli, batch 67 (209): accuracy: 0.8159, mnli_loss: 0.4986
09/06 04:44:17 AM: Evaluate: task mnli, batch 117 (209): accuracy: 0.8120, mnli_loss: 0.5076
09/06 04:44:27 AM: Evaluate: task mnli, batch 167 (209): accuracy: 0.8181, mnli_loss: 0.5081
09/06 04:44:35 AM: Updating LR scheduler:
09/06 04:44:35 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:44:35 AM: 	# validation passes without improvement: 1
09/06 04:44:35 AM: mnli_loss: training: 0.350432 validation: 0.520063
09/06 04:44:35 AM: macro_avg: validation: 0.814600
09/06 04:44:35 AM: micro_avg: validation: 0.814600
09/06 04:44:35 AM: mnli_accuracy: training: 0.866366 validation: 0.814600
09/06 04:44:35 AM: Global learning rate: 2.5e-06
09/06 04:44:35 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:44:37 AM: Update 47001: task mnli, batch 1 (47001): accuracy: 0.7917, mnli_loss: 0.5012
09/06 04:44:48 AM: Update 47021: task mnli, batch 21 (47021): accuracy: 0.8889, mnli_loss: 0.3231
09/06 04:44:58 AM: Update 47039: task mnli, batch 39 (47039): accuracy: 0.8697, mnli_loss: 0.3618
09/06 04:45:08 AM: Update 47058: task mnli, batch 58 (47058): accuracy: 0.8728, mnli_loss: 0.3587
09/06 04:45:18 AM: Update 47078: task mnli, batch 78 (47078): accuracy: 0.8665, mnli_loss: 0.3599
09/06 04:45:29 AM: Update 47097: task mnli, batch 97 (47097): accuracy: 0.8634, mnli_loss: 0.3606
09/06 04:45:39 AM: Update 47117: task mnli, batch 117 (47117): accuracy: 0.8668, mnli_loss: 0.3499
09/06 04:45:49 AM: Update 47136: task mnli, batch 136 (47136): accuracy: 0.8649, mnli_loss: 0.3506
09/06 04:45:59 AM: Update 47156: task mnli, batch 156 (47156): accuracy: 0.8662, mnli_loss: 0.3465
09/06 04:46:10 AM: Update 47175: task mnli, batch 175 (47175): accuracy: 0.8676, mnli_loss: 0.3440
09/06 04:46:20 AM: Update 47193: task mnli, batch 193 (47193): accuracy: 0.8698, mnli_loss: 0.3403
09/06 04:46:30 AM: Update 47212: task mnli, batch 212 (47212): accuracy: 0.8701, mnli_loss: 0.3403
09/06 04:46:41 AM: Update 47231: task mnli, batch 231 (47231): accuracy: 0.8707, mnli_loss: 0.3399
09/06 04:46:51 AM: Update 47249: task mnli, batch 249 (47249): accuracy: 0.8708, mnli_loss: 0.3398
09/06 04:47:01 AM: Update 47266: task mnli, batch 266 (47266): accuracy: 0.8695, mnli_loss: 0.3433
09/06 04:47:11 AM: Update 47286: task mnli, batch 286 (47286): accuracy: 0.8690, mnli_loss: 0.3424
09/06 04:47:21 AM: Update 47305: task mnli, batch 305 (47305): accuracy: 0.8691, mnli_loss: 0.3430
09/06 04:47:31 AM: Update 47323: task mnli, batch 323 (47323): accuracy: 0.8702, mnli_loss: 0.3396
09/06 04:47:41 AM: Update 47340: task mnli, batch 340 (47340): accuracy: 0.8691, mnli_loss: 0.3423
09/06 04:47:52 AM: Update 47354: task mnli, batch 354 (47354): accuracy: 0.8677, mnli_loss: 0.3442
09/06 04:48:02 AM: Update 47373: task mnli, batch 373 (47373): accuracy: 0.8669, mnli_loss: 0.3455
09/06 04:48:12 AM: Update 47391: task mnli, batch 391 (47391): accuracy: 0.8665, mnli_loss: 0.3465
09/06 04:48:23 AM: Update 47408: task mnli, batch 408 (47408): accuracy: 0.8664, mnli_loss: 0.3464
09/06 04:48:33 AM: Update 47426: task mnli, batch 426 (47426): accuracy: 0.8669, mnli_loss: 0.3462
09/06 04:48:44 AM: Update 47446: task mnli, batch 446 (47446): accuracy: 0.8678, mnli_loss: 0.3453
09/06 04:48:54 AM: Update 47465: task mnli, batch 465 (47465): accuracy: 0.8686, mnli_loss: 0.3447
09/06 04:49:04 AM: Update 47482: task mnli, batch 482 (47482): accuracy: 0.8691, mnli_loss: 0.3452
09/06 04:49:14 AM: Update 47500: task mnli, batch 500 (47500): accuracy: 0.8677, mnli_loss: 0.3483
09/06 04:49:24 AM: Update 47519: task mnli, batch 519 (47519): accuracy: 0.8679, mnli_loss: 0.3474
09/06 04:49:35 AM: Update 47539: task mnli, batch 539 (47539): accuracy: 0.8682, mnli_loss: 0.3463
09/06 04:49:45 AM: Update 47559: task mnli, batch 559 (47559): accuracy: 0.8684, mnli_loss: 0.3459
09/06 04:49:56 AM: Update 47578: task mnli, batch 578 (47578): accuracy: 0.8687, mnli_loss: 0.3459
09/06 04:50:06 AM: Update 47597: task mnli, batch 597 (47597): accuracy: 0.8684, mnli_loss: 0.3473
09/06 04:50:16 AM: Update 47616: task mnli, batch 616 (47616): accuracy: 0.8695, mnli_loss: 0.3468
09/06 04:50:26 AM: Update 47636: task mnli, batch 636 (47636): accuracy: 0.8696, mnli_loss: 0.3464
09/06 04:50:36 AM: Update 47654: task mnli, batch 654 (47654): accuracy: 0.8693, mnli_loss: 0.3464
09/06 04:50:46 AM: Update 47674: task mnli, batch 674 (47674): accuracy: 0.8703, mnli_loss: 0.3436
09/06 04:50:57 AM: Update 47693: task mnli, batch 693 (47693): accuracy: 0.8695, mnli_loss: 0.3453
09/06 04:51:07 AM: Update 47712: task mnli, batch 712 (47712): accuracy: 0.8690, mnli_loss: 0.3462
09/06 04:51:18 AM: Update 47733: task mnli, batch 733 (47733): accuracy: 0.8698, mnli_loss: 0.3441
09/06 04:51:28 AM: Update 47752: task mnli, batch 752 (47752): accuracy: 0.8694, mnli_loss: 0.3445
09/06 04:51:39 AM: Update 47765: task mnli, batch 765 (47765): accuracy: 0.8682, mnli_loss: 0.3469
09/06 04:51:49 AM: Update 47783: task mnli, batch 783 (47783): accuracy: 0.8681, mnli_loss: 0.3472
09/06 04:51:59 AM: Update 47802: task mnli, batch 802 (47802): accuracy: 0.8679, mnli_loss: 0.3473
09/06 04:52:10 AM: Update 47821: task mnli, batch 821 (47821): accuracy: 0.8673, mnli_loss: 0.3480
09/06 04:52:20 AM: Update 47840: task mnli, batch 840 (47840): accuracy: 0.8675, mnli_loss: 0.3481
09/06 04:52:31 AM: Update 47859: task mnli, batch 859 (47859): accuracy: 0.8671, mnli_loss: 0.3480
09/06 04:52:41 AM: Update 47877: task mnli, batch 877 (47877): accuracy: 0.8669, mnli_loss: 0.3485
09/06 04:52:51 AM: Update 47895: task mnli, batch 895 (47895): accuracy: 0.8668, mnli_loss: 0.3486
09/06 04:53:01 AM: Update 47913: task mnli, batch 913 (47913): accuracy: 0.8669, mnli_loss: 0.3489
09/06 04:53:11 AM: Update 47932: task mnli, batch 932 (47932): accuracy: 0.8661, mnli_loss: 0.3507
09/06 04:53:22 AM: Update 47951: task mnli, batch 951 (47951): accuracy: 0.8660, mnli_loss: 0.3507
09/06 04:53:32 AM: Update 47969: task mnli, batch 969 (47969): accuracy: 0.8659, mnli_loss: 0.3511
09/06 04:53:42 AM: Update 47988: task mnli, batch 988 (47988): accuracy: 0.8661, mnli_loss: 0.3504
09/06 04:53:49 AM: ***** Step 48000 / Validation 48 *****
09/06 04:53:49 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 04:53:49 AM: Validating...
09/06 04:53:52 AM: Evaluate: task mnli, batch 17 (209): accuracy: 0.8137, mnli_loss: 0.4930
09/06 04:54:02 AM: Evaluate: task mnli, batch 67 (209): accuracy: 0.8190, mnli_loss: 0.4977
09/06 04:54:12 AM: Evaluate: task mnli, batch 117 (209): accuracy: 0.8137, mnli_loss: 0.5057
09/06 04:54:23 AM: Evaluate: task mnli, batch 167 (209): accuracy: 0.8196, mnli_loss: 0.5059
09/06 04:54:31 AM: Updating LR scheduler:
09/06 04:54:31 AM: 	Best result seen so far for macro_avg: 0.820
09/06 04:54:31 AM: 	# validation passes without improvement: 2
09/06 04:54:31 AM: mnli_loss: training: 0.350003 validation: 0.517714
09/06 04:54:31 AM: macro_avg: validation: 0.815800
09/06 04:54:31 AM: micro_avg: validation: 0.815800
09/06 04:54:31 AM: mnli_accuracy: training: 0.866286 validation: 0.815800
09/06 04:54:31 AM: Global learning rate: 2.5e-06
09/06 04:54:31 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 04:54:33 AM: Update 48002: task mnli, batch 2 (48002): accuracy: 0.8750, mnli_loss: 0.2066
09/06 04:54:43 AM: Update 48021: task mnli, batch 21 (48021): accuracy: 0.8532, mnli_loss: 0.3519
09/06 04:54:54 AM: Update 48041: task mnli, batch 41 (48041): accuracy: 0.8526, mnli_loss: 0.3610
09/06 04:55:04 AM: Update 48060: task mnli, batch 60 (48060): accuracy: 0.8576, mnli_loss: 0.3564
09/06 04:55:14 AM: Update 48079: task mnli, batch 79 (48079): accuracy: 0.8608, mnli_loss: 0.3493
09/06 04:55:24 AM: Update 48098: task mnli, batch 98 (48098): accuracy: 0.8580, mnli_loss: 0.3561
09/06 04:55:35 AM: Update 48118: task mnli, batch 118 (48118): accuracy: 0.8612, mnli_loss: 0.3439
09/06 04:55:45 AM: Update 48138: task mnli, batch 138 (48138): accuracy: 0.8587, mnli_loss: 0.3533
09/06 04:55:56 AM: Update 48158: task mnli, batch 158 (48158): accuracy: 0.8623, mnli_loss: 0.3511
09/06 04:56:06 AM: Update 48176: task mnli, batch 176 (48176): accuracy: 0.8627, mnli_loss: 0.3495
09/06 04:56:16 AM: Update 48190: task mnli, batch 190 (48190): accuracy: 0.8640, mnli_loss: 0.3525
09/06 04:56:26 AM: Update 48208: task mnli, batch 208 (48208): accuracy: 0.8636, mnli_loss: 0.3534
09/06 04:56:36 AM: Update 48227: task mnli, batch 227 (48227): accuracy: 0.8616, mnli_loss: 0.3563
09/06 04:56:47 AM: Update 48246: task mnli, batch 246 (48246): accuracy: 0.8616, mnli_loss: 0.3561
09/06 04:56:57 AM: Update 48265: task mnli, batch 265 (48265): accuracy: 0.8618, mnli_loss: 0.3547
09/06 04:57:08 AM: Update 48284: task mnli, batch 284 (48284): accuracy: 0.8610, mnli_loss: 0.3549
09/06 04:57:18 AM: Update 48303: task mnli, batch 303 (48303): accuracy: 0.8615, mnli_loss: 0.3570
09/06 04:57:28 AM: Update 48321: task mnli, batch 321 (48321): accuracy: 0.8627, mnli_loss: 0.3550
09/06 04:57:39 AM: Update 48342: task mnli, batch 342 (48342): accuracy: 0.8630, mnli_loss: 0.3540
09/06 04:57:49 AM: Update 48360: task mnli, batch 360 (48360): accuracy: 0.8643, mnli_loss: 0.3525
09/06 04:57:59 AM: Update 48377: task mnli, batch 377 (48377): accuracy: 0.8643, mnli_loss: 0.3514
09/06 04:58:09 AM: Update 48396: task mnli, batch 396 (48396): accuracy: 0.8644, mnli_loss: 0.3502
09/06 04:58:20 AM: Update 48415: task mnli, batch 415 (48415): accuracy: 0.8642, mnli_loss: 0.3504
09/06 04:58:30 AM: Update 48435: task mnli, batch 435 (48435): accuracy: 0.8644, mnli_loss: 0.3508
09/06 04:58:40 AM: Update 48452: task mnli, batch 452 (48452): accuracy: 0.8639, mnli_loss: 0.3524
09/06 04:58:51 AM: Update 48473: task mnli, batch 473 (48473): accuracy: 0.8645, mnli_loss: 0.3525
09/06 04:59:01 AM: Update 48491: task mnli, batch 491 (48491): accuracy: 0.8641, mnli_loss: 0.3536
09/06 04:59:11 AM: Update 48510: task mnli, batch 510 (48510): accuracy: 0.8638, mnli_loss: 0.3546
09/06 04:59:22 AM: Update 48529: task mnli, batch 529 (48529): accuracy: 0.8637, mnli_loss: 0.3561
09/06 04:59:32 AM: Update 48548: task mnli, batch 548 (48548): accuracy: 0.8638, mnli_loss: 0.3558
09/06 04:59:42 AM: Update 48569: task mnli, batch 569 (48569): accuracy: 0.8640, mnli_loss: 0.3544
09/06 04:59:52 AM: Update 48587: task mnli, batch 587 (48587): accuracy: 0.8644, mnli_loss: 0.3529
09/06 05:00:03 AM: Update 48601: task mnli, batch 601 (48601): accuracy: 0.8638, mnli_loss: 0.3535
09/06 05:00:13 AM: Update 48619: task mnli, batch 619 (48619): accuracy: 0.8644, mnli_loss: 0.3527
09/06 05:00:23 AM: Update 48636: task mnli, batch 636 (48636): accuracy: 0.8646, mnli_loss: 0.3525
09/06 05:00:33 AM: Update 48657: task mnli, batch 657 (48657): accuracy: 0.8652, mnli_loss: 0.3519
09/06 05:00:44 AM: Update 48676: task mnli, batch 676 (48676): accuracy: 0.8655, mnli_loss: 0.3511
09/06 05:00:54 AM: Update 48693: task mnli, batch 693 (48693): accuracy: 0.8652, mnli_loss: 0.3518
09/06 05:01:04 AM: Update 48712: task mnli, batch 712 (48712): accuracy: 0.8649, mnli_loss: 0.3525
09/06 05:01:15 AM: Update 48731: task mnli, batch 731 (48731): accuracy: 0.8659, mnli_loss: 0.3513
09/06 05:01:25 AM: Update 48750: task mnli, batch 750 (48750): accuracy: 0.8658, mnli_loss: 0.3523
09/06 05:01:35 AM: Update 48767: task mnli, batch 767 (48767): accuracy: 0.8655, mnli_loss: 0.3521
09/06 05:01:45 AM: Update 48788: task mnli, batch 788 (48788): accuracy: 0.8654, mnli_loss: 0.3520
09/06 05:01:56 AM: Update 48805: task mnli, batch 805 (48805): accuracy: 0.8652, mnli_loss: 0.3528
09/06 05:02:06 AM: Update 48825: task mnli, batch 825 (48825): accuracy: 0.8647, mnli_loss: 0.3537
09/06 05:02:16 AM: Update 48844: task mnli, batch 844 (48844): accuracy: 0.8649, mnli_loss: 0.3538
09/06 05:02:27 AM: Update 48864: task mnli, batch 864 (48864): accuracy: 0.8653, mnli_loss: 0.3533
09/06 05:02:37 AM: Update 48883: task mnli, batch 883 (48883): accuracy: 0.8656, mnli_loss: 0.3531
09/06 05:02:47 AM: Update 48903: task mnli, batch 903 (48903): accuracy: 0.8662, mnli_loss: 0.3519
09/06 05:02:58 AM: Update 48923: task mnli, batch 923 (48923): accuracy: 0.8665, mnli_loss: 0.3512
09/06 05:03:08 AM: Update 48941: task mnli, batch 941 (48941): accuracy: 0.8665, mnli_loss: 0.3516
09/06 05:03:18 AM: Update 48959: task mnli, batch 959 (48959): accuracy: 0.8663, mnli_loss: 0.3523
09/06 05:03:29 AM: Update 48978: task mnli, batch 978 (48978): accuracy: 0.8663, mnli_loss: 0.3527
09/06 05:03:39 AM: Update 48997: task mnli, batch 997 (48997): accuracy: 0.8661, mnli_loss: 0.3532
09/06 05:03:40 AM: ***** Step 49000 / Validation 49 *****
09/06 05:03:40 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 05:03:40 AM: Validating...
09/06 05:03:49 AM: Evaluate: task mnli, batch 42 (209): accuracy: 0.8185, mnli_loss: 0.4940
09/06 05:03:59 AM: Evaluate: task mnli, batch 92 (209): accuracy: 0.8193, mnli_loss: 0.4953
09/06 05:04:09 AM: Evaluate: task mnli, batch 142 (209): accuracy: 0.8172, mnli_loss: 0.5106
09/06 05:04:19 AM: Evaluate: task mnli, batch 192 (209): accuracy: 0.8197, mnli_loss: 0.5063
09/06 05:04:23 AM: Updating LR scheduler:
09/06 05:04:23 AM: 	Best result seen so far for macro_avg: 0.820
09/06 05:04:23 AM: 	# validation passes without improvement: 3
09/06 05:04:23 AM: mnli_loss: training: 0.352983 validation: 0.516843
09/06 05:04:23 AM: macro_avg: validation: 0.816000
09/06 05:04:23 AM: micro_avg: validation: 0.816000
09/06 05:04:23 AM: mnli_accuracy: training: 0.866161 validation: 0.816000
09/06 05:04:23 AM: Global learning rate: 2.5e-06
09/06 05:04:23 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:04:30 AM: Update 49012: task mnli, batch 12 (49012): accuracy: 0.8715, mnli_loss: 0.3670
09/06 05:04:40 AM: Update 49028: task mnli, batch 28 (49028): accuracy: 0.8595, mnli_loss: 0.3879
09/06 05:04:50 AM: Update 49047: task mnli, batch 47 (49047): accuracy: 0.8506, mnli_loss: 0.3901
09/06 05:05:01 AM: Update 49067: task mnli, batch 67 (49067): accuracy: 0.8529, mnli_loss: 0.3846
09/06 05:05:11 AM: Update 49087: task mnli, batch 87 (49087): accuracy: 0.8547, mnli_loss: 0.3832
09/06 05:05:22 AM: Update 49105: task mnli, batch 105 (49105): accuracy: 0.8582, mnli_loss: 0.3701
09/06 05:05:32 AM: Update 49124: task mnli, batch 124 (49124): accuracy: 0.8597, mnli_loss: 0.3707
09/06 05:05:42 AM: Update 49139: task mnli, batch 139 (49139): accuracy: 0.8583, mnli_loss: 0.3716
09/06 05:05:52 AM: Update 49157: task mnli, batch 157 (49157): accuracy: 0.8573, mnli_loss: 0.3715
09/06 05:06:02 AM: Update 49176: task mnli, batch 176 (49176): accuracy: 0.8590, mnli_loss: 0.3698
09/06 05:06:13 AM: Update 49195: task mnli, batch 195 (49195): accuracy: 0.8606, mnli_loss: 0.3651
09/06 05:06:23 AM: Update 49214: task mnli, batch 214 (49214): accuracy: 0.8611, mnli_loss: 0.3642
09/06 05:06:33 AM: Update 49234: task mnli, batch 234 (49234): accuracy: 0.8637, mnli_loss: 0.3602
09/06 05:06:44 AM: Update 49254: task mnli, batch 254 (49254): accuracy: 0.8648, mnli_loss: 0.3552
09/06 05:06:54 AM: Update 49273: task mnli, batch 273 (49273): accuracy: 0.8659, mnli_loss: 0.3537
09/06 05:07:04 AM: Update 49291: task mnli, batch 291 (49291): accuracy: 0.8666, mnli_loss: 0.3531
09/06 05:07:14 AM: Update 49311: task mnli, batch 311 (49311): accuracy: 0.8677, mnli_loss: 0.3501
09/06 05:07:25 AM: Update 49329: task mnli, batch 329 (49329): accuracy: 0.8681, mnli_loss: 0.3479
09/06 05:07:35 AM: Update 49346: task mnli, batch 346 (49346): accuracy: 0.8688, mnli_loss: 0.3482
09/06 05:07:45 AM: Update 49365: task mnli, batch 365 (49365): accuracy: 0.8686, mnli_loss: 0.3468
09/06 05:07:55 AM: Update 49382: task mnli, batch 382 (49382): accuracy: 0.8681, mnli_loss: 0.3477
09/06 05:08:05 AM: Update 49401: task mnli, batch 401 (49401): accuracy: 0.8686, mnli_loss: 0.3485
09/06 05:08:16 AM: Update 49420: task mnli, batch 420 (49420): accuracy: 0.8695, mnli_loss: 0.3450
09/06 05:08:26 AM: Update 49441: task mnli, batch 441 (49441): accuracy: 0.8693, mnli_loss: 0.3447
09/06 05:08:36 AM: Update 49460: task mnli, batch 460 (49460): accuracy: 0.8692, mnli_loss: 0.3466
09/06 05:08:47 AM: Update 49480: task mnli, batch 480 (49480): accuracy: 0.8689, mnli_loss: 0.3485
09/06 05:08:57 AM: Update 49498: task mnli, batch 498 (49498): accuracy: 0.8689, mnli_loss: 0.3484
09/06 05:09:07 AM: Update 49516: task mnli, batch 516 (49516): accuracy: 0.8688, mnli_loss: 0.3483
09/06 05:09:17 AM: Update 49535: task mnli, batch 535 (49535): accuracy: 0.8687, mnli_loss: 0.3484
09/06 05:09:27 AM: Update 49549: task mnli, batch 549 (49549): accuracy: 0.8685, mnli_loss: 0.3488
09/06 05:09:37 AM: Update 49568: task mnli, batch 568 (49568): accuracy: 0.8693, mnli_loss: 0.3465
09/06 05:09:48 AM: Update 49587: task mnli, batch 587 (49587): accuracy: 0.8704, mnli_loss: 0.3446
09/06 05:09:58 AM: Update 49606: task mnli, batch 606 (49606): accuracy: 0.8703, mnli_loss: 0.3445
09/06 05:10:08 AM: Update 49625: task mnli, batch 625 (49625): accuracy: 0.8702, mnli_loss: 0.3438
09/06 05:10:19 AM: Update 49644: task mnli, batch 644 (49644): accuracy: 0.8697, mnli_loss: 0.3453
09/06 05:10:29 AM: Update 49662: task mnli, batch 662 (49662): accuracy: 0.8702, mnli_loss: 0.3438
09/06 05:10:40 AM: Update 49682: task mnli, batch 682 (49682): accuracy: 0.8696, mnli_loss: 0.3451
09/06 05:10:50 AM: Update 49701: task mnli, batch 701 (49701): accuracy: 0.8700, mnli_loss: 0.3447
09/06 05:11:00 AM: Update 49721: task mnli, batch 721 (49721): accuracy: 0.8709, mnli_loss: 0.3420
09/06 05:11:11 AM: Update 49741: task mnli, batch 741 (49741): accuracy: 0.8703, mnli_loss: 0.3428
09/06 05:11:21 AM: Update 49759: task mnli, batch 759 (49759): accuracy: 0.8710, mnli_loss: 0.3421
09/06 05:11:31 AM: Update 49778: task mnli, batch 778 (49778): accuracy: 0.8712, mnli_loss: 0.3419
09/06 05:11:41 AM: Update 49796: task mnli, batch 796 (49796): accuracy: 0.8710, mnli_loss: 0.3427
09/06 05:11:52 AM: Update 49815: task mnli, batch 815 (49815): accuracy: 0.8703, mnli_loss: 0.3434
09/06 05:12:02 AM: Update 49835: task mnli, batch 835 (49835): accuracy: 0.8706, mnli_loss: 0.3428
09/06 05:12:12 AM: Update 49856: task mnli, batch 856 (49856): accuracy: 0.8705, mnli_loss: 0.3441
09/06 05:12:22 AM: Update 49873: task mnli, batch 873 (49873): accuracy: 0.8703, mnli_loss: 0.3439
09/06 05:12:33 AM: Update 49892: task mnli, batch 892 (49892): accuracy: 0.8702, mnli_loss: 0.3444
09/06 05:12:43 AM: Update 49911: task mnli, batch 911 (49911): accuracy: 0.8703, mnli_loss: 0.3442
09/06 05:12:53 AM: Update 49929: task mnli, batch 929 (49929): accuracy: 0.8702, mnli_loss: 0.3437
09/06 05:13:04 AM: Update 49949: task mnli, batch 949 (49949): accuracy: 0.8703, mnli_loss: 0.3437
09/06 05:13:14 AM: Update 49963: task mnli, batch 963 (49963): accuracy: 0.8700, mnli_loss: 0.3441
09/06 05:13:24 AM: Update 49982: task mnli, batch 982 (49982): accuracy: 0.8697, mnli_loss: 0.3439
09/06 05:13:34 AM: Update 50000: task mnli, batch 1000 (50000): accuracy: 0.8698, mnli_loss: 0.3438
09/06 05:13:34 AM: ***** Step 50000 / Validation 50 *****
09/06 05:13:34 AM: mnli: trained on 1000 batches, 0.061 epochs
09/06 05:13:34 AM: Validating...
09/06 05:13:44 AM: Evaluate: task mnli, batch 51 (209): accuracy: 0.8219, mnli_loss: 0.4864
09/06 05:13:54 AM: Evaluate: task mnli, batch 101 (209): accuracy: 0.8197, mnli_loss: 0.4946
09/06 05:14:04 AM: Evaluate: task mnli, batch 150 (209): accuracy: 0.8197, mnli_loss: 0.5069
09/06 05:14:15 AM: Evaluate: task mnli, batch 200 (209): accuracy: 0.8208, mnli_loss: 0.5050
09/06 05:14:16 AM: Updating LR scheduler:
09/06 05:14:16 AM: 	Best result seen so far for macro_avg: 0.820
09/06 05:14:16 AM: 	# validation passes without improvement: 4
09/06 05:14:16 AM: Reached max_epochs limit on all tasks. Stopping training.
09/06 05:14:16 AM: mnli_loss: training: 0.343809 validation: 0.515038
09/06 05:14:16 AM: macro_avg: validation: 0.817000
09/06 05:14:16 AM: micro_avg: validation: 0.817000
09/06 05:14:16 AM: mnli_accuracy: training: 0.869774 validation: 0.817000
09/06 05:14:16 AM: Global learning rate: 2.5e-06
09/06 05:14:16 AM: Saving checkpoints to: diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:14:18 AM: Stopped training after 50 validation checks
09/06 05:14:18 AM: Trained mnli for 50000 batches or 3.056 epochs
09/06 05:14:18 AM: ***** VALIDATION RESULTS *****
09/06 05:14:18 AM: mnli_accuracy (for best val pass 41): mnli_loss: 0.52355, macro_avg: 0.82040, micro_avg: 0.82040, mnli_accuracy: 0.82040
09/06 05:14:18 AM: micro_avg (for best val pass 41): mnli_loss: 0.52355, macro_avg: 0.82040, micro_avg: 0.82040, mnli_accuracy: 0.82040
09/06 05:14:18 AM: macro_avg (for best val pass 41): mnli_loss: 0.52355, macro_avg: 0.82040, micro_avg: 0.82040, mnli_accuracy: 0.82040
09/06 05:14:18 AM: Evaluating...
09/06 05:14:19 AM: Loaded model state from diagnostic_run_2/my-experiment/mnli_diagnostic/model_state_pretrain_val_41.best.th
09/06 05:14:19 AM: Evaluating on: glue-diagnostic, split: val
09/06 05:14:30 AM: Task 'glue-diagnostic': sorting predictions by 'idx'
09/06 05:14:30 AM: Finished evaluating on: glue-diagnostic
09/06 05:14:30 AM: Wrote predictions for task: glue-diagnostic
09/06 05:14:30 AM: Task 'glue-diagnostic': Wrote predictions to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:14:30 AM: Wrote all preds for split 'val' to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:14:30 AM: Evaluating on: glue-diagnostic, split: test
09/06 05:14:40 AM: Task 'glue-diagnostic': sorting predictions by 'idx'
09/06 05:14:40 AM: Finished evaluating on: glue-diagnostic
09/06 05:14:40 AM: Wrote predictions for task: glue-diagnostic
09/06 05:14:40 AM: Task 'glue-diagnostic': Wrote predictions to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:14:40 AM: Wrote all preds for split 'test' to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:14:40 AM: Writing results for split 'val' to diagnostic_run_2/my-experiment/results.tsv
09/06 05:14:40 AM: micro_avg: 0.000, macro_avg: 0.000, glue-diagnostic_lex_sem: 0.379, glue-diagnostic_lex_sem__Factivity;Quantifiers: 0.000, glue-diagnostic_lex_sem__Factivity: 0.214, glue-diagnostic_lex_sem__Quantifiers: 0.595, glue-diagnostic_lex_sem__Named entities: 0.260, glue-diagnostic_lex_sem__Lexical entailment;Factivity: 0.000, glue-diagnostic_lex_sem__Symmetry/Collectivity: 0.000, glue-diagnostic_lex_sem__Redundancy: 0.592, glue-diagnostic_lex_sem__Morphological negation: 0.428, glue-diagnostic_lex_sem__Lexical entailment: 0.264, glue-diagnostic_lex_sem__Lexical entailment;Quantifiers: 1.000, glue-diagnostic_pr_ar_str: 0.406, glue-diagnostic_pr_ar_str__Active/Passive: 0.332, glue-diagnostic_pr_ar_str__Nominalization: 0.405, glue-diagnostic_pr_ar_str__Relative clauses;Anaphora/Coreference: 1.000, glue-diagnostic_pr_ar_str__Restrictivity: -0.250, glue-diagnostic_pr_ar_str__Coordination scope;Prepositional phrases: 0.333, glue-diagnostic_pr_ar_str__Ellipsis/Implicits;Anaphora/Coreference: 0.289, glue-diagnostic_pr_ar_str__Anaphora/Coreference: 0.260, glue-diagnostic_pr_ar_str__Core args;Anaphora/Coreference: 0.447, glue-diagnostic_pr_ar_str__Active/Passive;Prepositional phrases: 1.000, glue-diagnostic_pr_ar_str__Coordination scope: 0.443, glue-diagnostic_pr_ar_str__Nominalization;Genitives/Partitives: 0.000, glue-diagnostic_pr_ar_str__Intersectivity: 0.262, glue-diagnostic_pr_ar_str__Genitives/Partitives: 0.685, glue-diagnostic_pr_ar_str__Intersectivity;Ellipsis/Implicits: 0.000, glue-diagnostic_pr_ar_str__Datives: 0.673, glue-diagnostic_pr_ar_str__Restrictivity;Relative clauses: -1.000, glue-diagnostic_pr_ar_str__Anaphora/Coreference;Prepositional phrases: 0.577, glue-diagnostic_pr_ar_str__Relative clauses;Restrictivity: 0.577, glue-diagnostic_pr_ar_str__Core args: 0.318, glue-diagnostic_pr_ar_str__Restrictivity;Anaphora/Coreference: 0.000, glue-diagnostic_pr_ar_str__Ellipsis/Implicits: 0.455, glue-diagnostic_pr_ar_str__Relative clauses: 0.198, glue-diagnostic_pr_ar_str__Prepositional phrases: 0.707, glue-diagnostic_logic: 0.215, glue-diagnostic_logic__Existential;Negation: 0.000, glue-diagnostic_logic__Existential;Upward monotone: 1.000, glue-diagnostic_logic__Universal;Negation: 0.000, glue-diagnostic_logic__Downward monotone;Conditionals: -1.000, glue-diagnostic_logic__Negation: 0.112, glue-diagnostic_logic__Intervals/Numbers: -0.111, glue-diagnostic_logic__Disjunction: -0.374, glue-diagnostic_logic__Universal: 0.682, glue-diagnostic_logic__Temporal;Intervals/Numbers: 0.000, glue-diagnostic_logic__Disjunction;Conjunction: 0.000, glue-diagnostic_logic__Conjunction;Upward monotone: 1.000, glue-diagnostic_logic__Temporal: 0.180, glue-diagnostic_logic__Upward monotone: 0.363, glue-diagnostic_logic__Disjunction;Negation: -0.337, glue-diagnostic_logic__Non-monotone: 0.171, glue-diagnostic_logic__Universal;Conjunction: 0.000, glue-diagnostic_logic__Conjunction;Negation: 0.000, glue-diagnostic_logic__Conjunction: 0.492, glue-diagnostic_logic__Existential: 0.331, glue-diagnostic_logic__Downward monotone: -0.544, glue-diagnostic_logic__Disjunction;Conditionals;Negation: 0.289, glue-diagnostic_logic__Double negation;Negation: 0.000, glue-diagnostic_logic__Downward monotone;Existential;Negation: -1.000, glue-diagnostic_logic__Conditionals: 0.247, glue-diagnostic_logic__Disjunction;Non-monotone: 0.000, glue-diagnostic_logic__Double negation: 0.290, glue-diagnostic_logic__Negation;Conditionals: 0.000, glue-diagnostic_logic__Intervals/Numbers;Non-monotone: 0.707, glue-diagnostic_logic__Temporal;Conjunction: 0.000, glue-diagnostic_knowledge: 0.185, glue-diagnostic_knowledge__Common sense: 0.235, glue-diagnostic_knowledge__World knowledge: 0.131, glue-diagnostic_all_mcc: 0.329, glue-diagnostic_accuracy: 0.568
09/06 05:14:41 AM: Loaded model state from diagnostic_run_2/my-experiment/mnli_diagnostic/model_state_pretrain_val_41.best.th
09/06 05:14:41 AM: Evaluating on: mnli, split: val
09/06 05:15:11 AM: 	Task mnli: batch 143
09/06 05:15:41 AM: 	Task mnli: batch 292
09/06 05:16:11 AM: 	Task mnli: batch 440
09/06 05:16:41 AM: 	Task mnli: batch 587
09/06 05:17:11 AM: 	Task mnli: batch 734
09/06 05:17:29 AM: Task 'mnli': sorting predictions by 'idx'
09/06 05:17:29 AM: Finished evaluating on: mnli
09/06 05:17:29 AM: Wrote predictions for task: mnli
09/06 05:17:29 AM: Task 'mnli': Wrote predictions to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:17:29 AM: Wrote all preds for split 'val' to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:17:29 AM: Evaluating on: mnli, split: test
09/06 05:17:59 AM: 	Task mnli: batch 148
09/06 05:18:29 AM: 	Task mnli: batch 297
09/06 05:18:59 AM: 	Task mnli: batch 445
09/06 05:19:29 AM: 	Task mnli: batch 587
09/06 05:19:59 AM: 	Task mnli: batch 734
09/06 05:20:17 AM: Task 'mnli': sorting predictions by 'idx'
09/06 05:20:17 AM: Finished evaluating on: mnli
09/06 05:20:17 AM: There are 19643 examples in MNLI, 19643 were expected
09/06 05:20:17 AM: Wrote predictions for task: mnli
09/06 05:20:17 AM: Task 'mnli': Wrote predictions to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:20:17 AM: Wrote all preds for split 'test' to diagnostic_run_2/my-experiment/mnli_diagnostic
09/06 05:20:17 AM: Writing results for split 'val' to diagnostic_run_2/my-experiment/results.tsv
09/06 05:20:17 AM: micro_avg: 0.825, macro_avg: 0.825, mnli_accuracy: 0.825
09/06 05:20:17 AM: Done!
